{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimality_gap(bk_sol, opt_sol):\n",
    "    return ((bk_sol - opt_sol) / bk_sol).mean().item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../results/eval_methods_pareto/cvrp50/symnco-cvrp50/results.pkl', '../results/eval_methods_pareto/cvrp50/am-cvrp50-sm/results.pkl', '../results/eval_methods_pareto/cvrp50/am-critic-cvrp50/results.pkl', '../results/eval_methods_pareto/cvrp50/am-cvrp50/results.pkl', '../results/eval_methods_pareto/cvrp50/pomo-cvrp50/results.pkl', '../results/eval_methods_pareto/cvrp50/am-cvrp50-sm-xl/results.pkl']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all files inside ../results iteratively with .pkl extension\n",
    "files = glob.glob(\"../results/**/*.pkl\", recursive=True)\n",
    "\n",
    "# get only tsp50 files\n",
    "files = [file for file in files if \"cvrp50\" in file]\n",
    "\n",
    "print(files)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver files\n",
    "\n",
    "These contain the BK solutions (best know), from which we compute the gaps\n",
    "\n",
    "We need to load depending on the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cost: 10.3661\n"
     ]
    }
   ],
   "source": [
    "# Concorde\n",
    "def load_solver_file_tsp(num_nodes):\n",
    "    solver_path = Path(\"../solver/tsp\")\n",
    "    solver_files = glob.glob(str(solver_path / \"*tsp*.pkl\"), recursive=True)\n",
    "    # load pickle of first solver file\n",
    "    file_ = solver_path / f\"tsp_{num_nodes}.pkl\"\n",
    "    with open(file_, 'rb') as f:\n",
    "        costs = pickle.load(f)\n",
    "    print(\"Concorde time for {} nodes: {:.2f}s\".format(num_nodes, costs[0]))\n",
    "    print(\"Average cost: {:.4f}\".format(sum(costs[1])/len(costs[1])))\n",
    "\n",
    "    return torch.Tensor(costs[1])\n",
    "\n",
    "\n",
    "\n",
    "# HGS\n",
    "def load_solver_file_vrp(num_nodes):\n",
    "\n",
    "    solver_path = Path(\"../solver/vrp\")\n",
    "\n",
    "    dir_ = solver_path / f\"{num_nodes}_test_seed_1234\"\n",
    "\n",
    "    solver_files = sorted(glob.glob(str(dir_ / \"*.txt\")))\n",
    "    # take the interger of file number and order by it\n",
    "    solver_files = sorted(solver_files, key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "    costs = []\n",
    "    for solver_file in solver_files:\n",
    "        with open(solver_file, \"r\") as f:\n",
    "            # get lines as dict\n",
    "            lines = f.readlines()\n",
    "            lines = [line.strip().split() for line in lines]\n",
    "            lines = {line[0]: line[1:] for line in lines}\n",
    "            costs.append(float(lines['obj_val:'][0]))\n",
    "    print(\"Average cost: {:.4f}\".format(sum(costs)/len(costs)))\n",
    "    return torch.Tensor(costs)\n",
    "\n",
    "\n",
    "# Example\n",
    "costs = load_solver_file_vrp(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plot\n",
    "\n",
    "experiments = ['greedy', 'augment', 'sampling', \n",
    "               'greedy_multistart', 'greedy_multistart_augment']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concorde time for 20 nodes: 1132.89s\n",
      "Average cost: 3.8357\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all files inside ../results iteratively with .pkl extension\n",
    "files = glob.glob(\"../results/**/*.pkl\", recursive=True)\n",
    "\n",
    "# # TSP50\n",
    "# costs = load_solver_file_tsp(50)\n",
    "# files = [file for file in files if \"tsp50\" in file]\n",
    "# results_name = \"tsp50\"\n",
    "\n",
    "# TSP20\n",
    "costs = load_solver_file_tsp(20)\n",
    "files = [file for file in files if \"tsp20\" in file]\n",
    "results_name = \"tsp20\"\n",
    "\n",
    "\n",
    "# # CVRP50\n",
    "# costs = load_solver_file_vrp(50)\n",
    "# files = [file for file in files if \"cvrp50\" in file]\n",
    "# results_name = \"cvrp50\"\n",
    "\n",
    "\n",
    "\n",
    "# # CVRP20\n",
    "# costs = load_solver_file_vrp(50)\n",
    "# files = [file for file in files if \"cvrp50\" in file]\n",
    "# results_name = \"cvrp50\"\n",
    "\n",
    "\n",
    "# Make a CSV table of all results\n",
    "csv_results = defaultdict(list)\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    data = pickle.load(open(f, \"rb\"))\n",
    "    filename = \"plots/\" + f.split(\"/\")[-3] + \"/\" + f.split(\"/\")[-2]\n",
    "\n",
    "    model_name = filename.split(\"/\")[-1]\n",
    "\n",
    "    for experiment in experiments:\n",
    "        \n",
    "        for exp in data[experiment]:\n",
    "\n",
    "            costs_model = -exp['rewards']\n",
    "            gap = optimality_gap(costs_model, costs)\n",
    "\n",
    "            costs_model_mean = costs_model.mean().item()\n",
    "\n",
    "            time = exp['inference_time']\n",
    "\n",
    "            csv_results['model'].append(model_name)\n",
    "\n",
    "            # exp name is exp['exp_kwargs'] combo of key and values if any\n",
    "            kwargs = \"\"\n",
    "            for key, value in exp['exp_kwargs'].items():\n",
    "                kwargs += f\"{key}_{value}_\"\n",
    "            csv_results['experiment'].append(experiment)\n",
    "            csv_results['kwargs'].append(kwargs)\n",
    "            csv_results['gap'].append(gap)\n",
    "            csv_results['costs'].append(costs_model_mean)\n",
    "            csv_results['time'].append(time)\n",
    "    \n",
    "\n",
    "\n",
    "# Save as markdown table\n",
    "\n",
    "df = pd.DataFrame(csv_results)\n",
    "# df.to_csv(\"results.csv\", index=False)\n",
    "\n",
    "\n",
    "# # SAve as markdown table\n",
    "# df.to_markdown(\"results.md\", index=False)\n",
    "\n",
    "\n",
    "# to html\n",
    "# df.to_html(\"results.html\", index=False)\n",
    "\n",
    "# to excel\n",
    "df.to_excel(f\"tables/{results_name}2.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
