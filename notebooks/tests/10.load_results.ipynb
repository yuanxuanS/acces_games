{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/botu/botu/Dev/rl4co/env/lib/python3.10/site-packages/torchrl/__init__.py:26: UserWarning: failed to set start method to spawn, and current start method for mp is fork.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.append(2*'../')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from omegaconf import DictConfig\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import lightning as L\n",
    "\n",
    "from rl4co.tasks.rl4co import RL4COLitModule\n",
    "from rl4co.utils.lightning import load_model_from_checkpoint\n",
    "from rl4co.tasks.eval import evaluate_policy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fpath = '../../results/eval_methods_pareto/tsp50/am-tsp50/results.pkl'\n",
    "\n",
    "with open(fpath, 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greedy\n",
      "1\n",
      "[{'actions': tensor([[44, 28, 43,  ..., 16,  8, 26],\n",
      "        [ 3,  6, 48,  ..., 41,  9, 25],\n",
      "        [49, 26, 10,  ..., 45, 31, 28],\n",
      "        ...,\n",
      "        [ 5, 33, 15,  ...,  8, 13, 35],\n",
      "        [ 2,  9, 22,  ...,  5,  8, 10],\n",
      "        [41, 34, 21,  ..., 48,  9, 16]]), 'rewards': tensor([-14.8449, -17.9183, -22.1559,  ..., -19.1024, -17.8643, -18.8610]), 'inference_time': 622.5745849609375, 'avg_reward': tensor(-17.3433), 'exp_name': 'greedy', 'exp_kwargs': {}}]\n",
      "augment\n",
      "2\n",
      "[{'actions': tensor([[44, 28, 43,  ..., 16,  8, 26],\n",
      "        [ 3, 15, 40,  ..., 41,  0, 39],\n",
      "        [20, 40, 23,  ..., 22, 14,  4],\n",
      "        ...,\n",
      "        [21, 49, 24,  ...,  8, 38, 25],\n",
      "        [15,  7, 45,  ..., 10,  4, 19],\n",
      "        [16,  2, 17,  ...,  0,  1, 29]]), 'rewards': tensor([-15.1276, -11.0022, -12.2947,  ..., -14.9368, -17.7912, -14.0221]), 'inference_time': 3078.867431640625, 'avg_reward': tensor(-13.7893), 'exp_name': 'augment', 'exp_kwargs': {'num_augment': 8}}, {'actions': tensor([[ 3, 30, 10,  ..., 17, 35,  6],\n",
      "        [ 3, 20, 34,  ..., 38, 43, 37],\n",
      "        [37, 17, 13,  ...,  6, 12, 27],\n",
      "        ...,\n",
      "        [40, 21, 30,  ...,  5, 33, 15],\n",
      "        [13, 41, 27,  ...,  2, 23, 22],\n",
      "        [28, 13, 47,  ...,  4, 32,  0]]), 'rewards': tensor([-13.9536, -13.1214, -14.4788,  ..., -13.5125, -14.1718, -11.9176]), 'inference_time': 6178.92236328125, 'avg_reward': tensor(-13.1810), 'exp_name': 'augment', 'exp_kwargs': {'num_augment': 16}}]\n",
      "augment_dihedral_8\n",
      "1\n",
      "[{'actions': tensor([[16, 44, 22,  ..., 31, 36,  8],\n",
      "        [14, 13, 15,  ...,  7, 18,  2],\n",
      "        [38, 43,  0,  ..., 49, 26, 41],\n",
      "        ...,\n",
      "        [47,  1, 21,  ...,  8, 42, 13],\n",
      "        [14, 25, 36,  ...,  7, 44, 42],\n",
      "        [32, 16, 12,  ..., 43, 23,  7]]), 'rewards': tensor([-14.5761, -13.5932, -13.1692,  ..., -14.5045, -16.0129, -13.6502]), 'inference_time': 3089.81396484375, 'avg_reward': tensor(-13.9177), 'exp_name': 'augment_dihedral_8', 'exp_kwargs': {'num_augment': 8, 'force_dihedral': True}}]\n",
      "sampling\n",
      "4\n",
      "[{'actions': tensor([[44, 28, 43,  ..., 36, 26, 16],\n",
      "        [ 3,  6, 48,  ..., 41,  9, 39],\n",
      "        [49, 26, 10,  ..., 25, 31, 28],\n",
      "        ...,\n",
      "        [ 5, 33, 15,  ..., 35,  8, 38],\n",
      "        [ 2,  9, 22,  ...,  5,  8, 10],\n",
      "        [41, 34, 21,  ..., 33,  9, 48]]), 'rewards': tensor([-15.2801, -17.6535, -21.5554,  ..., -17.5749, -17.8643, -17.1459]), 'inference_time': 3125.797119140625, 'avg_reward': tensor(-15.6541), 'exp_name': 'sampling', 'exp_kwargs': {'samples': 8, 'softmax_temp': 0.1}}, {'actions': tensor([[44, 28, 43,  ..., 26,  8, 16],\n",
      "        [ 3,  6, 48,  ..., 39,  9, 25],\n",
      "        [49, 26, 10,  ..., 45, 31, 28],\n",
      "        ...,\n",
      "        [ 5, 33, 15,  ..., 35,  8, 22],\n",
      "        [ 2,  9, 22,  ..., 27, 14, 10],\n",
      "        [41, 34, 21,  ..., 20, 48,  9]]), 'rewards': tensor([-14.9528, -17.8878, -21.5083,  ..., -16.9939, -18.6309, -16.9736]), 'inference_time': 3112.806884765625, 'avg_reward': tensor(-15.4379), 'exp_name': 'sampling', 'exp_kwargs': {'samples': 8, 'softmax_temp': 0.2}}, {'actions': tensor([[44, 28, 43,  ..., 16, 26,  8],\n",
      "        [ 3,  6, 48,  ..., 41,  9, 25],\n",
      "        [49, 26, 10,  ..., 25, 31, 28],\n",
      "        ...,\n",
      "        [ 5, 33, 15,  ...,  8, 13, 38],\n",
      "        [ 2,  9, 22,  ..., 24,  5, 10],\n",
      "        [41, 34, 21,  ..., 33,  9, 39]]), 'rewards': tensor([-14.7993, -17.5385, -20.0979,  ..., -18.6840, -17.0902, -16.9152]), 'inference_time': 6228.38671875, 'avg_reward': tensor(-15.2691), 'exp_name': 'sampling', 'exp_kwargs': {'samples': 16, 'softmax_temp': 0.1}}, {'actions': tensor([[44, 28,  9,  ...,  8, 26, 16],\n",
      "        [ 3,  6, 42,  ...,  9, 25, 21],\n",
      "        [49, 26, 10,  ..., 25, 31, 28],\n",
      "        ...,\n",
      "        [ 5, 33, 15,  ..., 35, 13,  8],\n",
      "        [ 2,  9, 22,  ..., 45, 21, 10],\n",
      "        [41, 34, 21,  ..., 33,  9, 48]]), 'rewards': tensor([-14.1857, -17.6403, -20.9267,  ..., -16.7348, -18.0886, -16.8282]), 'inference_time': 6235.74853515625, 'avg_reward': tensor(-14.9958), 'exp_name': 'sampling', 'exp_kwargs': {'samples': 16, 'softmax_temp': 0.2}}]\n",
      "greedy_multistart\n",
      "1\n",
      "[{'actions': tensor([[28, 44, 22,  ..., 36,  8, 26],\n",
      "        [18, 42, 40,  ...,  9, 41, 39],\n",
      "        [46,  9,  1,  ..., 10, 26, 49],\n",
      "        ...,\n",
      "        [28, 47, 16,  ...,  8, 13, 35],\n",
      "        [ 5, 25, 28,  ..., 32, 24, 19],\n",
      "        [21, 10,  7,  ..., 40, 22, 20]]), 'rewards': tensor([-14.2213, -14.5444, -19.1462,  ..., -14.1380, -14.5197, -14.0393]), 'inference_time': 1973.6304931640625, 'avg_reward': tensor(-13.5642), 'exp_name': 'greedy_multistart', 'exp_kwargs': {'num_starts': 50}}]\n",
      "greedy_multistart_augment_dihedral_8\n",
      "1\n",
      "[{'actions': tensor([[38, 47, 40,  ..., 29,  4,  9],\n",
      "        [12, 22, 25,  ..., 15, 19, 13],\n",
      "        [ 1, 37, 48,  ..., 13, 17,  4],\n",
      "        ...,\n",
      "        [ 9, 31, 28,  ..., 34, 43, 39],\n",
      "        [20,  2, 23,  ...,  7, 45, 10],\n",
      "        [43, 28, 26,  ..., 38, 46, 42]]), 'rewards': tensor([-11.1238, -10.4120, -11.6491,  ..., -12.8364, -11.0120, -11.5363]), 'inference_time': 15652.662109375, 'avg_reward': tensor(-11.3293), 'exp_name': 'greedy_multistart_augment_dihedral_8', 'exp_kwargs': {'num_starts': 50, 'num_augment': 8, 'force_dihedral': True}}]\n",
      "greedy_multistart_augment\n",
      "2\n",
      "[{'actions': tensor([[45, 34, 39,  ..., 21, 49, 25],\n",
      "        [ 3, 15, 40,  ..., 27,  0, 39],\n",
      "        [37, 20, 40,  ...,  4, 14, 35],\n",
      "        ...,\n",
      "        [14, 31, 27,  ..., 45, 19, 44],\n",
      "        [ 0,  3, 46,  ..., 41, 44, 14],\n",
      "        [28, 16, 17,  ...,  1,  3, 36]]), 'rewards': tensor([-11.1535, -10.7774, -11.2276,  ..., -11.9765, -11.6962, -11.7937]), 'inference_time': 15624.62109375, 'avg_reward': tensor(-11.2928), 'exp_name': 'greedy_multistart_augment', 'exp_kwargs': {'num_starts': 50, 'num_augment': 8}}, {'actions': tensor([[26, 31, 36,  ..., 39, 20, 34],\n",
      "        [44, 21, 25,  ...,  3, 20,  4],\n",
      "        [ 7, 33, 46,  ..., 17,  4, 35],\n",
      "        ...,\n",
      "        [ 0, 46, 49,  ..., 39, 40, 41],\n",
      "        [ 5, 41,  6,  ..., 33, 39, 35],\n",
      "        [36,  0, 21,  ..., 33,  9, 39]]), 'rewards': tensor([-10.6418, -10.9636, -12.3397,  ..., -11.7400,  -9.8414, -11.7158]), 'inference_time': 31376.267578125, 'avg_reward': tensor(-10.8345), 'exp_name': 'greedy_multistart_augment', 'exp_kwargs': {'num_starts': 50, 'num_augment': 16}}]\n"
     ]
    }
   ],
   "source": [
    "experiments = list(results.keys())\n",
    "\n",
    "for exp in experiments:\n",
    "    print(exp)\n",
    "    num_exps = len(results[exp])\n",
    "    print(num_exps)\n",
    "    print(results[exp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-14.8449, -17.9183, -22.1559,  ..., -19.1024, -17.8643, -18.8610])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['greedy'][0]['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: {'params': {'total': 708608, 'trainable': 708608, 'non_trainable': 0}}\n"
     ]
    }
   ],
   "source": [
    "checkpoints_path = Path('../../saved_checkpoints/')\n",
    "\n",
    "exp_name = 'tsp50'\n",
    "model_name = 'am-tsp50'\n",
    "checkpoints_path = checkpoints_path / exp_name / model_name\n",
    "\n",
    "cfg_path = checkpoints_path / 'config.yaml'\n",
    "ckpt_path = checkpoints_path / 'epoch_099.ckpt'\n",
    "\n",
    "lit_module = load_model_from_checkpoint(cfg_path, ckpt_path, phase='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "policy = lit_module.model.policy.to(device)\n",
    "policy.eval()\n",
    "env = lit_module.model.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective batch size: 1024 (ratio: 20)\n",
      "Using automatic batch size: 1024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b83932c82e486f8bf90350824e33b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running augmentation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for augmentation: -5.7103\n",
      "Time: 7.7164s\n"
     ]
    }
   ],
   "source": [
    "test_dataset = lit_module.test_dataset\n",
    "\n",
    "\n",
    "out_aug = evaluate_policy(env, policy, test_dataset, method=\"augment\", num_augment=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective batch size: 4096 (ratio: 1)\n",
      "Using automatic batch size: 4096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0505db22bb1346bbb913c38acc610f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running greedy:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for greedy: -5.7785\n",
      "Time: 0.5134s\n",
      "Effective batch size: 512 (ratio: 50)\n",
      "Using automatic batch size: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1673a71a33d4447ba3ce31885700df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running sampling:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for sampling: -5.7340\n",
      "Time: 18.9422s\n",
      "Effective batch size: 4096 (ratio: 5)\n",
      "Using automatic batch size: 4096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0062cf9286491cac5241dcd83848d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running greedy_multistart:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for greedy_multistart: -5.7668\n",
      "Time: 1.8868s\n",
      "Effective batch size: 4096 (ratio: 8)\n",
      "Using automatic batch size: 4096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb6ae87602d448e98017a0cacd7b1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running augmentation:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for augmentation: -5.7204\n",
      "Time: 3.0353s\n",
      "Effective batch size: 512 (ratio: 50)\n",
      "Using automatic batch size: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5b1e1a2f5841baba9b7b2f5a071e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running augmentation:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for augmentation: -5.7048\n",
      "Time: 19.1155s\n",
      "Effective batch size: 512 (ratio: 40)\n",
      "Using automatic batch size: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5d56f619304c65aac95ed8242d05f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running greedy_multistart_augment:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for greedy_multistart_augment: -5.7148\n",
      "Time: 14.8714s\n",
      "Effective batch size: 128 (ratio: 250)\n",
      "Using automatic batch size: 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c751e1f7702d46f78016d42ac1d5b53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running greedy_multistart_augment:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for greedy_multistart_augment: -5.7023\n",
      "Time: 91.0452s\n"
     ]
    }
   ],
   "source": [
    "test_dataset = lit_module.test_dataset\n",
    "\n",
    "# Greedy\n",
    "out_greedy = evaluate_policy(env, policy, test_dataset, method=\"greedy\")\n",
    "\n",
    "# Sampling\n",
    "out_samppling = evaluate_policy(env, policy, test_dataset, method=\"sampling\", samples=50)\n",
    "\n",
    "# Greedy multistart\n",
    "out_greedy_ms = evaluate_policy(env, policy, test_dataset, method=\"greedy_multistart\")#, num_starts=20)\n",
    "\n",
    "# Augment dihedral 8 (same as POMO)\n",
    "out_augd = evaluate_policy(env, policy, test_dataset, method=\"augment_dihedral_8\")\n",
    "\n",
    "# Symmetric augment\n",
    "out_aug = evaluate_policy(env, policy, test_dataset, method=\"augment\", num_augment=50)\n",
    "\n",
    "# Greedy multistart with augment dihedral 8\n",
    "out_greedy_ms_augd = evaluate_policy(env, policy, test_dataset, method=\"greedy_multistart_augment_dihedral_8\")\n",
    "\n",
    "# Greedy multistart with symmetric augment\n",
    "out_greddy_ms_aug = evaluate_policy(env, policy, test_dataset, method=\"greedy_multistart_augment\", num_augment=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
