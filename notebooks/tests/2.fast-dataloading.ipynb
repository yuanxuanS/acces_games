{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Env + Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys; sys.path.append('../../')\n",
        "\n",
        "import math\n",
        "from typing import List, Tuple, Optional, NamedTuple, Dict, Union, Any\n",
        "from einops import rearrange, repeat\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "from torch.nn import DataParallel\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import lightning as L\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from tensordict import TensorDict\n",
        "\n",
        "from rl4co.data.dataset import TensorDictDataset, TensorDictCollate\n",
        "from rl4co.models.rl.reinforce import *\n",
        "from rl4co.models.zoo.am.context import env_context\n",
        "from rl4co.models.zoo.am.embeddings import env_init_embedding, env_dynamic_embedding\n",
        "from rl4co.models.zoo.am.encoder import GraphAttentionEncoder\n",
        "from rl4co.models.zoo.am.decoder import Decoder, decode_probs, PrecomputedCache, LogitAttention\n",
        "from rl4co.models.zoo.am.policy import get_log_likelihood\n",
        "from rl4co.models.zoo.am import AttentionModel, AttentionModelPolicy\n",
        "from rl4co.models.nn.attention import NativeFlashMHA, flash_attn_wrapper\n",
        "from rl4co.utils.lightning import get_lightning_device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## New implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rl4co.envs import TSPEnv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'dataset'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 25\u001b[0m\n\u001b[1;32m     14\u001b[0m     dataloader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     15\u001b[0m         dataset,\n\u001b[1;32m     16\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         collate_fn\u001b[39m=\u001b[39mTensorDictCollate(),\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m env, \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataloader))\n\u001b[0;32m---> 25\u001b[0m env, batch \u001b[39m=\u001b[39m generate_env_data(\u001b[39m\"\u001b[39;49m\u001b[39mtsp\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m50\u001b[39;49m)\n",
            "Cell \u001b[0;32mIn[19], line 12\u001b[0m, in \u001b[0;36mgenerate_env_data\u001b[0;34m(env, size)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_env_data\u001b[39m(env, size):\n\u001b[1;32m     11\u001b[0m     env \u001b[39m=\u001b[39m get_env(env, size)\n\u001b[0;32m---> 12\u001b[0m     dataset \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mdataset([\u001b[39m2\u001b[39m])\n\u001b[1;32m     14\u001b[0m     dataloader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m     15\u001b[0m         dataset,\n\u001b[1;32m     16\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m         collate_fn\u001b[39m=\u001b[39mTensorDictCollate(),\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m env, \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataloader))\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dataset'"
          ]
        }
      ],
      "source": [
        "def get_env(env_name, size):\n",
        "    if env_name == \"tsp\":\n",
        "        env = TSPEnv(num_loc=size)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    return env.transform()\n",
        "\n",
        "\n",
        "def generate_env_data(env, size):\n",
        "    env = get_env(env, size)\n",
        "    dataset = env.dataset([2])\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=2,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        collate_fn=TensorDictCollate(),\n",
        "    )\n",
        "\n",
        "    return env, next(iter(dataloader))\n",
        "\n",
        "\n",
        "env, batch = generate_env_data(\"tsp\", 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.rand(10000, 50, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 50, 2])\n"
          ]
        }
      ],
      "source": [
        "data = TensorDict({'a': a}, batch_size=a.shape[0])\n",
        "\n",
        "dataset = TensorDictDataset(data)\n",
        "dl = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=0, collate_fn=TensorDictCollate())#, collate_fn=torch.stack)\n",
        "\n",
        "\n",
        "batch = next(iter(dl))\n",
        "print(batch['a'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.21 ms ± 2.85 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit for batch in dl: pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Old implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TensorDictDataset2(Dataset):\n",
        "    \"\"\"Simple dataset compatible with TensorDicts\"\"\"\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]  # note: use torch.stack to get batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 50, 2])\n"
          ]
        }
      ],
      "source": [
        "data = TensorDict({'a': a}, batch_size=a.shape[0])\n",
        "\n",
        "dataset = TensorDictDataset2(data)\n",
        "dl = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=0, collate_fn=torch.stack)# collate_fn=TensorDictCollate())#, collate_fn=torch.stack)\n",
        "\n",
        "\n",
        "batch = next(iter(dl))\n",
        "print(batch['a'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65.1 ms ± 170 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit for batch in dl: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 50, 2])\n"
          ]
        }
      ],
      "source": [
        "data = TensorDict({'a': a}, batch_size=a.shape[0])#.memmap_()\n",
        "\n",
        "# split the batch inside the dictionary as list of dictionaries\n",
        "data = [{key: value[i] for key, value in data.items()} for i in range(data.shape[0])]\n",
        "\n",
        "\n",
        "dataset = TensorDictDataset2(data)\n",
        "\n",
        "dl = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=0)#, collate_fn=#custom_collate)\n",
        "\n",
        "\n",
        "batch = next(iter(dl))\n",
        "print(batch['a'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.11 ms ± 3.49 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit for batch in dl: pass"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
