{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torchrl>=0.1.1 tensordict>=0.1.1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tensordict dataloading speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tensordict import TensorDict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.rand(1000, 50, 2)\n",
        "td = TensorDict({\"a\": a}, batch_size=1000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Case 1: store data as tensors, create TensorDicts on the run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "dataset = SimpleDataset(td['a'])\n",
        "dataloader = DataLoader(dataset, batch_size=32)\n",
        "x = TensorDict({'a': next(iter(dataloader))}, batch_size=32)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.24 ms ± 5.71 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit for x in dataloader: TensorDict({'a': x}, batch_size=x.shape[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Case 2: store data as TensorDicts and directly load them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "class TensorDictDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = [d for d in data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "data  = TensorDictDataset(td)\n",
        "# use collate_fn=torch.stack to avoid StopIteration error\n",
        "dataloader = DataLoader(data, batch_size=32, collate_fn=torch.stack)\n",
        "x = next(iter(dataloader))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.73 ms ± 5.12 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit for x in dataloader: pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Case 3: store TensorDict data as dictionaries and create TensorDicts on the run with collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "class CustomTensorDictDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = [\n",
        "            {key: value[i] for key, value in data.items()}\n",
        "            for i in range(data.shape[0])\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "class CustomTensorDictCollate(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, batch):\n",
        "        return TensorDict(\n",
        "            {key: torch.stack([b[key] for b in batch]) for key in batch[0].keys()},\n",
        "            batch_size=len(batch),\n",
        "        )\n",
        "    \n",
        "data = CustomTensorDictDataset(td)\n",
        "dataloader = DataLoader(data, batch_size=32, collate_fn=CustomTensorDictCollate())\n",
        "x = next(iter(dataloader))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "573 µs ± 1.32 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit for x in dataloader: pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apparently, splitting data into dictionaries and creating TensorDicts on the run is the fastest way to load data... but why is it not faster to just index TensorDicts instead? And is there a better way?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
