{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install torchrl>=0.1.1 tensordict>=0.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensordict\n",
        "\n",
        "# ??tensordict"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tensordict dataloading speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from tensordict import TensorDict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = torch.rand(1000, 50, 2)\n",
        "td = TensorDict({\"a\": a}, batch_size=1000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Case 1: store data as tensors, create TensorDicts on the run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        # We split into a list since it is faster to dataload (fair comparison vs others)\n",
        "        self.data = [d for d in data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "\n",
        "dataset = SimpleDataset(td['a'])\n",
        "dataloader = DataLoader(dataset, batch_size=32, collate_fn=torch.stack)\n",
        "x = TensorDict({'a': next(iter(dataloader))}, batch_size=32)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "522 µs ± 79.3 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r 10 -n 100 for x in dataloader: TensorDict({'a': x}, batch_size=x.shape[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Case 2: store data as TensorDicts and directly load them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "class TensorDictDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = [d for d in data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "data  = TensorDictDataset(td)\n",
        "# use collate_fn=torch.stack to avoid StopIteration error\n",
        "dataloader = DataLoader(data, batch_size=32, collate_fn=torch.stack)\n",
        "x = next(iter(dataloader))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.75 ms ± 58.9 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r 10 -n 100 for x in dataloader: pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Case 3: store TensorDict data as dictionaries and create TensorDicts on the run with collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "class CustomTensorDictDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = [\n",
        "            {key: value[i] for key, value in data.items()}\n",
        "            for i in range(data.shape[0])\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "class CustomTensorDictCollate(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, batch):\n",
        "        return TensorDict(\n",
        "            {key: torch.stack([b[key] for b in batch]) for key in batch[0].keys()},\n",
        "            batch_size=len(batch),\n",
        "        )\n",
        "    \n",
        "data = CustomTensorDictDataset(td)\n",
        "dataloader = DataLoader(data, batch_size=32, collate_fn=CustomTensorDictCollate())\n",
        "x = next(iter(dataloader))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "563 µs ± 63.6 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r 10 -n 100 for x in dataloader: pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 4: easiest way\n",
        "\n",
        "https://github.com/pytorch-labs/tensordict/issues/374"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "dataloader = DataLoader(td, batch_size=32, collate_fn=lambda x: x)\n",
        "x = next(iter(dataloader))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "668 µs ± 1.02 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r 10 -n 100 for x in dataloader: pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Case 5: direct indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LazyStackedTensorDict(\n",
            "    fields={\n",
            "        a: Tensor(shape=torch.Size([32, 50, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "    batch_size=torch.Size([32]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "class TensorDictDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "data  = TensorDictDataset(td)\n",
        "dataloader = DataLoader(data, batch_size=32, collate_fn=torch.stack)\n",
        "x = next(iter(dataloader))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.67 ms ± 12.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r 10 -n 100 for x in dataloader: pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        a: Tensor(shape=torch.Size([32, 50, 2]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "    batch_size=torch.Size([32]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "class TensorDictDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitems__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "data  = TensorDictDataset(td)\n",
        "dataloader = DataLoader(data, batch_size=32, collate_fn=lambda x: x)#, collate_fn=torch.stack)\n",
        "x = next(iter(dataloader))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "678 µs ± 1.91 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit for x in dataloader: pass"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apparently, splitting data into dictionaries and creating TensorDicts on the run is the fastest way to load data... but why is it not faster to just index TensorDicts instead? And is there a better way?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
