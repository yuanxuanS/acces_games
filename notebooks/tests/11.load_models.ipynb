{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hak/anaconda3/envs/torch200-py39/lib/python3.9/site-packages/torchrl/__init__.py:26: UserWarning: failed to set start method to spawn, and current start method for mp is fork.\n",
      "  warn(\n",
      "/home/hak/anaconda3/envs/torch200-py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append('../')\n",
    "\n",
    "import torch.nn as nn\n",
    "from rl4co.utils.lightning import load_model_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: {'params': {'total': 692608, 'trainable': 692608, 'non_trainable': 0}}\n"
     ]
    }
   ],
   "source": [
    "problem = 'cvrp'\n",
    "size = '20'\n",
    "model = f'am-{problem}{size}'\n",
    "\n",
    "config = f'../../saved_checkpoints/{problem}{size}/{model}/config.yaml'\n",
    "ckpt = f'../../saved_checkpoints/{problem}{size}/{model}/epoch_099.ckpt'\n",
    "\n",
    "m_cvrp = load_model_from_checkpoint(config, ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: {'params': {'total': 708608, 'trainable': 708608, 'non_trainable': 0}}\n"
     ]
    }
   ],
   "source": [
    "problem = 'tsp'\n",
    "size = '20'\n",
    "model = f'am-{problem}{size}'\n",
    "\n",
    "config = f'../../saved_checkpoints/{problem}{size}/{model}/config.yaml'\n",
    "ckpt = f'../../saved_checkpoints/{problem}{size}/{model}/epoch_099.ckpt'\n",
    "\n",
    "m_tsp = load_model_from_checkpoint(config, ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def transplant_model(source:nn.Module, \n",
    "                     target:nn.Module,\n",
    "                     load_encoder:bool=True,\n",
    "                     load_decoder:bool=True):\n",
    "    source_policy = source.model.policy\n",
    "    target_policy = target.model.policy\n",
    "    \n",
    "    # Transplant encoder's layer except init_embedding\n",
    "    if load_encoder:\n",
    "        source_encoder_params = source_policy.encoder.layers.state_dict()\n",
    "        target_policy.encoder.layers.load_state_dict(source_encoder_params)\n",
    "    \n",
    "    if load_decoder:\n",
    "        source_decoder = source_policy.decoder\n",
    "        target_decoder = target_policy.decoder\n",
    "        iter_ = zip(source_decoder.named_children(),\n",
    "                    target_decoder.named_children())\n",
    "        \n",
    "        for (name, source), (_, target) in iter_:\n",
    "            if name in [\"env\", \"context\", \"dynamic_embedding\"]:\n",
    "                continue\n",
    "\n",
    "            target.load_state_dict(source.state_dict())\n",
    "            \n",
    "    # if load_baseline:\n",
    "        \n",
    "transplant_model(m_tsp, m_cvrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha1 = m_tsp.model.policy.encoder.layers[0][0].state_dict()['module.Wk']\n",
    "mha2 = m_cvrp.model.policy.encoder.layers[0][0].state_dict()['module.Wk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = m_tsp.model.policy.decoder.logit_attention.project_out.state_dict()['weight']\n",
    "w2 = m_cvrp.model.policy.decoder.logit_attention.project_out.state_dict()['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 - w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch200-py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
