{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MatNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "sys.path.append(2*\"../\")\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchrl.modules.models.models import MLP\n",
        "from torchrl.envs import EnvBase\n",
        "from tensordict.tensordict import TensorDict\n",
        "\n",
        "from rl4co.envs import ATSPEnv \n",
        "from rl4co.utils.ops import batchify, unbatchify\n",
        "from rl4co.models.nn.attention import LogitAttention\n",
        "from rl4co.models.nn.utils import decode_probs, get_log_likelihood\n",
        "from rl4co.models.nn.env_context import env_context\n",
        "from rl4co.models.nn.env_embedding import env_dynamic_embedding, env_init_embedding\n",
        "from rl4co.data.dataset import TensorDictCollate"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Differences between AM and MatNet\n",
        "\n",
        "1. MatNet uses a dual graph attention layer for processing the  set of source and destination nodes A and B separately\n",
        "2. Mixed-score attention: this should make the network learn the \"best\" recipe\n",
        "3. Initial node representation: zero-vectors for A nodes and one-hot vectors for B nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorDict(\n",
              "    fields={\n",
              "        action_mask: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.bool, is_shared=False),\n",
              "        cost_matrix: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "        current_node: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
              "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
              "        first_node: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
              "        i: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
              "    batch_size=torch.Size([]),\n",
              "    device=cpu,\n",
              "    is_shared=False)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = ATSPEnv(num_loc=10)\n",
        "env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test out\n",
        "\n",
        "# col_emb.shape: (batch, col_cnt, embedding)\n",
        "# row_emb.shape: (batch, row_cnt, embedding)\n",
        "# cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "batch = 64\n",
        "row_cnt = 20\n",
        "col_cnt = 30\n",
        "\n",
        "\n",
        "model_params = {\n",
        "    'embedding_dim': 256,\n",
        "    'sqrt_embedding_dim': 256**(1/2),\n",
        "    'encoder_layer_num': 5,\n",
        "    'qkv_dim': 16,\n",
        "    'sqrt_qkv_dim': 16**(1/2),\n",
        "    'head_num': 16,\n",
        "    'logit_clipping': 10,\n",
        "    'ff_hidden_dim': 512,\n",
        "    'ms_hidden_dim': 16,\n",
        "    'ms_layer1_init': (1/2)**(1/2),\n",
        "    'ms_layer2_init': (1/16)**(1/2),\n",
        "    'eval_type': 'argmax',\n",
        "    'one_hot_seed_cnt': 20,  # must be >= node_cnt\n",
        "}\n",
        "\n",
        "\n",
        "row_emb = torch.randn(batch, row_cnt, model_params['embedding_dim'])\n",
        "col_emb = torch.randn(batch, col_cnt, model_params['embedding_dim'])\n",
        "cost_mat = torch.randn(batch, row_cnt, col_cnt)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ours (all we need)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MixedScoreMHA(nn.Module):\n",
        "    def __init__(self, \n",
        "                    embed_dim,\n",
        "                    num_heads,\n",
        "                    hidden_dim: int = 16,\n",
        "                    qkv_dim: int = 16,\n",
        "                    bias=False,\n",
        "                    layer1_init: float = (1/2)**(1/2),\n",
        "                    layer2_init: float = (1/16)**(1/2),\n",
        "                    device=None,\n",
        "                    dtype=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        assert (embed_dim % num_heads == 0), \"embed_dim must be divisible by num_heads\"\n",
        "        self.num_heads = num_heads\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Project\n",
        "        self.Wq = nn.Linear(embed_dim, num_heads*qkv_dim, bias=bias, **factory_kwargs)\n",
        "        self.Wk = nn.Linear(embed_dim, num_heads*qkv_dim, bias=bias, **factory_kwargs)\n",
        "        self.Wv = nn.Linear(embed_dim, num_heads*qkv_dim, bias=bias, **factory_kwargs)\n",
        "        self.out_proj = nn.Linear(num_heads*qkv_dim, embed_dim, **factory_kwargs)\n",
        "\n",
        "        # Init mix params\n",
        "        self.mix1_weight = nn.Parameter(torch.empty(num_heads, 2, hidden_dim).uniform_(-layer1_init, layer1_init))\n",
        "        self.mix1_bias = nn.Parameter(torch.empty(num_heads, hidden_dim).uniform_(-layer1_init, layer1_init))\n",
        "        self.mix2_weight = nn.Parameter(torch.empty(num_heads, hidden_dim, 1).uniform_(-layer2_init, layer2_init))\n",
        "        self.mix2_bias = nn.Parameter(torch.empty(num_heads, 1).uniform_(-layer2_init, layer2_init))\n",
        "\n",
        "    def forward(self, q, k, v, matrix):\n",
        "        # Project q, k, v and reshape to [batch, head_num, row_cnt, hidden_dim]\n",
        "        # q, k, v = self.Wq(q), self.Wk(k), self.Wv(v)\n",
        "        # q, k, v = map(lambda t: self._reshape_heads(t), (q, k, v))\n",
        "        q = self._make_heads(self.Wq(q))\n",
        "        k = self._make_heads(self.Wk(k))\n",
        "        v = self._make_heads(self.Wv(v))\n",
        "\n",
        "        # Prepare dot product and matrix score: [batch, head_num, row_cnt, col_cnt]\n",
        "        dot_product = torch.einsum('...rd,...cd->...rc', q, k) / math.sqrt(q.shape[-1])\n",
        "        matrix_score = repeat(matrix, 'b r c -> b h r c', h=self.num_heads)\n",
        "\n",
        "        # Mix the scores. Use einsum for best performance\n",
        "        two_scores = torch.stack((dot_product, matrix_score), dim=-1)\n",
        "        ms1 = torch.einsum('bhrct,htd->brhcd', two_scores, self.mix1_weight)\n",
        "        ms2 = torch.einsum('brhcd,hdt->brhct', F.relu(ms1), self.mix2_weight)\n",
        "        mixed_scores = rearrange(ms2, 'b h r c 1 -> b r h c')\n",
        "\n",
        "        # Softmax and multiply with values\n",
        "        weights = F.softmax(mixed_scores, dim=3)\n",
        "        out = torch.matmul(weights, v)\n",
        "        \n",
        "        # Project out\n",
        "        out = rearrange(out, 'b h r d -> b r (h d)')\n",
        "        return self.out_proj(out)\n",
        "\n",
        "    def _make_heads(self, x):\n",
        "        return rearrange(x, \"b g (h s) -> b h g s\", h=self.num_heads)\n",
        "         \n",
        "    \n",
        "class AddAndInstanceNormalization(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.norm = nn.InstanceNorm1d(embedding_dim, affine=True, track_running_stats=False)\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # [batch, problem, embedding]\n",
        "        added = input1 + input2\n",
        "        normalized = self.norm(added.transpose(1, 2)).transpose(1, 2)\n",
        "        return normalized\n",
        "    \n",
        "class EncodingBlock(nn.Module):\n",
        "    def __init__(self,\n",
        "                    embed_dim,\n",
        "                    num_heads,\n",
        "                    ms_hidden_dim=16,\n",
        "                    ff_hidden_dim=512,\n",
        "                    **mha_kwargs\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.mixed_score_mha = MixedScoreMHA(embed_dim, num_heads, ms_hidden_dim, **mha_kwargs)\n",
        "        self.add_n_normalization_1 = AddAndInstanceNormalization(embed_dim)\n",
        "        self.feed_forward = MLP(embed_dim, embed_dim, 1, ff_hidden_dim, activation_class=nn.ReLU)\n",
        "        self.add_n_normalization_2 = AddAndInstanceNormalization(embed_dim)\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        q, k, v = row_emb, col_emb, col_emb\n",
        "        out_mha = self.mixed_score_mha(q, k, v, cost_mat)\n",
        "        out1 = self.add_n_normalization_1(row_emb, out_mha)\n",
        "        out2 = self.feed_forward(out1)\n",
        "        out3 = self.add_n_normalization_2(out1, out2)\n",
        "        return out3 # shape: (batch, row_cnt, embedding)\n",
        "    \n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__()\n",
        "        self.row_encoding_block = EncodingBlock(**kw)\n",
        "        self.col_encoding_block = EncodingBlock(**kw)\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        # row_emb.shape: (batch, row_cnt, embedding)\n",
        "        # col_emb.shape: (batch, col_cnt, embedding)\n",
        "        # cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "        row_emb_out = self.row_encoding_block(row_emb, col_emb, cost_mat)\n",
        "        col_emb_out = self.col_encoding_block(col_emb, row_emb, cost_mat.transpose(1, 2))\n",
        "        return row_emb_out, col_emb_out\n",
        "        \n",
        "\n",
        "class MatNetEncoder(nn.Module):\n",
        "    def __init__(self, num_layers, **kw):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([EncoderLayer(**kw) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        for layer in self.layers:\n",
        "            row_emb, col_emb = layer(row_emb, col_emb, cost_mat)\n",
        "        return row_emb, col_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 5.27 MB\n",
            "torch.Size([64, 20, 256]) torch.Size([64, 30, 256])\n"
          ]
        }
      ],
      "source": [
        "# encoder = MatNetEncoder(**model_params)\n",
        "\n",
        "encoder = MatNetEncoder(num_layers=5, embed_dim=256, num_heads=16)\n",
        "print('Number of parameters: {:.2f} MB'.format(sum(p.numel() for p in encoder.parameters() if p.requires_grad) / 1e6))\n",
        "out = encoder(row_emb, col_emb, cost_mat)\n",
        "print(out[0].shape, out[1].shape)\n",
        "#print number of parameters\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_start_nodes(batch_size, num_nodes, device=\"cpu\"):\n",
        "    \"\"\"Node selection strategy for POMO\n",
        "    Selects different start nodes for each batch element\n",
        "    \"\"\"\n",
        "    selected = torch.arange(num_nodes, device=device).repeat(batch_size)  # TODO: check\n",
        "    return selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class PrecomputedCache:\n",
        "    row_embeddings: torch.Tensor\n",
        "    # graph_context: torch.Tensor # TODO: check if used in MatNet\n",
        "    glimpse_key: torch.Tensor\n",
        "    glimpse_val: torch.Tensor\n",
        "    logit_key: torch.Tensor\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, env, embedding_dim, num_heads, num_pomo=20, **logit_attn_kwargs):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.env = env\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        assert embedding_dim % num_heads == 0\n",
        "\n",
        "        self.context = env_context(self.env.name, {\"embedding_dim\": embedding_dim})\n",
        "        self.dynamic_embedding = env_dynamic_embedding(\n",
        "            self.env.name, {\"embedding_dim\": embedding_dim}\n",
        "        )\n",
        "\n",
        "        # For each node we compute (glimpse key, glimpse value ) so 2 * embedding_dim\n",
        "        # In original implementation, this is separated but this is the same\n",
        "        # Note that compared to original AM, we do not project the logit key\n",
        "        self.project_node_embeddings = nn.Linear(\n",
        "            embedding_dim, 2 * embedding_dim, bias=False\n",
        "        )\n",
        "    \n",
        "        self.project_fixed_context = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
        "\n",
        "        # MHA\n",
        "        self.logit_attention = LogitAttention(\n",
        "            embedding_dim, num_heads, **logit_attn_kwargs\n",
        "        )\n",
        "\n",
        "        # POMO\n",
        "        self.num_pomo = max(num_pomo, 1) # POMO = 1 is just normal REINFORCE\n",
        "\n",
        "    def forward(self, td, embeddings, decode_type=\"sampling\"):\n",
        "        # Collect outputs\n",
        "        outputs = []\n",
        "        actions = []\n",
        " \n",
        "\n",
        "        if self.num_pomo > 1:\n",
        "            # POMO: first action is decided via select_start_nodes\n",
        "            action = select_start_nodes(batch_size=td.shape[0], num_nodes=self.num_pomo, device=td.device)\n",
        "\n",
        "            # # Expand td to batch_size * num_pomo\n",
        "            td = batchify(td, self.num_pomo)\n",
        "\n",
        "            td.set(\"action\", action)\n",
        "            td = self.env.step(td)[\"next\"]\n",
        "            log_p = torch.zeros_like(td['action_mask'], device=td.device) # first log_p is 0, so p = log_p.exp() = 1\n",
        "\n",
        "            outputs.append(log_p.squeeze(1))\n",
        "            actions.append(action)\n",
        "        \n",
        "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
        "        cached_embeds = self._precompute(embeddings)      \n",
        "        \n",
        "        # Here we suppose all the batch is done at the same time\n",
        "        while not td[\"done\"].all():  \n",
        "            # Compute the logits for the next node\n",
        "            log_p, mask = self._get_log_p(cached_embeds, td)\n",
        "\n",
        "            # Select the indices of the next nodes in the sequences, result (batch_size) long\n",
        "            action = decode_probs(\n",
        "                log_p.exp().squeeze(1), mask.squeeze(1), decode_type=decode_type\n",
        "            )\n",
        "\n",
        "            # Step the environment\n",
        "            td.set(\"action\", action)\n",
        "            td = self.env.step(td)[\"next\"]\n",
        "\n",
        "            # Collect output of step\n",
        "            outputs.append(log_p.squeeze(1))\n",
        "            actions.append(action)\n",
        "\n",
        "        outputs, actions = torch.stack(outputs, 1), torch.stack(actions, 1)\n",
        "        td.set(\"reward\", self.env.get_reward(td, actions))\n",
        "        return outputs, actions, td\n",
        "    \n",
        "    def _precompute(self, embeddings):       \n",
        "        # The projection of the node embeddings for the attention is calculated once up front\n",
        "        row_embed, col_embed = embeddings\n",
        "    \n",
        "        (\n",
        "            glimpse_key_fixed,\n",
        "            glimpse_val_fixed,\n",
        "        ) = self.project_node_embeddings(col_embed).chunk(2, dim=-1)\n",
        "\n",
        "\n",
        "        # Organize in a dataclass for easy access\n",
        "        cached_embeds = PrecomputedCache(\n",
        "            row_embeddings=batchify(row_embed, self.num_pomo),\n",
        "            glimpse_key=batchify(glimpse_key_fixed, self.num_pomo),\n",
        "            glimpse_val=batchify(glimpse_val_fixed, self.num_pomo),\n",
        "            logit_key=batchify(col_embed, self.num_pomo),\n",
        "        )\n",
        "\n",
        "        return cached_embeds\n",
        "\n",
        "    def _get_log_p(self, cached, td):\n",
        "        # Compute the query based on the context (computes automatically the first and last node context)\n",
        "        step_context = self.context(cached.row_embeddings, td)\n",
        "        glimpse_q = step_context.unsqueeze(1)  # TODO check in POMO, no graph context (trick for overfit) # [batch, 1, embed_dim] # TODO: check if this is the same as POMO\n",
        "\n",
        "        # Compute keys and values for the nodes\n",
        "        glimpse_key_dynamic, glimpse_val_dynamic, logit_key_dynamic = self.dynamic_embedding(td)\n",
        "        glimpse_k = cached.glimpse_key + glimpse_key_dynamic\n",
        "        glimpse_v = cached.glimpse_val + glimpse_val_dynamic\n",
        "        logit_k = cached.logit_key + logit_key_dynamic\n",
        "\n",
        "        # Get the mask\n",
        "        mask = ~td[\"action_mask\"]\n",
        "\n",
        "        # Compute logits\n",
        "        log_p = self.logit_attention(glimpse_q, glimpse_k, glimpse_v, logit_k, mask)\n",
        "\n",
        "        return log_p, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MatNetInitEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_dim, one_hot_seed_cnt):\n",
        "        super(MatNetInitEmbedding, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.one_hot_seed_cnt = one_hot_seed_cnt\n",
        "\n",
        "    def forward(self, td):\n",
        "        # Generate initial embeddings: [batch, node, node]\n",
        "        cost_mat = td[\"cost_matrix\"]\n",
        "        batch_size = cost_mat.size(0)\n",
        "        node_cnt = cost_mat.size(1)\n",
        "        row_emb = torch.zeros((batch_size, node_cnt, self.embedding_dim), device=cost_mat.device)\n",
        "        col_emb = torch.zeros((batch_size, node_cnt, self.embedding_dim), device=cost_mat.device)\n",
        "        # randomize col_emb: we refactor with topk\n",
        "        rand = torch.rand(batch_size, self.one_hot_seed_cnt, device=cost_mat.device)\n",
        "        _, rand_idx = rand.topk(node_cnt, dim=1, largest=False)\n",
        "        b_idx, n_idx = torch.meshgrid(torch.arange(batch_size, device=cost_mat.device),\n",
        "                                    torch.arange(node_cnt, device=cost_mat.device))\n",
        "        col_emb[b_idx, n_idx, rand_idx] = 1\n",
        "        return row_emb, col_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([100, 50, 128]), torch.Size([100, 50, 128]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding = MatNetInitEmbedding(128, 50)\n",
        "\n",
        "td = TensorDict({\"cost_matrix\": torch.randn(100, 50, 50)}, batch_size=100)\n",
        "a, b = embedding(td)\n",
        "a.shape, b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MatNetPolicy(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        env: EnvBase,\n",
        "        encoder: nn.Module = None,\n",
        "        decoder: nn.Module = None,\n",
        "        embedding_dim: int = 256,\n",
        "        num_pomo: int = 10,\n",
        "        one_hot_seed_cnt: int = 20,\n",
        "        num_encode_layers: int = 5,\n",
        "        num_heads: int = 16,\n",
        "        mask_inner: bool = True,\n",
        "        train_decode_type: str = \"sampling\",\n",
        "        val_decode_type: str = \"greedy\",\n",
        "        test_decode_type: str = \"greedy\",\n",
        "        **unused_kwargs\n",
        "    ):\n",
        "        super(MatNetPolicy, self).__init__()\n",
        "\n",
        "        if len(unused_kwargs) > 0:\n",
        "            print(\"Unused kwargs found in MatNetPolicy init: \", unused_kwargs)\n",
        "\n",
        "        self.env = env\n",
        "\n",
        "        self.init_embedding = MatNetInitEmbedding(embedding_dim, one_hot_seed_cnt)\n",
        "\n",
        "        self.encoder = (\n",
        "            MatNetEncoder(\n",
        "                num_heads=num_heads,\n",
        "                embed_dim=embedding_dim,\n",
        "                num_layers=num_encode_layers,\n",
        "            )\n",
        "            if encoder is None\n",
        "            else encoder\n",
        "        )\n",
        "\n",
        "        self.decoder = (\n",
        "            Decoder(\n",
        "                env,\n",
        "                embedding_dim,\n",
        "                num_heads,\n",
        "                num_pomo=num_pomo,\n",
        "                mask_inner=mask_inner,\n",
        "            )\n",
        "            if decoder is None\n",
        "            else decoder\n",
        "        )\n",
        "        self.num_pomo = num_pomo\n",
        "        self.train_decode_type = train_decode_type\n",
        "        self.val_decode_type = val_decode_type\n",
        "        self.test_decode_type = test_decode_type\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        td: TensorDict,\n",
        "        phase: str = \"train\",\n",
        "        return_actions: bool = False,\n",
        "        **decoder_kwargs,\n",
        "    ) -> TensorDict:\n",
        "        \"\"\"Given observation, precompute embeddings and rollout\"\"\"\n",
        "\n",
        "        # Set decoding type for policy, can be also greedy\n",
        "        row_emb, col_emb = self.init_embedding(td)\n",
        "        encoded_inputs = self.encoder(row_emb, col_emb, td[\"cost_matrix\"])\n",
        "        \n",
        "        # Get decode type depending on phase\n",
        "        if decoder_kwargs.get(\"decode_type\", None) is None:\n",
        "            decoder_kwargs[\"decode_type\"] = getattr(self, f\"{phase}_decode_type\")\n",
        "\n",
        "        # Main rollout\n",
        "        log_p, actions, td = self.decoder(td, encoded_inputs, **decoder_kwargs)\n",
        "\n",
        "        # Log likelyhood is calculated within the model since returning it per action does not work well with\n",
        "        ll = get_log_likelihood(log_p, actions, td.get(\"mask\", None))\n",
        "        out = {\n",
        "            \"reward\": td[\"reward\"],\n",
        "            \"log_likelihood\": ll,\n",
        "            \"actions\": actions if return_actions else None,\n",
        "        }\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test policy only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'reward': tensor([-3.8764, -3.8805, -3.7429,  ..., -3.4783, -3.3634, -4.2051],\n",
            "       device='cuda:0'), 'log_likelihood': tensor([-32.3867, -34.4745, -32.3190,  ..., -39.6832, -32.7075, -31.2971],\n",
            "       device='cuda:0', grad_fn=<SumBackward1>), 'actions': None}\n"
          ]
        }
      ],
      "source": [
        "env = ATSPEnv(num_loc=20)\n",
        "env.name = \"tsp\" # TODO: make this automatic when creating env\n",
        "\n",
        "dataset = env.dataset(batch_size=[10000])\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,  # no need to shuffle, we're resampling every epoch\n",
        "    num_workers=0,\n",
        "    collate_fn=TensorDictCollate(),\n",
        ")\n",
        "\n",
        "policy = MatNetPolicy(\n",
        "    env,\n",
        "    num_pomo=20,\n",
        ").to(\"cuda\")\n",
        "\n",
        "# model = torch.compile(model)\n",
        "\n",
        "td = next(iter(dataloader)).to(\"cuda\")\n",
        "td = env.reset(td)\n",
        "\n",
        "out = policy(td, decode_type=\"sampling\")\n",
        "\n",
        "print(out)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create full MatNet: `env` + `policy` + `baseline`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Any, Optional, Tuple, Union\n",
        "\n",
        "import lightning as L\n",
        "\n",
        "from rl4co.utils.lightning import get_lightning_device\n",
        "from rl4co.models.rl.reinforce import WarmupBaseline, RolloutBaseline, ExponentialBaseline, SharedBaseline\n",
        "from rl4co.models.zoo.pomo.utils import get_best_actions\n",
        "from rl4co.data.dataset import TensorDictDataset\n",
        "\n",
        "\n",
        "class MatNet(nn.Module):\n",
        "    def __init__(self, env, policy=None, baseline=None):\n",
        "        super().__init__()\n",
        "        self.env = env\n",
        "        self.policy = MatNetPolicy(env) if policy is None else policy\n",
        "        self.baseline = SharedBaseline() if baseline is None else baseline\n",
        "        # self.baseline = WarmupBaseline(RolloutBaseline()) if baseline is None else baseline\n",
        "        self.num_pomo = self.policy.num_pomo\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        td: TensorDict,\n",
        "        phase: str = \"train\",\n",
        "        decode_type: str = \"sampling\",\n",
        "        return_actions: bool = False,\n",
        "    ):\n",
        "        \"\"\"Evaluate model, get costs and log probabilities and compare with baseline\"\"\"\n",
        "\n",
        "        # Evaluate model, get costs and log probabilities\n",
        "        out = self.policy(td, decode_type=decode_type, return_actions=return_actions)\n",
        "\n",
        "        # Max POMO reward [batch, num_pomo]\n",
        "        reward = unbatchify(out[\"reward\"], self.num_pomo,)\n",
        "        max_reward, max_idxs = reward.max(dim=1)\n",
        "        out.update(\n",
        "            {\n",
        "                \"max_reward\": max_reward,\n",
        "                \"best_actions\": get_best_actions(out[\"actions\"], max_idxs)\n",
        "                if return_actions\n",
        "                else None,\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if phase == \"train\":\n",
        "            costs = unbatchify(-out[\"reward\"], self.policy.num_pomo)\n",
        "            ll = unbatchify(out[\"log_likelihood\"], self.policy.num_pomo)\n",
        "            bl_val, bl_loss = self.baseline.eval(td, costs)\n",
        "\n",
        "            # Calculate REINFORCE loss\n",
        "            advantage = costs - bl_val\n",
        "            reinforce_loss = (advantage * ll).mean()\n",
        "            loss = reinforce_loss + bl_loss\n",
        "            out.update(\n",
        "                {\n",
        "                    \"loss\": loss,\n",
        "                    \"reinforce_loss\": reinforce_loss,\n",
        "                    \"bl_loss\": bl_loss,\n",
        "                    \"bl_val\": bl_val,\n",
        "                }\n",
        "            )\n",
        "\n",
        "        return out\n",
        "\n",
        "    def setup(self, lit_module):\n",
        "        # Make baseline taking model itself and train_dataloader from model as input\n",
        "        self.baseline.setup(\n",
        "            self.policy,\n",
        "            lit_module.val_dataloader(),\n",
        "            self.env,\n",
        "            device=get_lightning_device(lit_module),\n",
        "        )\n",
        "\n",
        "    def on_train_epoch_end(self, lit_module):\n",
        "        self.baseline.epoch_callback(\n",
        "            self.policy,\n",
        "            lit_module.val_dataloader(),\n",
        "            lit_module.current_epoch,\n",
        "            self.env,\n",
        "            device=get_lightning_device(lit_module),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'reward': tensor([-3.4833, -4.0503, -3.7302,  ..., -3.4266, -3.5680, -3.8304],\n",
            "       device='cuda:0'), 'log_likelihood': tensor([-33.3946, -36.6741, -35.4177,  ..., -38.5814, -36.5290, -35.7415],\n",
            "       device='cuda:0', grad_fn=<SumBackward1>), 'actions': None, 'max_reward': tensor([-3.2624, -3.1658, -3.3551, -3.6487, -2.8194, -3.6433, -3.0511, -3.3108,\n",
            "        -2.3023, -2.9610, -2.3308, -3.0961, -3.4044, -3.0073, -2.6106, -2.3959,\n",
            "        -3.6710, -3.5016, -3.2650, -2.5826, -2.1744, -3.1541, -3.0656, -3.6812,\n",
            "        -3.1330, -2.9431, -2.9945, -3.4661, -2.7532, -3.2616, -2.9546, -3.8312,\n",
            "        -3.3108, -3.3512, -2.8004, -3.2813, -4.2569, -2.4225, -3.8343, -3.6446,\n",
            "        -3.4028, -2.5493, -2.8171, -2.6127, -3.1835, -4.3616, -3.2950, -3.4235,\n",
            "        -2.6913, -3.2220, -2.9644, -3.2457, -3.8106, -4.2216, -2.8878, -2.9706,\n",
            "        -2.7781, -3.6095, -2.9931, -2.7426, -3.1610, -2.8864, -3.3325, -3.6092],\n",
            "       device='cuda:0'), 'best_actions': None, 'loss': tensor(0.0092, device='cuda:0', grad_fn=<AddBackward0>), 'reinforce_loss': tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>), 'bl_loss': 0, 'bl_val': tensor([[3.6268, 3.5677, 3.6895, 3.6826, 3.6297, 3.6186, 3.6465, 3.6584, 3.5767,\n",
            "         3.6587, 3.5489, 3.6565, 3.6628, 3.5815, 3.6630, 3.6332, 3.6011, 3.5864,\n",
            "         3.6920, 3.6157]], device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = MatNet(\n",
        "    env,\n",
        "    policy,\n",
        "    # baseline=baseline,\n",
        ").to(\"cuda\")\n",
        "\n",
        "\n",
        "td = next(iter(dataloader)).to(\"cuda\")\n",
        "td = env.reset(td)\n",
        "\n",
        "out = model(td, decode_type=\"sampling\")\n",
        "\n",
        "print(out)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics = {}\n",
        "not(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RL4COLitModule(L.LightningModule):\n",
        "    def __init__(self, env, model, cfg):\n",
        "        \"\"\"\n",
        "        Base LightningModule for Neural Combinatorial Optimization\n",
        "        If model_cfg is passed, it will take precedence over cfg.model\n",
        "        Likewise for env_cfg\n",
        "        \n",
        "        NOTE: simplified not to use Hydra instantiate here\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        # this line ensures params passed to LightningModule will be saved to ckpt\n",
        "        # it also allows to access params with 'self.hparams' attribute\n",
        "        self.save_hyperparameters(cfg)\n",
        "        self.cfg = cfg\n",
        "        self.env = env\n",
        "        self.model = model\n",
        "        self.instantiate_metrics()\n",
        "\n",
        "    def instantiate_metrics(self):\n",
        "        \"\"\"Dictionary of metrics to be logged at each phase\"\"\"\n",
        "        self.train_metrics = self.cfg.metrics.get(\"train\", [\"loss\", \"reward\"])\n",
        "        self.val_metrics = self.cfg.metrics.get(\"val\", [\"reward\"])\n",
        "        self.test_metrics = self.cfg.metrics.get(\"test\", [\"reward\"])\n",
        "        self.log_on_step = self.cfg.metrics.get(\"log_on_step\", True)\n",
        "\n",
        "\n",
        "    def setup(self, stage=\"fit\"):\n",
        "        self.train_dataset = self.env.dataset(self.cfg.data.train_size, \"train\")\n",
        "        self.val_dataset = self.env.dataset(self.cfg.data.val_size, \"val\")\n",
        "        test_size = self.cfg.data.get(\"test_size\", self.cfg.data.val_size)\n",
        "        self.test_dataset = self.env.dataset(test_size, \"test\")\n",
        "        if hasattr(self.model, \"setup\"):\n",
        "            self.model.setup(self)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        parameters = (\n",
        "            self.parameters()\n",
        "        )  # this will train task specific parameters such as Retrieval head for AAN\n",
        "        optimizer = torch.optim.Adam(\n",
        "            parameters, lr=self.cfg.optim.lr, weight_decay=self.cfg.optim.weight_decay\n",
        "        )\n",
        "        return [optimizer] # NOTE: for simplicity we do not include the scheduler here\n",
        "    \n",
        "    def shared_step(self, batch: Any, batch_idx: int, phase: str):\n",
        "        td = self.env.reset(batch)\n",
        "        out = self.model(td, phase)\n",
        "        # Log metrics\n",
        "        metrics = getattr(self, f\"{phase}_metrics\")\n",
        "        metrics = {f\"{phase}/{k}\": v.mean() for k, v in out.items() if k in metrics}\n",
        "        self.log_dict(\n",
        "            metrics,\n",
        "            on_step=self.log_on_step,\n",
        "            on_epoch=True,\n",
        "            prog_bar=True,\n",
        "            sync_dist=True,\n",
        "        )\n",
        "\n",
        "        return {\"loss\": out.get(\"loss\", None)}\n",
        "\n",
        "    def training_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase=\"train\")\n",
        "\n",
        "    def validation_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase=\"val\")\n",
        "\n",
        "    def test_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase=\"test\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self._dataloader(self.train_dataset)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self._dataloader(self.val_dataset)\n",
        "    \n",
        "    def test_dataloader(self):\n",
        "        return self._dataloader(self.test_dataset)\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        if hasattr(self.model, \"on_train_epoch_end\"):\n",
        "            self.model.on_train_epoch_end(self)\n",
        "        self.train_dataset = self.env.dataset(self.cfg.data.train_size, \"train\")\n",
        "\n",
        "    def _dataloader(self, dataset):\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.cfg.data.batch_size,\n",
        "            shuffle=False,  # no need to shuffle, we're resampling every epoch\n",
        "            num_workers=self.cfg.data.get(\"num_workers\", 0),\n",
        "            collate_fn=TensorDictCollate(),\n",
        "        )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from omegaconf import OmegaConf, DictConfig\n",
        "\n",
        "config = DictConfig(\n",
        "    {\n",
        "        \"data\": {\n",
        "            \"train_size\": 100000, # with 1 epochs, this is 1k samples\n",
        "            \"val_size\": 10000, \n",
        "            \"batch_size\": 64, #64,\n",
        "        },\n",
        "        \"optim\": {\n",
        "            \"lr\": 4e-4,\n",
        "            \"weight_decay\": 1e-6,\n",
        "        },\n",
        "        \"metrics\": {\n",
        "            \"train\": [\"loss\", \"reward\"],\n",
        "            \"val\": [\"reward\"],\n",
        "            \"test\": [\"reward\"],\n",
        "            \"log_on_step\": True,\n",
        "        },\n",
        "        \n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "lit_module = RL4COLitModule(env, model, config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type    | Params\n",
            "----------------------------------\n",
            "0 | env   | ATSPEnv | 0     \n",
            "1 | model | MatNet  | 5.7 M \n",
            "----------------------------------\n",
            "5.7 M     Trainable params\n",
            "0         Non-trainable params\n",
            "5.7 M     Total params\n",
            "22.670    Total estimated model params size (MB)\n",
            "2023-05-16 15:24:43.134228: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-05-16 15:24:43.150439: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-16 15:24:43.523837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:  27%|██▋       | 419/1563 [00:23<01:03, 18.03it/s, v_num=7, train/reward_step=-3.46, train/loss_step=-.00971] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "# Trick to make calculations faster\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "\n",
        "# Trainer\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=10, # 10\n",
        "    accelerator=\"gpu\",\n",
        "    logger=None, # can replace with WandbLogger, TensorBoardLogger, etc.\n",
        "    precision=\"16-mixed\", # Lightning will handle casting to float16\n",
        "    log_every_n_steps=1,   \n",
        "    gradient_clip_val=1.0, # clip gradients to avoid exploding gradients!\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "trainer.fit(lit_module)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
