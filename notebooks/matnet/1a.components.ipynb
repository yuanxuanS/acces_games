{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MatNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "sys.path.append(2*\"../\")\n",
        "\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "from typing import Optional\n",
        "\n",
        "from rl4co.envs import TSPEnv, ATSPEnv \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Differences between AM and MatNet\n",
        "\n",
        "1. MatNet uses a dual graph attention layer for processing the  set of source and destination nodes A and B separately\n",
        "2. Mixed-score attention: this should make the network learn the \"best\" recipe\n",
        "3. Initial node representation: zero-vectors for A nodes and one-hot vectors for B nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorDict(\n",
              "    fields={\n",
              "        action_mask: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.bool, is_shared=False),\n",
              "        cost_matrix: Tensor(shape=torch.Size([10, 10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "        current_node: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
              "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
              "        first_node: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
              "        i: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
              "    batch_size=torch.Size([]),\n",
              "    device=cpu,\n",
              "    is_shared=False)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = ATSPEnv(num_loc=10)\n",
        "env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "batch_size = 128\n",
        "head_num = 8\n",
        "row_cnt = 30\n",
        "col_cnt = 20\n",
        "qkv_dim = 64\n",
        "\n",
        "q = torch.randn(batch_size, head_num, row_cnt, qkv_dim)\n",
        "k = torch.randn(batch_size, head_num, col_cnt, qkv_dim)\n",
        "v = torch.randn(batch_size, head_num, col_cnt, qkv_dim)\n",
        "cost_mat = torch.randn(batch_size, row_cnt, col_cnt)\n",
        "\n",
        "model_params = {\n",
        "        'head_num': head_num,\n",
        "        'qkv_dim': qkv_dim,\n",
        "        'sqrt_qkv_dim': qkv_dim**(1/2),\n",
        "        'ms_hidden_dim': 16,\n",
        "        'ms_layer1_init': (1/2)**(1/2),\n",
        "        'ms_layer2_init': (1/16)**(1/2)\n",
        "        }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MixedScore MHA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class MixedScore_MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, **model_params):\n",
        "        super().__init__()\n",
        "        self.model_params = model_params\n",
        "\n",
        "        head_num = model_params['head_num']\n",
        "        ms_hidden_dim = model_params['ms_hidden_dim']\n",
        "        mix1_init = model_params['ms_layer1_init']\n",
        "        mix2_init = model_params['ms_layer2_init']\n",
        "\n",
        "        mix1_weight = torch.torch.distributions.Uniform(low=-mix1_init, high=mix1_init).sample((head_num, 2, ms_hidden_dim))\n",
        "        mix1_bias = torch.torch.distributions.Uniform(low=-mix1_init, high=mix1_init).sample((head_num, ms_hidden_dim))\n",
        "        self.mix1_weight = nn.Parameter(mix1_weight)\n",
        "        # shape: (head, 2, ms_hidden)\n",
        "        self.mix1_bias = nn.Parameter(mix1_bias)\n",
        "        # shape: (head, ms_hidden)\n",
        "\n",
        "        mix2_weight = torch.torch.distributions.Uniform(low=-mix2_init, high=mix2_init).sample((head_num, ms_hidden_dim, 1))\n",
        "        mix2_bias = torch.torch.distributions.Uniform(low=-mix2_init, high=mix2_init).sample((head_num, 1))\n",
        "        self.mix2_weight = nn.Parameter(mix2_weight)\n",
        "        # shape: (head, ms_hidden, 1)\n",
        "        self.mix2_bias = nn.Parameter(mix2_bias)\n",
        "        # shape: (head, 1)\n",
        "\n",
        "    def forward(self, q, k, v, cost_mat):\n",
        "        # q shape: (batch, head_num, row_cnt, qkv_dim)\n",
        "        # k,v shape: (batch, head_num, col_cnt, qkv_dim)\n",
        "        # cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "\n",
        "        batch_size = q.size(0)\n",
        "        row_cnt = q.size(2)\n",
        "        col_cnt = k.size(2)\n",
        "\n",
        "        head_num = self.model_params['head_num']\n",
        "        qkv_dim = self.model_params['qkv_dim']\n",
        "        sqrt_qkv_dim = self.model_params['sqrt_qkv_dim']\n",
        "\n",
        "        dot_product = torch.matmul(q, k.transpose(2, 3))\n",
        "        # shape: (batch, head_num, row_cnt, col_cnt)\n",
        "\n",
        "        dot_product_score = dot_product / sqrt_qkv_dim\n",
        "        # shape: (batch, head_num, row_cnt, col_cnt)\n",
        "\n",
        "        cost_mat_score = cost_mat[:, None, :, :].expand(batch_size, head_num, row_cnt, col_cnt)\n",
        "        # shape: (batch, head_num, row_cnt, col_cnt)\n",
        "\n",
        "        two_scores = torch.stack((dot_product_score, cost_mat_score), dim=4)\n",
        "        # shape: (batch, head_num, row_cnt, col_cnt, 2)\n",
        "\n",
        "        two_scores_transposed = two_scores.transpose(1,2)\n",
        "        # shape: (batch, row_cnt, head_num, col_cnt, 2)\n",
        "\n",
        "        ms1 = torch.matmul(two_scores_transposed, self.mix1_weight)\n",
        "        # shape: (batch, row_cnt, head_num, col_cnt, ms_hidden_dim)\n",
        "\n",
        "        ms1 = ms1 + self.mix1_bias[None, None, :, None, :]\n",
        "        # shape: (batch, row_cnt, head_num, col_cnt, ms_hidden_dim)\n",
        "\n",
        "        ms1_activated = F.relu(ms1)\n",
        "\n",
        "        ms2 = torch.matmul(ms1_activated, self.mix2_weight)\n",
        "        # shape: (batch, row_cnt, head_num, col_cnt, 1)\n",
        "\n",
        "        ms2 = ms2 + self.mix2_bias[None, None, :, None, :]\n",
        "        # shape: (batch, row_cnt, head_num, col_cnt, 1)\n",
        "\n",
        "        mixed_scores = ms2.transpose(1,2)\n",
        "        # shape: (batch, head_num, row_cnt, col_cnt, 1)\n",
        "\n",
        "        mixed_scores = mixed_scores.squeeze(4)\n",
        "        # shape: (batch, head_num, row_cnt, col_cnt)\n",
        "\n",
        "        weights = nn.Softmax(dim=3)(mixed_scores)\n",
        "        # shape: (batch, head_num, row_cnt, col_cnt)\n",
        "\n",
        "        out = torch.matmul(weights, v)\n",
        "        # shape: (batch, head_num, row_cnt, qkv_dim)\n",
        "\n",
        "        out_transposed = out.transpose(1, 2)\n",
        "        # shape: (batch, row_cnt, head_num, qkv_dim)\n",
        "\n",
        "        out_concat = out_transposed.reshape(batch_size, row_cnt, head_num * qkv_dim)\n",
        "        # shape: (batch, row_cnt, head_num*qkv_dim)\n",
        "\n",
        "        return out_concat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 30, 512])\n",
            "520\n"
          ]
        }
      ],
      "source": [
        "# make axamples with\n",
        "       # q shape: (batch, head_num, row_cnt, AddAndInstanceNormalizationnt, qkv_dim)\n",
        "        # cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "\n",
        "ms_mha_old = MixedScore_MultiHeadAttention(**model_params)\n",
        "out = ms_mha_old(q, k, v, cost_mat)\n",
        "print(out.shape)\n",
        "\n",
        "# Get num of params\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(count_parameters(ms_mha_old))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12.5 ms ± 318 µs per loop (mean ± std. dev. of 5 runs, 20 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r 5 -n 20 ms_mha_old(q, k, v, cost_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from einops import rearrange, repeat\n",
        "import math\n",
        "\n",
        "\n",
        "class MixedScoreMHA_noweights(nn.Module):\n",
        "    def __init__(self, \n",
        "                 head_num: int, \n",
        "                 ms_hidden_dim: int = 16,\n",
        "                 ms_layer1_init: float = (1/2)**(1/2),\n",
        "                 ms_layer2_init: float = (1/16)**(1/2),\n",
        "                **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.head_num = head_num\n",
        "        self.ms_hidden_dim = ms_hidden_dim\n",
        "        self.qkv_dim = qkv_dim\n",
        "        self.sqrt_qkv_dim = int(math.sqrt(qkv_dim))\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.mix1_weight = nn.Parameter(torch.empty(head_num, 2, ms_hidden_dim))\n",
        "        self.mix1_bias = nn.Parameter(torch.empty(head_num, ms_hidden_dim))\n",
        "        self.mix2_weight = nn.Parameter(torch.empty(head_num, ms_hidden_dim, 1))\n",
        "        self.mix2_bias = nn.Parameter(torch.empty(head_num, 1))\n",
        "        nn.init.uniform_(self.mix1_weight, -ms_layer1_init, ms_layer1_init)\n",
        "        nn.init.uniform_(self.mix1_bias, -ms_layer1_init, ms_layer1_init)\n",
        "        nn.init.uniform_(self.mix2_weight, -ms_layer2_init, ms_layer2_init)\n",
        "        nn.init.uniform_(self.mix2_bias, -ms_layer2_init, ms_layer2_init)\n",
        "\n",
        "\n",
        "    def forward(self, q, k, v, matrix):\n",
        "        # Prepare dot product and matrix score: [batch, head_num, row_cnt, col_cnt]\n",
        "        dot_product = torch.einsum('b h r d, b h c d -> b h r c', q, k) / math.sqrt(q.shape[-1])\n",
        "        matrix_score = repeat(matrix, 'b r c -> b h r c', h=self.head_num)\n",
        "\n",
        "        # Mix the scores\n",
        "        two_scores = torch.stack((dot_product, matrix_score), dim=-1)\n",
        "        ms1 = torch.matmul(two_scores.transpose(1,2), self.mix1_weight) + self.mix1_bias[None, None, :, None, :]\n",
        "        \n",
        "        ms2 = torch.matmul(F.relu(ms1), self.mix2_weight) + self.mix2_bias[None, None, :, None, :]\n",
        "        mixed_scores = rearrange(ms2, 'b h r c 1 -> b r h c')\n",
        "\n",
        "        # Softmax and multiply with values\n",
        "        weights = F.softmax(mixed_scores, dim=3)\n",
        "        out = torch.matmul(weights, v)\n",
        "        return rearrange(out, 'b h r d -> b r (h d)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 30, 512])\n",
            "520\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ms_mha = MixedScoreMHA_noweights(**model_params)\n",
        "out = ms_mha(q, k, v, cost_mat)\n",
        "print(out.shape)\n",
        "\n",
        "# Get num of params\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(count_parameters(ms_mha))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13.1 ms ± 78.1 µs per loop (mean ± std. dev. of 5 runs, 20 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -r 5 -n 20 ms_mha(q, k, v, cost_mat)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, **model_params):\n",
        "        super().__init__()\n",
        "        encoder_layer_num = model_params['encoder_layer_num']\n",
        "        self.layers = nn.ModuleList([EncoderLayer(**model_params) for _ in range(encoder_layer_num)])\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        # col_emb.shape: (batch, col_cnt, embedding)\n",
        "        # row_emb.shape: (batch, row_cnt, embedding)\n",
        "        # cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            row_emb, col_emb = layer(row_emb, col_emb, cost_mat)\n",
        "\n",
        "        return row_emb, col_emb\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, **model_params):\n",
        "        super().__init__()\n",
        "        self.row_encoding_block = EncodingBlock(**model_params)\n",
        "        self.col_encoding_block = EncodingBlock(**model_params)\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        # row_emb.shape: (batch, row_cnt, embedding)\n",
        "        # col_emb.shape: (batch, col_cnt, embedding)\n",
        "        # cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "        row_emb_out = self.row_encoding_block(row_emb, col_emb, cost_mat)\n",
        "        col_emb_out = self.col_encoding_block(col_emb, row_emb, cost_mat.transpose(1, 2))\n",
        "\n",
        "        return row_emb_out, col_emb_out\n",
        "\n",
        "\n",
        "class EncodingBlock(nn.Module):\n",
        "    def __init__(self, **model_params):\n",
        "        super().__init__()\n",
        "        self.model_params = model_params\n",
        "        embedding_dim = self.model_params['embedding_dim']\n",
        "        head_num = self.model_params['head_num']\n",
        "        qkv_dim = self.model_params['qkv_dim']\n",
        "\n",
        "        self.Wq = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n",
        "        self.Wk = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n",
        "        self.Wv = nn.Linear(embedding_dim, head_num * qkv_dim, bias=False)\n",
        "        self.mixed_score_MHA = MixedScore_MultiHeadAttention(**model_params)\n",
        "        self.multi_head_combine = nn.Linear(head_num * qkv_dim, embedding_dim)\n",
        "\n",
        "        self.add_n_normalization_1 = AddAndInstanceNormalization(**model_params)\n",
        "        self.feed_forward = FeedForward(**model_params)\n",
        "        self.add_n_normalization_2 = AddAndInstanceNormalization(**model_params)\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        # NOTE: row and col can be exchanged, if cost_mat.transpose(1,2) is used\n",
        "        # input1.shape: (batch, row_cnt, embedding)\n",
        "        # input2.shape: (batch, col_cnt, embedding)\n",
        "        # cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "        head_num = self.model_params['head_num']\n",
        "\n",
        "        q = reshape_by_heads(self.Wq(row_emb), head_num=head_num)\n",
        "        # q shape: (batch, head_num, row_cnt, qkv_dim)\n",
        "        k = reshape_by_heads(self.Wk(col_emb), head_num=head_num)\n",
        "        v = reshape_by_heads(self.Wv(col_emb), head_num=head_num)\n",
        "        # kv shape: (batch, head_num, col_cnt, qkv_dim)\n",
        "\n",
        "        out_concat = self.mixed_score_MHA(q, k, v, cost_mat)\n",
        "        # shape: (batch, row_cnt, head_num*qkv_dim)\n",
        "\n",
        "        multi_head_out = self.multi_head_combine(out_concat)\n",
        "        # shape: (batch, row_cnt, embedding)\n",
        "\n",
        "        out1 = self.add_n_normalization_1(row_emb, multi_head_out)\n",
        "        out2 = self.feed_forward(out1)\n",
        "        out3 = self.add_n_normalization_2(out1, out2)\n",
        "\n",
        "        return out3\n",
        "        # shape: (batch, row_cnt, embedding)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, **model_params):\n",
        "        super().__init__()\n",
        "        embedding_dim = model_params['embedding_dim']\n",
        "        ff_hidden_dim = model_params['ff_hidden_dim']\n",
        "\n",
        "        self.W1 = nn.Linear(embedding_dim, ff_hidden_dim)\n",
        "        self.W2 = nn.Linear(ff_hidden_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, input1):\n",
        "        # input.shape: (batch, problem, embedding)\n",
        "\n",
        "        return self.W2(F.relu(self.W1(input1)))\n",
        "    \n",
        "\n",
        "def reshape_by_heads(qkv, head_num):\n",
        "    # q.shape: (batch, n, head_num*key_dim)   : n can be either 1 or PROBLEM_SIZE\n",
        "\n",
        "    batch_s = qkv.size(0)\n",
        "    n = qkv.size(1)\n",
        "\n",
        "    q_reshaped = qkv.reshape(batch_s, n, head_num, -1)\n",
        "    # shape: (batch, n, head_num, key_dim)\n",
        "\n",
        "    q_transposed = q_reshaped.transpose(1, 2)\n",
        "    # shape: (batch, head_num, n, key_dim)\n",
        "\n",
        "    return q_transposed\n",
        "\n",
        "\n",
        "\n",
        "class AddAndInstanceNormalization(nn.Module):\n",
        "    def __init__(self, **model_params):\n",
        "        super().__init__()\n",
        "        embedding_dim = model_params['embedding_dim']\n",
        "        self.norm = nn.InstanceNorm1d(embedding_dim, affine=True, track_running_stats=False)\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # input.shape: (batch, problem, embedding)\n",
        "\n",
        "        added = input1 + input2\n",
        "        # shape: (batch, problem, embedding)\n",
        "\n",
        "        transposed = added.transpose(1, 2)\n",
        "        # shape: (batch, embedding, problem)\n",
        "\n",
        "        normalized = self.norm(transposed)\n",
        "        # shape: (batch, embedding, problem)\n",
        "\n",
        "        back_trans = normalized.transpose(1, 2)\n",
        "        # shape: (batch, problem, embedding)\n",
        "\n",
        "        return back_trans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder(\n",
            "  (layers): ModuleList(\n",
            "    (0-4): 5 x EncoderLayer(\n",
            "      (row_encoding_block): EncodingBlock(\n",
            "        (Wq): Linear(in_features=256, out_features=128, bias=False)\n",
            "        (Wk): Linear(in_features=256, out_features=128, bias=False)\n",
            "        (Wv): Linear(in_features=256, out_features=128, bias=False)\n",
            "        (mixed_score_MHA): MixedScore_MultiHeadAttention()\n",
            "        (multi_head_combine): Linear(in_features=128, out_features=256, bias=True)\n",
            "        (add_n_normalization_1): AddAndInstanceNormalization(\n",
            "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (W1): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (W2): Linear(in_features=512, out_features=256, bias=True)\n",
            "        )\n",
            "        (add_n_normalization_2): AddAndInstanceNormalization(\n",
            "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (col_encoding_block): EncodingBlock(\n",
            "        (Wq): Linear(in_features=256, out_features=128, bias=False)\n",
            "        (Wk): Linear(in_features=256, out_features=128, bias=False)\n",
            "        (Wv): Linear(in_features=256, out_features=128, bias=False)\n",
            "        (mixed_score_MHA): MixedScore_MultiHeadAttention()\n",
            "        (multi_head_combine): Linear(in_features=128, out_features=256, bias=True)\n",
            "        (add_n_normalization_1): AddAndInstanceNormalization(\n",
            "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "        )\n",
            "        (feed_forward): FeedForward(\n",
            "          (W1): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (W2): Linear(in_features=512, out_features=256, bias=True)\n",
            "        )\n",
            "        (add_n_normalization_2): AddAndInstanceNormalization(\n",
            "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "torch.Size([64, 20, 256]) torch.Size([64, 30, 256])\n",
            "Number of parameters: 3.96 MB\n"
          ]
        }
      ],
      "source": [
        "# Test out\n",
        "\n",
        "model_params = {\n",
        "    'embedding_dim': 256,\n",
        "    'sqrt_embedding_dim': 256**(1/2),\n",
        "    'encoder_layer_num': 5,\n",
        "    'qkv_dim': 16,\n",
        "    'sqrt_qkv_dim': 16**(1/2),\n",
        "    'head_num': 8,\n",
        "    'logit_clipping': 10,\n",
        "    'ff_hidden_dim': 512,\n",
        "    'ms_hidden_dim': 16,\n",
        "    'ms_layer1_init': (1/2)**(1/2),\n",
        "    'ms_layer2_init': (1/16)**(1/2),\n",
        "    'eval_type': 'argmax',\n",
        "    'one_hot_seed_cnt': 20,  # must be >= node_cnt\n",
        "}\n",
        "\n",
        "\n",
        "encoder = Encoder(**model_params)\n",
        "\n",
        "\n",
        "# col_emb.shape: (batch, col_cnt, embedding)\n",
        "# row_emb.shape: (batch, row_cnt, embedding)\n",
        "# cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "batch = 64\n",
        "row_cnt = 20\n",
        "col_cnt = 30\n",
        "\n",
        "row_emb = torch.randn(batch, row_cnt, model_params['embedding_dim'])\n",
        "col_emb = torch.randn(batch, col_cnt, model_params['embedding_dim'])\n",
        "cost_mat = torch.randn(batch, row_cnt, col_cnt)\n",
        "\n",
        "\n",
        "out = encoder(row_emb, col_emb, cost_mat)\n",
        "print(encoder)\n",
        "\n",
        "print(out[0].shape, out[1].shape)\n",
        "print('Number of parameters: {:.2f} MB'.format(sum(p.numel() for p in encoder.parameters() if p.requires_grad) / 1e6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "67.9 ms ± 599 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit encoder(row_emb, col_emb, cost_mat)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ours (all we need)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchrl.modules.models.models import MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method InteractiveShell.excepthook of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f3e00133b20>>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# rich traceback\n",
        "from rich.traceback import install\n",
        "install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MixedScoreMHA(nn.Module):\n",
        "    def __init__(self, \n",
        "                    embed_dim,\n",
        "                    num_heads,\n",
        "                    hidden_dim: int = 16,\n",
        "                    qkv_dim: int = 16,\n",
        "                    bias=False,\n",
        "                    layer1_init: float = (1/2)**(1/2),\n",
        "                    layer2_init: float = (1/16)**(1/2),\n",
        "                    device=None,\n",
        "                    dtype=None\n",
        "        ):\n",
        "        super().__init__()\n",
        "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
        "        assert (embed_dim % num_heads == 0), \"embed_dim must be divisible by num_heads\"\n",
        "        self.num_heads = num_heads\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Project\n",
        "        self.Wq = nn.Linear(embed_dim, num_heads*qkv_dim, bias=bias, **factory_kwargs)\n",
        "        self.Wk = nn.Linear(embed_dim, num_heads*qkv_dim, bias=bias, **factory_kwargs)\n",
        "        self.Wv = nn.Linear(embed_dim, num_heads*qkv_dim, bias=bias, **factory_kwargs)\n",
        "        self.out_proj = nn.Linear(num_heads*qkv_dim, embed_dim, **factory_kwargs)\n",
        "\n",
        "        # Init mix params\n",
        "        self.mix1_weight = nn.Parameter(torch.empty(num_heads, 2, hidden_dim).uniform_(-layer1_init, layer1_init))\n",
        "        self.mix1_bias = nn.Parameter(torch.empty(num_heads, hidden_dim).uniform_(-layer1_init, layer1_init))\n",
        "        self.mix2_weight = nn.Parameter(torch.empty(num_heads, hidden_dim, 1).uniform_(-layer2_init, layer2_init))\n",
        "        self.mix2_bias = nn.Parameter(torch.empty(num_heads, 1).uniform_(-layer2_init, layer2_init))\n",
        "\n",
        "    def forward(self, q, k, v, matrix):\n",
        "        # Project q, k, v and reshape to [batch, head_num, row_cnt, hidden_dim]\n",
        "        q, k, v = self.Wq(q), self.Wk(k), self.Wv(v)\n",
        "        q, k, v = map(lambda t: self._reshape_heads(t), (q, k, v))\n",
        "\n",
        "        # Prepare dot product and matrix score: [batch, head_num, row_cnt, col_cnt]\n",
        "        dot_product = torch.einsum('...rd,...cd->...rc', q, k) / math.sqrt(q.shape[-1])\n",
        "        matrix_score = repeat(matrix, 'b r c -> b h r c', h=self.num_heads)\n",
        "\n",
        "        # Mix the scores. Use einsum for best performance\n",
        "        two_scores = torch.stack((dot_product, matrix_score), dim=-1)\n",
        "        ms1 = torch.einsum('bhrct,htd->brhcd', two_scores, self.mix1_weight)\n",
        "        ms2 = torch.einsum('brhcd,hdt->brhct', F.relu(ms1), self.mix2_weight)\n",
        "        mixed_scores = rearrange(ms2, 'b h r c 1 -> b r h c')\n",
        "\n",
        "        # Softmax and multiply with values\n",
        "        weights = F.softmax(mixed_scores, dim=3)\n",
        "        out = torch.matmul(weights, v)\n",
        "        \n",
        "        # Project out\n",
        "        out = rearrange(out, 'b h r d -> b r (h d)')\n",
        "        return self.out_proj(out)\n",
        "    \n",
        "    def _reshape_heads(self, x):\n",
        "        # same as rearrange(v, 'b r (h d) -> b h r d', h=self.num_heads) but faster\n",
        "        return x.view(x.shape[0], x.shape[1], self.num_heads, -1).transpose(1, 2)\n",
        "         \n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__()\n",
        "        encoder_layer_num = kw['encoder_layer_num']\n",
        "        self.layers = nn.ModuleList([EncoderLayer(**kw) for _ in range(encoder_layer_num)])\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        for layer in self.layers:\n",
        "            row_emb, col_emb = layer(row_emb, col_emb, cost_mat)\n",
        "        return row_emb, col_emb\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__()\n",
        "        self.row_encoding_block = EncodingBlock(**kw)\n",
        "        self.col_encoding_block = EncodingBlock(**kw)\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        # row_emb.shape: (batch, row_cnt, embedding)\n",
        "        # col_emb.shape: (batch, col_cnt, embedding)\n",
        "        # cost_mat.shape: (batch, row_cnt, col_cnt)\n",
        "        row_emb_out = self.row_encoding_block(row_emb, col_emb, cost_mat)\n",
        "        col_emb_out = self.col_encoding_block(col_emb, row_emb, cost_mat.transpose(1, 2))\n",
        "        return row_emb_out, col_emb_out\n",
        "\n",
        "\n",
        "class EncodingBlock(nn.Module):\n",
        "    def __init__(self, **kw):\n",
        "        super().__init__()\n",
        "        self.mixed_score_mha = MixedScoreMHA(kw['embedding_dim'], kw['head_num'], kw['ms_hidden_dim'])\n",
        "        self.add_n_normalization_1 = AddAndInstanceNormalization(kw['embedding_dim'])\n",
        "        # self.feed_forward = MLP(kw['embedding_dim'], kw['embedding_dim'], 1, kw['ff_hidden_dim'], activation_class=nn.ReLU)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(kw['embedding_dim'], kw['ff_hidden_dim']),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(kw['ff_hidden_dim'], kw['embedding_dim'])\n",
        "        )\n",
        "        self.add_n_normalization_2 = AddAndInstanceNormalization(kw['embedding_dim'])\n",
        "\n",
        "    def forward(self, row_emb, col_emb, cost_mat):\n",
        "        q, k, v = row_emb, col_emb, col_emb\n",
        "        out_mha = self.mixed_score_mha(q, k, v, cost_mat)\n",
        "        out1 = self.add_n_normalization_1(row_emb, out_mha)\n",
        "        out2 = self.feed_forward(out1)\n",
        "        out3 = self.add_n_normalization_2(out1, out2)\n",
        "        return out3 # shape: (batch, row_cnt, embedding)\n",
        "        \n",
        "    \n",
        "class AddAndInstanceNormalization(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.norm = nn.InstanceNorm1d(embedding_dim, affine=True, track_running_stats=False)\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # [batch, problem, embedding]\n",
        "        added = input1 + input2\n",
        "        normalized = self.norm(added.transpose(1, 2)).transpose(1, 2)\n",
        "        return normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder(\n",
            "  (layers): ModuleList(\n",
            "    (0-4): 5 x EncoderLayer(\n",
            "      (row_encoding_block): EncodingBlock(\n",
            "        (mixed_score_mha): MixedScoreMHA(\n",
            "          (Wq): Linear(in_features=256, out_features=128, bias=False)\n",
            "          (Wk): Linear(in_features=256, out_features=128, bias=False)\n",
            "          (Wv): Linear(in_features=256, out_features=128, bias=False)\n",
            "          (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "        )\n",
            "        (add_n_normalization_1): AddAndInstanceNormalization(\n",
            "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "        )\n",
            "        (feed_forward): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "        )\n",
            "        (add_n_normalization_2): AddAndInstanceNormalization(\n",
            "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (col_encoding_block): EncodingBlock(\n",
            "        (mixed_score_mha): MixedScoreMHA(\n",
            "          (Wq): Linear(in_features=256, out_features=128, bias=False)\n",
            "          (Wk): Linear(in_features=256, out_features=128, bias=False)\n",
            "          (Wv): Linear(in_features=256, out_features=128, bias=False)\n",
            "          (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
            "        )\n",
            "        (add_n_normalization_1): AddAndInstanceNormalization(\n",
            "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "        )\n",
            "        (feed_forward): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "        )\n",
            "        (add_n_normalization_2): AddAndInstanceNormalization(\n",
            "          (norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Number of parameters: 3.96 MB\n",
            "torch.Size([64, 20, 256]) torch.Size([64, 30, 256])\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(**model_params)\n",
        "print(encoder)\n",
        "print('Number of parameters: {:.2f} MB'.format(sum(p.numel() for p in encoder.parameters() if p.requires_grad) / 1e6))\n",
        "out = encoder(row_emb, col_emb, cost_mat)\n",
        "print(out[0].shape, out[1].shape)\n",
        "#print number of parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57.1 ms ± 278 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit encoder(row_emb, col_emb, cost_mat)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
