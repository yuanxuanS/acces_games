{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention Model Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method InteractiveShell.excepthook of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f270c35d310>>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# rich tracebacks\n",
        "import rich\n",
        "import rich.traceback\n",
        "\n",
        "rich.traceback.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/ncobench/env/lib/python3.9/site-packages/torchrl/__init__.py:26: UserWarning: failed to set start method to spawn, and current start method for mp is fork.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys; sys.path.append('../../')\n",
        "\n",
        "import math\n",
        "from typing import List, Tuple, Optional, NamedTuple, Dict, Union, Any\n",
        "from einops import rearrange, repeat\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "from torch.nn import DataParallel\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import lightning as L\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from tensordict import TensorDict\n",
        "\n",
        "from graph_encoder import GraphAttentionEncoder\n",
        "from attention import CrossAttention\n",
        "from utils import CachedLookup, sample_many\n",
        "\n",
        "from reinforce_baselines import *\n",
        "\n",
        "from tsp import TSPEnv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AttentionModelBase\n",
        "\n",
        "Here we declare the `AttentionModelBase`, which is the `nn.Module`:\n",
        "- Given initial states, it returns the solutions and rewards for them\n",
        "- We then wrap the main model with REINFORCE baselines and epoch callbacks to train it (full `AttentionModel`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AttentionModelBase(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 env: EnvBase,\n",
        "                 embedding_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 *,\n",
        "                 n_encode_layers: int = 2,\n",
        "                 tanh_clipping: float = 10.,\n",
        "                 mask_inner: bool = True,\n",
        "                 mask_logits: bool = True,\n",
        "                 normalization: str = 'batch',\n",
        "                 n_heads: int = 8,\n",
        "                 checkpoint_encoder: bool = False,\n",
        "                 use_flash_attn: bool = False,\n",
        "                 **kwargs\n",
        "                 ):\n",
        "        super(AttentionModelBase, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_encode_layers = n_encode_layers\n",
        "        self.decode_type = None\n",
        "        self.temp = 1.0\n",
        "        self.env = env\n",
        "\n",
        "        self.tanh_clipping = tanh_clipping\n",
        "\n",
        "        self.mask_inner = mask_inner\n",
        "        self.mask_logits = mask_logits\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.checkpoint_encoder = checkpoint_encoder\n",
        "\n",
        "        # TODO: add extra except TSP\n",
        "        step_context_dim = 2 * embedding_dim  # Embedding of first and last node\n",
        "        node_dim = 2  # x, y\n",
        "        \n",
        "        # Learned input symbols for first action\n",
        "        self.W_placeholder = nn.Parameter(torch.Tensor(2 * embedding_dim))\n",
        "        self.W_placeholder.data.uniform_(-1, 1)  # Placeholder should be in range of activations\n",
        "\n",
        "        self.init_embed = nn.Linear(node_dim, embedding_dim)\n",
        "\n",
        "        self.embedder = GraphAttentionEncoder(\n",
        "            n_heads=n_heads,\n",
        "            embed_dim=embedding_dim,\n",
        "            n_layers=self.n_encode_layers,\n",
        "            normalization=normalization,\n",
        "            use_flash_attn=use_flash_attn,\n",
        "        )\n",
        "        \n",
        "        self.cross_attention = CrossAttention() # NOTE: FlashCrossAttention does not support inner masking!\n",
        "\n",
        "        # For each node we compute (glimpse key, glimpse value, logit key) so 3 * embedding_dim\n",
        "        self.project_node_embeddings = nn.Linear(embedding_dim, 3 * embedding_dim, bias=False)\n",
        "        self.project_fixed_context = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
        "        self.project_step_context = nn.Linear(step_context_dim, embedding_dim, bias=False)\n",
        "        assert embedding_dim % n_heads == 0\n",
        "        # Note n_heads * val_dim == embedding_dim so input to project_out is embedding_dim\n",
        "        self.project_out = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
        "\n",
        "    def forward(self, td: TensorDict, phase: str = \"train\", decode_type: str = \"sampling\") -> TensorDict:\n",
        "        \"\"\"Given observation, precompute embeddings and rollout\"\"\"\n",
        "\n",
        "        # Set decoding type for policy, can be also greedy\n",
        "        self.decode_type = decode_type\n",
        "\n",
        "        if self.checkpoint_encoder and self.training:  # Only checkpoint if we need gradients\n",
        "            embeddings, _ = checkpoint(self.embedder, self._init_embed(td['observation']))\n",
        "        else:\n",
        "            embeddings, _ = self.embedder(self._init_embed(td['observation']))\n",
        "\n",
        "        # Main rollout\n",
        "        _log_p, actions, td = self._rollout(td, embeddings)\n",
        "        reward = self.env.get_rewards(td['observation'], actions)\n",
        "\n",
        "        # Log likelyhood is calculated within the model since returning it per action does not work well with\n",
        "        ll = self._calc_log_likelihood(_log_p, actions, td.get('mask', None))\n",
        "        out = {\"reward\": reward, \"log_likelihood\": ll, \"actions\": actions, \"cost\": -reward}\n",
        "        return out\n",
        "    \n",
        "    def _rollout(self, td, embeddings):\n",
        "\n",
        "        outputs = []\n",
        "        sequences = []\n",
        "\n",
        "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
        "        fixed = self._precompute(embeddings)\n",
        "\n",
        "        # while not td[\"done\"].any(): # NOTE: here we suppose all the batch is done at the same time\n",
        "            \n",
        "        #     log_p, mask = self._get_log_p(fixed, td)\n",
        "\n",
        "        #     # Select the indices of the next nodes in the sequences, result (batch_size) long\n",
        "        #     selected = self._select_node(log_p.exp()[:, 0, :], mask[:, 0, :])  # Squeeze out steps dimension\n",
        "           \n",
        "        #     td.set(\"action\", selected[:, None])\n",
        "        #     td = self.env.step(td)['next']\n",
        "\n",
        "        #     # Collect output of step\n",
        "        #     outputs.append(log_p[:, 0, :])\n",
        "        #     sequences.append(selected)\n",
        "\n",
        "        # Define policy: given state, return td with action and any other value\n",
        "        def policy(td):\n",
        "            log_p, mask = self._get_log_p(fixed, td)\n",
        "            action = self._select_node(log_p.exp()[:, 0, :], mask[:, 0, :])\n",
        "            td.set(\"action\", action[:, None])\n",
        "            # td.set(\"log_p\", log_p[:, 0, :])\n",
        "            outputs.append(log_p[:, 0, :])\n",
        "            sequences.append(action)\n",
        "            return td\n",
        "\n",
        "        # Rollout over the environment starting from the initial state\n",
        "        td = self.env.rollout(td['observation'].shape[-2], policy, auto_reset=False, tensordict=td, return_only_last=True )\n",
        "\n",
        "        # Collected lists, return Tensor\n",
        "        return torch.stack(outputs, 1), torch.stack(sequences, 1), td\n",
        "\n",
        "    def _calc_log_likelihood(self, _log_p, a, mask):\n",
        "\n",
        "        # Get log_p corresponding to selected actions\n",
        "        log_p = _log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        # Optional: mask out actions irrelevant to objective so they do not get reinforced\n",
        "        if mask is not None:\n",
        "            log_p[mask] = 0\n",
        "\n",
        "        assert (log_p > -1000).data.all(), \"Logprobs should not be -inf, check sampling procedure!\"\n",
        "\n",
        "        # Calculate log_likelihood\n",
        "        return log_p.sum(1)\n",
        "\n",
        "    def _init_embed(self, x):\n",
        "        # TODO: others except TSP\n",
        "        return self.init_embed(x)\n",
        "    \n",
        "    def _select_node(self, probs, mask):\n",
        "\n",
        "        assert (probs == probs).all(), \"Probs should not contain any nans\"\n",
        "\n",
        "        if self.decode_type == \"greedy\":\n",
        "            _, selected = probs.max(1)\n",
        "            assert not mask.gather(1, selected.unsqueeze(\n",
        "                -1)).data.any(), \"Decode greedy: infeasible action has maximum probability\"\n",
        "\n",
        "        elif self.decode_type == \"sampling\":\n",
        "            selected = probs.multinomial(1).squeeze(1)\n",
        "\n",
        "            while mask.gather(1, selected.unsqueeze(-1)).data.any():\n",
        "                print('Sampled bad values, resampling!')\n",
        "                selected = probs.multinomial(1).squeeze(1)\n",
        "\n",
        "        else:\n",
        "            assert False, \"Unknown decode type\"\n",
        "        return selected\n",
        "    \n",
        "    def _precompute(self, embeddings, num_steps=1):\n",
        "        # The fixed context projection of the graph embedding is calculated only once for efficiency\n",
        "        graph_embed = embeddings.mean(1)\n",
        "        \n",
        "        # The projection of the node embeddings for the attention is calculated once up front\n",
        "        glimpse_key_fixed, glimpse_val_fixed, logit_key_fixed = \\\n",
        "            self.project_node_embeddings(embeddings[:, None, :, :]).chunk(3, dim=-1)\n",
        "        \n",
        "        # Organize in a TensorDict for easy access\n",
        "        fixed = TensorDict({\n",
        "                \"node_embeddings\": embeddings,\n",
        "                \"context_node_projected\": self.project_fixed_context(graph_embed)[:, None, :],\n",
        "                \"glimpse_key\": self._make_heads(glimpse_key_fixed, num_steps),\n",
        "                \"glimpse_val\": self._make_heads(glimpse_val_fixed, num_steps),\n",
        "                \"logit_key\": logit_key_fixed.contiguous()\n",
        "            },\n",
        "            batch_size=[], # No batch dimension since we are only storing the fixed data\n",
        "        )\n",
        "        return fixed\n",
        "        \n",
        "    def _get_log_p(self, fixed, td, normalize=True):\n",
        "        \n",
        "        # Compute query = context node embedding\n",
        "        query = fixed[\"context_node_projected\"] + \\\n",
        "                self.project_step_context(self._get_parallel_step_context(fixed[\"node_embeddings\"], td))\n",
        "\n",
        "        # Compute keys and values for the nodes\n",
        "        glimpse_K, glimpse_V, logit_K = self._get_attention_node_data(fixed, td['observation'])\n",
        "\n",
        "        # Compute the mask\n",
        "        mask = self.env.get_mask(td)\n",
        "\n",
        "        # Compute logits (unnormalized log_p)\n",
        "        log_p = self._one_to_many_logits(query, glimpse_K, glimpse_V, logit_K, mask)\n",
        "\n",
        "        if normalize:\n",
        "            log_p = torch.log_softmax(log_p / self.temp, dim=-1)\n",
        "\n",
        "        assert not torch.isnan(log_p).any()\n",
        "\n",
        "        return log_p, mask\n",
        "\n",
        "    def _get_parallel_step_context(self, embeddings, td):\n",
        "        \"\"\"\n",
        "        Returns the context per step, optionally for multiple steps at once (for efficient evaluation of the model)\n",
        "        \"\"\"\n",
        "        current_node = self.env.get_current_node(td)\n",
        "        batch_size, num_steps = current_node.size()\n",
        "\n",
        "        # TODO: add others except TSP\n",
        "        if num_steps == 1:  # We need to special case if we have only 1 step, may be the first or not\n",
        "            if td['i'][0].item() == 0: \n",
        "                # First and only step, ignore prev_a (this is a placeholder)\n",
        "                return self.W_placeholder[None, None, :].expand(batch_size, 1, self.W_placeholder.size(-1))\n",
        "            else:\n",
        "                return embeddings.gather(\n",
        "                    1,\n",
        "                    torch.cat((td['first_a'], current_node), 1)[:, :, None].expand(batch_size, 2, embeddings.size(-1))\n",
        "                ).view(batch_size, 1, -1)\n",
        "        # More than one step, assume always starting with first\n",
        "        embeddings_per_step = embeddings.gather(\n",
        "            1,\n",
        "            current_node[:, 1:, None].expand(batch_size, num_steps - 1, embeddings.size(-1))\n",
        "        )\n",
        "        return torch.cat((\n",
        "            # First step placeholder, cat in dim 1 (time steps)\n",
        "            self.W_placeholder[None, None, :].expand(batch_size, 1, self.W_placeholder.size(-1)),\n",
        "            # Second step, concatenate embedding of first with embedding of current/previous (in dim 2, context dim)\n",
        "            torch.cat((\n",
        "                embeddings_per_step[:, 0:1, :].expand(batch_size, num_steps - 1, embeddings.size(-1)),\n",
        "                embeddings_per_step\n",
        "            ), 2)\n",
        "        ), 1)\n",
        "\n",
        "    def _one_to_many_logits(self, query, key, value, logit_K, mask):\n",
        "        # Rearranging\n",
        "        kv = torch.stack([key, value])\n",
        "        q = rearrange(query, 'b 1 (h s) -> b 1 h s', h=self.n_heads)\n",
        "        kv = rearrange(kv, 'two h b 1 g s -> b g two h s', two=2, h=self.n_heads)     \n",
        "\n",
        "        # 1 means to keep, so we invert the mask\n",
        "        key_padding_mask = ~mask.squeeze()\n",
        "\n",
        "        # Cross attention and projection to get glimpse\n",
        "        heads = self.cross_attention(q, kv, key_padding_mask=key_padding_mask)\n",
        "        heads = rearrange(heads, 'b 1 h g -> b 1 1 (h g)', h=self.n_heads)\n",
        "        glimpse = self.project_out(heads)\n",
        "\n",
        "        # Batch matrix multiplication to compute logits (batch_size, num_steps, graph_size)\n",
        "        logits = torch.matmul(glimpse, logit_K.transpose(-2, -1)).squeeze(-2) / math.sqrt(glimpse.size(-1))\n",
        "\n",
        "        # From the logits compute the probabilities by clipping, masking and softmax\n",
        "        if self.tanh_clipping > 0:\n",
        "            logits = torch.tanh(logits) * self.tanh_clipping\n",
        "        if self.mask_logits:\n",
        "            logits[mask] = -math.inf\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def _get_attention_node_data(self, fixed: TensorDict, td: TensorDict) -> dict:\n",
        "        # TODO: add others except TSP\n",
        "        return fixed[\"glimpse_key\"], fixed[\"glimpse_val\"], fixed[\"logit_key\"]\n",
        "\n",
        "    def _make_heads(self, v, num_steps=None):\n",
        "        # TODO: refactor so no need for rearrange\n",
        "        assert num_steps is None or v.size(1) == 1 or v.size(1) == num_steps\n",
        "\n",
        "        return (\n",
        "            v.contiguous().view(v.size(0), v.size(1), v.size(2), self.n_heads, -1)\n",
        "            .expand(v.size(0), v.size(1) if num_steps is None else num_steps, v.size(2), self.n_heads, -1)\n",
        "            .permute(3, 0, 1, 2, 4)  # (n_heads, batch_size, num_steps, graph_size, head_dim)\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test `AttentionModelBase`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/ncobench/env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9.9350, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "class TorchDictDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx] # note: use torch.stack to get batch\n",
        "    \n",
        "\n",
        "env = TSPEnv(n_loc=20)\n",
        "env = env.transform()\n",
        "\n",
        "data = env.gen_params(batch_size=[10000]) # NOTE: need to put batch_size in a list!!\n",
        "init_td = env.reset(data)\n",
        "dataset = TorchDictDataset(init_td)\n",
        "\n",
        "dataloader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=128,\n",
        "                shuffle=False, # no need to shuffle, we're resampling every epoch\n",
        "                num_workers=0,\n",
        "                collate_fn=torch.stack, # we need this to stack the batches in the dataset\n",
        "            )\n",
        "\n",
        "\n",
        "model = AttentionModelBase(\n",
        "    env,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=128,\n",
        "    n_encode_layers=3,\n",
        ").to(\"cuda\")\n",
        "\n",
        "# model = torch.compile(model, backend=\"cuda\")\n",
        "\n",
        "x = next(iter(dataloader)).to(\"cuda\")\n",
        "\n",
        "out = model(x, decode_type=\"sampling\")\n",
        "\n",
        "import tqdm.auto as tqdm\n",
        "\n",
        "res = []\n",
        "for x in dataloader:\n",
        "    x = x.to(\"cuda\")\n",
        "    res.append(- model(x, decode_type=\"sampling\")['reward'])\n",
        "\n",
        "\n",
        "print(torch.cat(res).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AttentionModel(nn.Module):\n",
        "    def __init__(self, env, policy):\n",
        "        super().__init__()\n",
        "        self.env = env\n",
        "        self.policy = policy\n",
        "\n",
        "        # TODO: hydra instantiation\n",
        "        # self.policy = instantiate(cfg.policy)\n",
        "        # self.baseline = instantiate(cfg.baseline) TODO\n",
        "\n",
        "    def forward(self, td: TensorDict, phase: str=\"train\", decode_type: str=None) -> TensorDict:\n",
        "        \"\"\"Evaluate model, get costs and log probabilities and compare with baseline\"\"\"\n",
        "\n",
        "        # Evaluate model, get costs and log probabilities\n",
        "        out_policy = self.policy(td)\n",
        "        bl_val, bl_loss = self.baseline.eval(td, out_policy['cost'])\n",
        "\n",
        "        # print(bl_val, bl_loss)\n",
        "        # Calculate loss\n",
        "        advantage = out_policy['cost'] - bl_val\n",
        "        reinforce_loss = (advantage * out_policy['log_likelihood']).mean()\n",
        "        loss = reinforce_loss + bl_loss\n",
        "\n",
        "        return {'loss': loss, 'reinforce_loss': reinforce_loss, 'bl_loss': bl_loss, 'bl_val': bl_val, **out_policy}\n",
        "    \n",
        "    def setup(self, pl_module):\n",
        "        # Make baseline taking model itself and train_dataloader from model as input\n",
        "        # TODO make this as taken from config\n",
        "        self.baseline = instantiate({\"_target_\": \"__main__.WarmupBaseline\",\n",
        "                                    \"baseline\": {\"_target_\": \"__main__.RolloutBaseline\",                                             }\n",
        "                                    })   \n",
        "        self.baseline.setup(self.policy, pl_module.val_dataloader(), self.env)                         \n",
        "        # self.baseline = NoBaseline()\n",
        "\n",
        "    def on_train_epoch_end(self, pl_module):\n",
        "        self.baseline.epoch_callback(self.policy, pl_module.val_dataloader(), pl_module.current_epoch, self.env)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NCOLightningModule(L.LightningModule):\n",
        "    def __init__(self, env, model, lr=1e-4, batch_size=128, train_size=1000, val_size=10000):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: hydra instantiation\n",
        "        self.env = env\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.train_size = train_size\n",
        "        self.val_size = val_size\n",
        "        self.setup()\n",
        "\n",
        "    def setup(self, stage=\"fit\"):\n",
        "        self.train_dataset = self.get_observation_dataset(self.train_size)\n",
        "        self.val_dataset = self.get_observation_dataset(self.val_size)\n",
        "        if hasattr(self.model, \"setup\"):\n",
        "            self.model.setup(self)\n",
        "\n",
        "    def shared_step(self, batch: Any, batch_idx: int, phase: str):\n",
        "        td = self.env.reset(init_observation=batch)\n",
        "        output = self.model(td, phase)\n",
        "        \n",
        "        # output = self.model(batch, phase)\n",
        "        self.log(f\"{phase}/cost\", output[\"cost\"].mean(), prog_bar=True)\n",
        "        return {\"loss\": output['loss']}\n",
        "\n",
        "    def training_step(self, batch: Any, batch_idx: int):    \n",
        "        return self.shared_step(batch, batch_idx, phase='train')\n",
        "\n",
        "    def validation_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase='val')\n",
        "\n",
        "    def test_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase='test')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        # TODO: scheduler\n",
        "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, total_steps)\n",
        "        return [optim] #, [scheduler]\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return self._dataloader(self.train_dataset)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return self._dataloader(self.val_dataset)\n",
        "    \n",
        "    def on_train_epoch_end(self):\n",
        "        if hasattr(self.model, \"on_train_epoch_end\"):\n",
        "            self.model.on_train_epoch_end(self)\n",
        "        self.train_dataset = self.get_observation_dataset(self.train_size) \n",
        "\n",
        "    # def get_observation_dataset(self, size):\n",
        "    #     # online data generation: we generate a new batch online\n",
        "    #     data = self.env.gen_params(batch_size=size)\n",
        "    #     return TorchDictDataset(self.env.reset(data))\n",
        "\n",
        "    def get_observation_dataset(self, size):\n",
        "        # online data generation: we generate a new batch online\n",
        "        data = self.env.gen_params(batch_size=size)\n",
        "        return TorchDictDataset(self.env.reset(data)['observation'])\n",
        "       \n",
        "    def _dataloader(self, dataset):\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False, # no need to shuffle, we're resampling every epoch\n",
        "            num_workers=0,\n",
        "            collate_fn=torch.stack, # we need this to stack the batches in the dataset\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating baseline model on evaluation dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating baseline model on evaluation dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
            "\n",
            "  | Name  | Type           | Params\n",
            "-----------------------------------------\n",
            "0 | env   | TransformedEnv | 0     \n",
            "1 | model | AttentionModel | 1.4 M \n",
            "-----------------------------------------\n",
            "1.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.4 M     Total params\n",
            "5.681     Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/ncobench/env/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/home/botu/Dev/ncobench/env/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:  12%|█▏        | 292/2500 [00:22<02:52, 12.83it/s, v_num=26, train/cost=4.140]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/ncobench/env/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "env = TSPEnv(n_loc=20)\n",
        "env = env.transform()\n",
        "policy = AttentionModelBase(\n",
        "    env,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=128,\n",
        "    n_encode_layers=3,\n",
        ")\n",
        "\n",
        "model_final = AttentionModel(env, policy)\n",
        "\n",
        "# # TODO CHANGE THIS\n",
        "\n",
        "model = NCOLightningModule(env, model_final, batch_size=512, train_size=1280000, lr=1e-4)\n",
        "\n",
        "# Trick to make calculations faster\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "\n",
        "# Wandb Logger - we can use others as well as simply `None`\n",
        "# logger = pl.loggers.WandbLogger(project=\"torchrl\", name=\"pendulum\")\n",
        "# logger = L.loggers.CSVLogger(\"logs\", name=\"tsp\")\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "# Trainer\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=epochs,\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    # logger=logger,\n",
        "    log_every_n_steps=1,   \n",
        "    gradient_clip_val=1.0, # clip gradients to avoid exploding gradients\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "trainer.fit(model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
