{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SymNCO Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/torchrl/__init__.py:26: UserWarning: failed to set start method to spawn, and current start method for mp is fork.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys; sys.path.append('../../')\n",
        "\n",
        "import math\n",
        "from typing import List, Tuple, Optional, NamedTuple, Dict, Union, Any\n",
        "from einops import rearrange, repeat\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "from torch.nn import DataParallel\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import lightning as L\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from tensordict import TensorDict\n",
        "\n",
        "from rl4co.envs.tsp import TSPEnv\n",
        "from rl4co.models.rl.reinforce import *\n",
        "from rl4co.models.zoo.am.context import env_context\n",
        "from rl4co.models.zoo.am.embeddings import env_init_embedding, env_dynamic_embedding\n",
        "from rl4co.models.zoo.am.encoder import GraphAttentionEncoder\n",
        "from rl4co.models.zoo.am.decoder import Decoder, decode_probs, PrecomputedCache, LogitAttention\n",
        "from rl4co.models.zoo.am.policy import get_log_likelihood\n",
        "from rl4co.models.nn.attention import NativeFlashMHA, flash_attn_wrapper\n",
        "from rl4co.utils.lightning import get_lightning_device\n",
        "from rl4co.utils.ops import batchify, unbatchify"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Novelty compared to `POMO`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compared to the symmetricities in POMO, SymNCO introduces a new loss function:\n",
        "$$\\mathcal{L}_{total} = \\mathcal{L}_{ps} + \\beta \\mathcal{L}_{ss} + \\alpha \\mathcal{L}_{inv}$$\n",
        "where $\\mathcal{L}_{ps}$ is the problem symmetricity loss, $\\mathcal{L}_{ss}$ is the solution symmetricity loss, and $\\mathcal{L}_{inv}$ is the invariant representation loss. The $\\beta$ and $\\alpha$ are hyperparameters that control the relative importance of the symmetricity and inverse losses. A projection head (MLP) is introduced to process the embeddings and calculate $\\mathcal{L}_{inv}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method InteractiveShell.excepthook of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f751fc4e980>>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# For easier debugging\n",
        "\n",
        "from rich.traceback import install\n",
        "install()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilities: action selection, batching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_start_nodes(batch_size, num_nodes, device=\"cpu\"):\n",
        "    \"\"\"Node selection strategy for POMO\n",
        "    Selects different start nodes for each batch element\n",
        "    \"\"\"\n",
        "    selected = torch.arange(num_nodes, device=device).repeat(batch_size) # TODO: check\n",
        "    return selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# x.view(repeats, s[0] // repeats, *s[1:])\n",
        "# same but with s[i] and [s[k] for k in len(s) if k != i]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PrecomputedCache:\n",
        "    node_embeddings: torch.Tensor\n",
        "    graph_context: torch.Tensor\n",
        "    glimpse_key: torch.Tensor\n",
        "    glimpse_val: torch.Tensor\n",
        "    logit_key: torch.Tensor\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, env, embedding_dim, num_heads, num_starts=20, use_graph_context=True, **logit_attn_kwargs):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.env = env\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        assert embedding_dim % num_heads == 0\n",
        "\n",
        "        self.context = env_context(self.env.name, {\"embedding_dim\": embedding_dim})\n",
        "        self.dynamic_embedding = env_dynamic_embedding(\n",
        "            self.env.name, {\"embedding_dim\": embedding_dim}\n",
        "        )\n",
        "\n",
        "        # For each node we compute (glimpse key, glimpse value, logit key) so 3 * embedding_dim\n",
        "        self.project_node_embeddings = nn.Linear(\n",
        "            embedding_dim, 3 * embedding_dim, bias=False\n",
        "        )\n",
        "        self.project_fixed_context = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
        "\n",
        "        # MHA\n",
        "        self.logit_attention = LogitAttention(\n",
        "            embedding_dim, num_heads, **logit_attn_kwargs\n",
        "        )\n",
        "\n",
        "        # POMO\n",
        "        self.num_starts = max(num_starts, 1) # POMO = 1 is just normal REINFORCE\n",
        "        self.use_graph_context = use_graph_context # disabling makes it like in POMO\n",
        "\n",
        "    def forward(self, td, embeddings, decode_type=\"sampling\"):\n",
        "        # Collect outputs\n",
        "        outputs = []\n",
        "        actions = []\n",
        "\n",
        "        if self.num_starts > 1:\n",
        "            # POMO: first action is decided via select_start_nodes\n",
        "            action = select_start_nodes(batch_size=td.shape[0], num_nodes=self.num_starts, device=td.device)\n",
        "\n",
        "            # # Expand td to batch_size * num_starts\n",
        "            td = batchify(td, self.num_starts)\n",
        "\n",
        "            td.set(\"action\", action[:, None])\n",
        "            td = self.env.step(td)[\"next\"]\n",
        "            log_p = torch.zeros_like(td['action_mask'], device=td.device) # first log_p is 0, so p = log_p.exp() = 1\n",
        "\n",
        "            outputs.append(log_p.squeeze(1))\n",
        "            actions.append(action)\n",
        "        \n",
        "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
        "        cached_embeds = self._precompute(embeddings)        \n",
        "\n",
        "        while not td[\"done\"].all():  \n",
        "            # Compute the logits for the next node\n",
        "            log_p, mask = self._get_log_p(cached_embeds, td)\n",
        "\n",
        "            # Select the indices of the next nodes in the sequences, result (batch_size) long\n",
        "            action = decode_probs(\n",
        "                log_p.exp().squeeze(1), mask.squeeze(1), decode_type=decode_type\n",
        "            )\n",
        "\n",
        "            # Step the environment\n",
        "            td.set(\"action\", action[:, None])\n",
        "            td = self.env.step(td)[\"next\"]\n",
        "\n",
        "            # Collect output of step\n",
        "            outputs.append(log_p.squeeze(1))\n",
        "            actions.append(action)\n",
        "\n",
        "        outputs, actions = torch.stack(outputs, 1), torch.stack(actions, 1)\n",
        "        td.set(\"reward\", self.env.get_reward(td, actions))\n",
        "        return outputs, actions, td\n",
        "    \n",
        "    def _precompute(self, embeddings):       \n",
        "        # The projection of the node embeddings for the attention is calculated once up front\n",
        "        (\n",
        "            glimpse_key_fixed,\n",
        "            glimpse_val_fixed,\n",
        "            logit_key_fixed,\n",
        "        ) = self.project_node_embeddings(embeddings[:, None, :, :]).chunk(3, dim=-1)\n",
        "\n",
        "\n",
        "        # In POMO, no graph context (trick for overfit to single graph size) # [batch, 1, embed_dim]\n",
        "        graph_context = batchify(self.project_fixed_context(embeddings.mean(1))[:, None, :], self.num_starts) if self.use_graph_context else 0\n",
        "        \n",
        "        # Organize in a dataclass for easy access\n",
        "        cached_embeds = PrecomputedCache(\n",
        "            node_embeddings=batchify(embeddings, self.num_starts),\n",
        "            graph_context=graph_context,\n",
        "            glimpse_key=batchify(self.logit_attention._make_heads(glimpse_key_fixed), self.num_starts),\n",
        "            glimpse_val=batchify(self.logit_attention._make_heads(glimpse_val_fixed), self.num_starts),\n",
        "            logit_key=batchify(logit_key_fixed, self.num_starts)\n",
        "        )\n",
        "        return cached_embeds\n",
        "\n",
        "    def _get_log_p(self, cached, td):\n",
        "        # Compute the query based on the context (computes automatically the first and last node context)\n",
        "        step_context = self.context(cached.node_embeddings, td)\n",
        "        query = step_context + cached.graph_context\n",
        "\n",
        "        # Compute keys and values for the nodes\n",
        "        glimpse_key_dynamic, glimpse_val_dynamic, logit_key_dynamic = self.dynamic_embedding(td)\n",
        "        glimpse_key = cached.glimpse_key + glimpse_key_dynamic\n",
        "        glimpse_key = cached.glimpse_val + glimpse_val_dynamic\n",
        "        logit_key = cached.logit_key + logit_key_dynamic\n",
        "\n",
        "        # Get the mask\n",
        "        mask = ~td[\"action_mask\"]\n",
        "        mask = mask.unsqueeze(1) if mask.dim() == 2 else mask\n",
        "\n",
        "        # Compute logits\n",
        "        log_p = self.logit_attention(query, glimpse_key, glimpse_key, logit_key, mask)\n",
        "\n",
        "        return log_p, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchrl.modules.models import MLP\n",
        "\n",
        "\n",
        "class SymNCOPolicy(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 env: EnvBase,\n",
        "                 embedding_dim: int,\n",
        "                 hidden_dim: int,\n",
        "                 encoder: nn.Module = None,\n",
        "                 decoder: nn.Module = None,\n",
        "                 projection_head: nn.Module = None,\n",
        "                 num_starts: int = 10,\n",
        "                 num_encode_layers: int = 3,\n",
        "                 normalization: str = 'batch',\n",
        "                 num_heads: int = 8,\n",
        "                 checkpoint_encoder: bool = False,\n",
        "                 mask_inner: bool = True,\n",
        "                 force_flash_attn: bool = False,\n",
        "                 **kwargs\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        Differences with AM and POMO: proj_head for the embeddings\n",
        "        \"\"\"\n",
        "        super(SymNCOPolicy, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_encode_layers = num_encode_layers\n",
        "        self.env = env\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.checkpoint_encoder = checkpoint_encoder\n",
        "        self.num_starts = num_starts\n",
        "\n",
        "        self.init_embedding = env_init_embedding(self.env.name, {\"embedding_dim\": embedding_dim})\n",
        "\n",
        "        self.encoder = GraphAttentionEncoder(\n",
        "            num_heads=num_heads,\n",
        "            embed_dim=embedding_dim,\n",
        "            num_layers=self.num_encode_layers,\n",
        "            normalization=normalization,\n",
        "            force_flash_attn=force_flash_attn,\n",
        "        ) if encoder is None else encoder\n",
        "        \n",
        "        self.decoder = Decoder(env, embedding_dim, num_heads, num_starts=num_starts, mask_inner=mask_inner, force_flash_attn=force_flash_attn) if decoder is None else decoder\n",
        "        self.projection_head = MLP(embedding_dim, embedding_dim, 1, embedding_dim, nn.ReLU) if projection_head is None else projection_head\n",
        "\n",
        "    def forward(self, td: TensorDict, phase: str = \"train\", decode_type: str = \"sampling\", return_actions: bool = False) -> TensorDict:\n",
        "        \"\"\"Given observation, precompute embeddings and rollout\"\"\"\n",
        "\n",
        "        # Set decoding type for policy, can be also greedy\n",
        "        embeddings = self.init_embedding(td)\n",
        "        proj_embeddings = self.projection_head(embeddings)\n",
        "        encoded_inputs, _ = self.encoder(embeddings)\n",
        "\n",
        "        # Main rollout\n",
        "        log_p, actions, td = self.decoder(td, encoded_inputs, decode_type)\n",
        "\n",
        "        # Log likelyhood is calculated within the model since returning it per action does not work well with\n",
        "        ll = get_log_likelihood(log_p, actions, td.get('mask', None))\n",
        "        out = {\"reward\": td[\"reward\"], \"log_likelihood\": ll, \"proj_embeddings\": proj_embeddings, \"actions\": actions if return_actions else None}\n",
        "\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the Policy only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_loc = 15\n",
        "env = TSPEnv(num_loc=num_loc).transform()\n",
        "\n",
        "dataset = env.dataset(batch_size=[10000])\n",
        "\n",
        "dataloader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=32,\n",
        "                shuffle=False, # no need to shuffle, we're resampling every epoch\n",
        "                num_workers=0,\n",
        "                collate_fn=torch.stack, # we need this to stack the batches in the dataset\n",
        "            )\n",
        "\n",
        "model = SymNCOPolicy(\n",
        "    env,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=128,\n",
        "    num_encode_layers=3,\n",
        "    num_starts=num_loc,\n",
        "    # force_flash_attn=True,\n",
        ").to(\"cuda\")\n",
        "\n",
        "# model = torch.compile(model)\n",
        "\n",
        "x = next(iter(dataloader)).to(\"cuda\")\n",
        "x = env.reset(init_obs=x)\n",
        "\n",
        "out = model(x, decode_type=\"sampling\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create full model: `env` + `policy` + `baseline`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 20, 2])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Create a random tensor of shape [64, 20, 2]\n",
        "x = torch.randn(64, 20, 2)\n",
        "\n",
        "# Reflect the tensor along the second dimension\n",
        "reflected = torch.flip(x, dims=[2])\n",
        "print(reflected.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.5022) tensor(0.2890) tensor(0.0015) tensor(0.9999)\n",
            "tensor(0.4991) tensor(0.2890) tensor(-0.1906) tensor(1.1769)\n",
            "torch.Size([640, 20, 2])\n"
          ]
        }
      ],
      "source": [
        "def env_aug_feats(env_name: str) -> Tuple[str, ...]:\n",
        "    return ('observation', 'depot') if env_name == \"op\" else ('observation',)\n",
        "\n",
        "\n",
        "def rotation_reflection_transform(x, y, phi, offset=0.5):\n",
        "    \"\"\"SR group transform with rotation and reflection (~2x faster than original)\"\"\"\n",
        "    x, y = x - offset, y - offset\n",
        "    # random rotation\n",
        "    x_prime = torch.cos(phi) * x - torch.sin(phi) * y\n",
        "    y_prime = torch.sin(phi) * x + torch.cos(phi) * y\n",
        "    # make random reflection if phi > 2*pi (i.e. 50% of the time)\n",
        "    mask = phi > 2 * math.pi\n",
        "    # vectorized random reflection: swap axes x and y if mask\n",
        "    xy = torch.cat((x_prime, y_prime), dim=-1)\n",
        "    xy = torch.where(mask, xy.flip(-1), xy)\n",
        "    return xy + offset\n",
        "\n",
        "\n",
        "def augment_xy_data_by_n_fold(xy, num_augment: int = 8):\n",
        "    \"\"\"Augment xy data by N times via symmetric rotation transform and concatenate to original data\"\"\"\n",
        "    # create random rotation angles (4*pi for reflection, 2*pi for rotation)\n",
        "    phi = torch.rand(xy.shape[0], device=xy.device) * 4 * math.pi \n",
        "    # set phi to 0 for first , i.e. no augmnetation as in original paper\n",
        "    phi[:xy.shape[0]//num_augment] = 0.0\n",
        "    x, y = xy[..., [0]], xy[..., [1]]\n",
        "    return rotation_reflection_transform(x, y, phi[:, None, None])\n",
        "\n",
        "\n",
        "class StateAugmentation(nn.Module):\n",
        "    def __init__(self, env_name, num_augment: int = 8):\n",
        "        \"\"\"Augment state by N times via symmetric rotation transform\"\"\"\n",
        "        super(StateAugmentation, self).__init__()\n",
        "        self.num_augment = num_augment\n",
        "        self.augmentation = augment_xy_data_by_n_fold\n",
        "        self.feats = env_aug_feats(env_name)\n",
        "\n",
        "    def forward(self, td: TensorDict) -> TensorDict:\n",
        "        td_aug = batchify(td, self.num_augment)\n",
        "        for feat in self.feats:\n",
        "            aug_feat = self.augmentation(td_aug[feat], self.num_augment)\n",
        "            td_aug[feat] = aug_feat\n",
        "        return td_aug\n",
        "    \n",
        "\n",
        "augmentation = StateAugmentation(\"tsp\", num_augment=10)\n",
        "\n",
        "td = TensorDict({'observation': torch.rand(64, 20, 2)}, batch_size=64)\n",
        "\n",
        "td_aug = augmentation(td)\n",
        "z = td_aug['observation']\n",
        "# print(b['observation'].shape)\n",
        "a_ = td['observation']\n",
        "print(a_.mean(), a_.std(), a_.min(), a_.max())\n",
        "print(z.mean(), z.std(), z.min(), z.max())\n",
        "print(z.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "aug -10.682 unaug -10.682\n",
            "aug -10.682 unaug -10.682\n",
            "aug -10.682 unaug -10.682\n",
            "aug -10.682 unaug -10.682\n",
            "aug -10.682 unaug -10.682\n"
          ]
        }
      ],
      "source": [
        "# Sanity check\n",
        "\n",
        "# randomly sample 20 different integers from 0 to 20 only once\n",
        "a = torch.randperm(20)[:20]\n",
        "td_unaug = unbatchify(td_aug, 10)\n",
        "\n",
        "for idx in range(5):\n",
        "    rew0 = env.get_reward(td_unaug[:,idx], a[None]).mean()\n",
        "    rew1 = env.get_reward(td, a[None]).mean()\n",
        "    print(r\"aug {:.3f}\".format(rew0.item()), r\"unaug {:.3f}\".format(rew1.item()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def SR_transform(x, y, idx):\n",
        "    if idx < 0.5:\n",
        "        phi = idx * 4 * math.pi\n",
        "    else:\n",
        "        phi = (idx - 0.5) * 4 * math.pi\n",
        "\n",
        "    x = x - 1 / 2\n",
        "    y = y - 1 / 2\n",
        "\n",
        "    x_prime = torch.cos(phi) * x - torch.sin(phi) * y\n",
        "    y_prime = torch.sin(phi) * x + torch.cos(phi) * y\n",
        "\n",
        "    if idx < 0.5:\n",
        "        dat = torch.cat((x_prime + 1 / 2, y_prime + 1 / 2), dim=2)\n",
        "    else:\n",
        "        dat = torch.cat((y_prime + 1 / 2, x_prime + 1 / 2), dim=2)\n",
        "    return dat\n",
        "\n",
        "\n",
        "def augment_xy_data_by_N_fold(problems, N, depot=None):\n",
        "    x = problems[:, :, [0]]\n",
        "    y = problems[:, :, [1]]\n",
        "\n",
        "    if depot is not None:\n",
        "        x_depot = depot[:, :, [0]]\n",
        "        y_depot = depot[:, :, [1]]\n",
        "    idx = torch.rand(N - 1)\n",
        "\n",
        "    for i in range(N - 1):\n",
        "\n",
        "        problems = torch.cat((problems, SR_transform(x, y, idx[i])), dim=0)\n",
        "        if depot is not None:\n",
        "            depot = torch.cat((depot, SR_transform(x_depot, y_depot, idx[i])), dim=0)\n",
        "\n",
        "    if depot is not None:\n",
        "        return problems, depot\n",
        "\n",
        "    return problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = torch.rand(1024, 100, 2).cuda()\n",
        "td = TensorDict({'observation': x}, batch_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "579 µs ± 1.17 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit augment_xy_data_by_N_fold(x, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "285 µs ± 404 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit augmentation(td)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "\n",
        "def problem_symmetricity_loss(reward, log_likelihood, dim=1):\n",
        "    \"\"\"\n",
        "    REINFORCE loss for problem symmetricity\n",
        "    Baseline is the average reward for all augmented problems\n",
        "    \"\"\"\n",
        "    num_augment = reward.shape[dim]\n",
        "    if num_augment < 2:\n",
        "        return 0\n",
        "    advantage = reward - reward.mean(dim=dim, keepdim=True)\n",
        "    loss = -advantage * log_likelihood\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "def solution_symmetricity_loss(reward, log_likelihood, dim=2):\n",
        "    \"\"\"\n",
        "    REINFORCE loss for solution symmetricity\n",
        "    Baseline is the average reward for all start nodes\n",
        "    \"\"\"    \n",
        "    num_starts = reward.shape[dim]\n",
        "    if num_starts < 2:\n",
        "        return 0\n",
        "    advantage = reward - reward.mean(dim=dim, keepdim=True)\n",
        "    loss = -advantage * log_likelihood\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "def invariance_loss(proj_embed, num_augment):\n",
        "    \"\"\"Loss for invariant representation on projected nodes\"\"\"\n",
        "    pe = rearrange(proj_embed, '(b a) ... -> b a ...', a=num_augment)\n",
        "    similarity = sum([F.cosine_similarity(pe[:, 0], pe[:, i], dim=-1) for i in range(1, num_augment)])\n",
        "    return similarity.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rl4co.models.rl.reinforce import NoBaseline\n",
        "from rl4co.models.zoo.pomo.utils import get_best_actions\n",
        "\n",
        "# def get_best_actions(actions, max_idxs):\n",
        "#     actions = undo_repeat_batch(actions, max_idxs.shape[0])\n",
        "#     return actions.gather(0, max_idxs[..., None, None])\n",
        "\n",
        "\n",
        "class SymNCO(nn.Module):\n",
        "    def __init__(self, env, policy, baseline=None, num_augment=8, alpha=0.2, beta=1, augment_test=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.env = env\n",
        "        self.policy = policy\n",
        "        if baseline is not None:\n",
        "            print(\"SymNCO uses baselines in the loss functions, so we do not set the baseline here.\")\n",
        "        self.baseline = NoBaseline() # done in loss function\n",
        "\n",
        "        # Multi-start parameters\n",
        "        self.num_starts = getattr(policy, \"num_starts\", 1)\n",
        "        self.num_augment = num_augment \n",
        "        assert num_augment > 1, \"Number of augmentations must be greater than 1 for SymNCO\"\n",
        "        self.augment = StateAugmentation(env.name, num_augment)\n",
        "        self.augment_test = augment_test\n",
        "        self.alpha = alpha # weight for invariance loss\n",
        "        self.beta = beta # weight for solution symmetricity loss\n",
        "    \n",
        "\n",
        "    def forward(self, td: TensorDict, phase: str=\"train\", **policy_kwargs) -> TensorDict:\n",
        "        \"\"\"Evaluate model, get costs and log probabilities and compare with baseline\"\"\"\n",
        "\n",
        "        # Init vals\n",
        "        loss_retvals, multi_start_retvals, aug_retvals = {}, {}, {}\n",
        "        return_action = policy_kwargs.get(\"return_actions\", False)\n",
        "\n",
        "        # Augment data\n",
        "        if phase == \"train\" or self.augment_test:\n",
        "            td = self.augment(td)\n",
        "            aug_size = self.num_augment # reward to [batch_size, num_augment, num_starts]\n",
        "        else:\n",
        "            aug_size = 1\n",
        "\n",
        "        # Evaluate model, get costs and log probabilities and more\n",
        "        out = self.policy(td, **policy_kwargs)\n",
        "        reward = unbatchify(unbatchify(out[\"reward\"], self.num_starts), aug_size)\n",
        "\n",
        "        if phase == \"train\":\n",
        "            # [batch_size, num_augment, num_starts]\n",
        "            ll = unbatchify(unbatchify(out[\"log_likelihood\"], self.num_starts), aug_size)\n",
        "            loss_ps = problem_symmetricity_loss(reward, ll)\n",
        "            loss_ss = solution_symmetricity_loss(reward, ll)\n",
        "            loss_inv = invariance_loss(out['proj_embeddings'], self.num_augment)\n",
        "            loss = loss_ps + self.beta * loss_ss + self.alpha * loss_inv\n",
        "            loss_retvals = {\"loss\": loss, \"loss_ss\": loss_ss, \"loss_ps\": loss_ps, \"loss_inv\": loss_inv}\n",
        "\n",
        "        else:\n",
        "            # Get best actions for multi-start # [batch_size, num_augment, num_starts]\n",
        "            max_reward, max_idxs = reward.max(dim=2)\n",
        "            multi_start_retvals = {\"max_reward\": max_reward, \"best_actions\": get_best_actions(out[\"actions\"], max_idxs) if return_action else None}\n",
        "            # Get best out of augmented # [batch, num_augment]\n",
        "            max_aug_reward, max_idxs = max_reward.max(dim=1)\n",
        "            aug_retvals = {\"max_aug_reward\": max_aug_reward, \"best_aug_actions\": get_best_actions(out[\"actions\"], max_idxs) if return_action else None}\n",
        " \n",
        "        return { **out, **loss_retvals, **multi_start_retvals, **aug_retvals}\n",
        "        \n",
        "    def setup(self, *args, **kwargs):\n",
        "        pass # no baseline\n",
        "    \n",
        "    def on_train_epoch_end(self, *args, **kwargs):\n",
        "        pass # no baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple test of full SymNCO\n",
        "\n",
        "num_loc = 20\n",
        "env = TSPEnv(num_loc=num_loc).transform()\n",
        "\n",
        "dataset = env.dataset(batch_size=[10000])\n",
        "\n",
        "dataloader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=32,\n",
        "                shuffle=False, # no need to shuffle, we're resampling every epoch\n",
        "                num_workers=0,\n",
        "                collate_fn=torch.stack, # we need this to stack the batches in the dataset\n",
        "            )\n",
        "\n",
        "policy = SymNCOPolicy(\n",
        "    env,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=128,\n",
        "    num_encode_layers=3,\n",
        "    num_starts=num_loc,\n",
        "    # force_flash_attn=True,\n",
        ").to(\"cuda\")\n",
        "\n",
        "model = SymNCO(env, policy, num_augment=8, alpha=1, beta=1).to(\"cuda\")\n",
        "\n",
        "\n",
        "x = next(iter(dataloader)).to(\"cuda\")\n",
        "x = env.reset(init_obs=x)\n",
        "\n",
        "out = model(x, decode_type=\"sampling\")\n",
        "\n",
        "# out = model(x, decode_type=\"sampling\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NCOLightningModule(L.LightningModule):\n",
        "    def __init__(self, env, model, lr=1e-4, batch_size=128, train_size=1000, val_size=10000):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: hydra instantiation\n",
        "        self.env = env\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.train_size = train_size\n",
        "        self.val_size = val_size\n",
        "        self.train_log = [\"reward\", \"loss\", \"loss_ss\", \"loss_ps\", \"loss_inv\"]\n",
        "        self.val_log = [\"reward\", \"max_reward\", \"max_aug_reward\"]\n",
        "        self.test_log = self.val_log\n",
        "        self.log_cost = True\n",
        "\n",
        "    def setup(self, stage=\"fit\"):\n",
        "        self.train_dataset = self.env.dataset(self.train_size)\n",
        "        self.val_dataset = self.env.dataset(self.val_size)\n",
        "        if hasattr(self.model, \"setup\"):\n",
        "            self.model.setup(self)\n",
        "\n",
        "    def shared_step(self, batch: Any, batch_idx: int, phase: str):\n",
        "        td = self.env.reset(init_obs=batch)\n",
        "        out = self.model(td, phase)\n",
        "        \n",
        "        # Log metrics\n",
        "        log_metrics = getattr(self, f\"{phase}_log\")\n",
        "        metrics = {f\"{phase}/{k}\": v.mean() for k, v in out.items() if k in log_metrics}\n",
        "\n",
        "        # If log_cost, replace all max -> min, reward -> cost and invert sign\n",
        "        if self.log_cost:\n",
        "            metrics = {k.replace(\"max\", \"min\").replace(\"reward\", \"cost\"): -v for k, v in metrics.items()}\n",
        "        \n",
        "        self.log_dict(metrics, prog_bar=True)\n",
        "        \n",
        "        return {\"loss\": out.get(\"loss\", None)}\n",
        "\n",
        "    def training_step(self, batch: Any, batch_idx: int):   \n",
        "        return self.shared_step(batch, batch_idx, phase='train')\n",
        "\n",
        "    def validation_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase='val')\n",
        "\n",
        "    def test_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase='test')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=1e-6)\n",
        "        # optim = Lion(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
        "        # TODO: scheduler\n",
        "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, total_steps)\n",
        "        return [optim] #, [scheduler]\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return self._dataloader(self.train_dataset)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return self._dataloader(self.val_dataset)\n",
        "    \n",
        "    def on_train_epoch_end(self):\n",
        "        if hasattr(self.model, \"on_train_epoch_end\"):\n",
        "            self.model.on_train_epoch_end(self)\n",
        "        self.train_dataset = self.env.dataset(self.train_size) \n",
        "       \n",
        "    def _dataloader(self, dataset):\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False, # no need to shuffle, we're resampling every epoch\n",
        "            num_workers=0,\n",
        "            collate_fn=torch.stack, # we need this to stack the batches in the dataset\n",
        "            # pin_memory=self.on_gpu,\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "epochs = 1\n",
        "batch_size = 64 #1024 #512\n",
        "n_loc = 20\n",
        "train_size = 1280000\n",
        "lr = 1e-4\n",
        "n_starts = num_loc # TODO: comment to try out = 1\n",
        "# num_pomo = 1 # set to 1: similar to simple AM\n",
        "\n",
        "# Environment\n",
        "env = TSPEnv(num_loc=n_loc).transform()\n",
        "\n",
        "\n",
        "dataset = env.dataset(batch_size=[10000])\n",
        "\n",
        "dataloader = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=32,\n",
        "                shuffle=False, # no need to shuffle, we're resampling every epoch\n",
        "                num_workers=0,\n",
        "                collate_fn=torch.stack, # we need this to stack the batches in the dataset\n",
        "            )\n",
        "\n",
        "policy = SymNCOPolicy(\n",
        "    env,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=128,\n",
        "    num_encode_layers=3,\n",
        "    num_starts=num_loc,\n",
        "    # force_flash_attn=True,\n",
        ").to(\"cuda\")\n",
        "\n",
        "model = SymNCO(env, policy, num_augment=8, alpha=0.2, beta=1).to(\"cuda\")\n",
        "\n",
        "\n",
        "x = next(iter(dataloader)).to(\"cuda\")\n",
        "x = env.reset(init_obs=x)\n",
        "\n",
        "# Quick test\n",
        "out = model(x, decode_type=\"sampling\")\n",
        "\n",
        "\n",
        "# Create Lightning module (for training)\n",
        "lit_model = NCOLightningModule(env, model, batch_size=batch_size, train_size=train_size, lr=lr)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type   | Params\n",
            "---------------------------------\n",
            "0 | env   | TSPEnv | 0     \n",
            "1 | model | SymNCO | 743 K \n",
            "---------------------------------\n",
            "743 K     Trainable params\n",
            "0         Non-trainable params\n",
            "743 K     Total params\n",
            "2.973     Total estimated model params size (MB)\n",
            "2023-04-20 17:43:30.791044: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-04-20 17:43:30.810355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-20 17:43:31.150830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   4%|▍         | 813/20000 [01:36<37:59,  8.42it/s, v_num=4, train/cost=4.050, train/loss=0.507, train/loss_ss=0.268, train/loss_ps=0.255, train/loss_inv=-.0829]  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/rl4co/env/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "# Trick to make calculations faster\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "\n",
        "# Trainer\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=epochs,\n",
        "    accelerator=\"gpu\",\n",
        "    # devices=[1],\n",
        "    logger=None, # can replace with WandbLogger, TensorBoardLogger, etc.\n",
        "    # precision=16, # uncomment to make faster\n",
        "    log_every_n_steps=100,   \n",
        "    gradient_clip_val=1.0, # clip gradients to avoid exploding gradients!\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "trainer.fit(lit_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation DataLoader 0: 100%|██████████| 157/157 [00:07<00:00, 21.82it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val/cost          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.075383186340332     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     val/min_aug_cost      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.843059778213501     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/min_cost        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.876986026763916     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val/cost         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.075383186340332    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    val/min_aug_cost     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.843059778213501    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      val/min_cost       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.876986026763916    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'val/cost': 4.075383186340332,\n",
              "  'val/min_cost': 3.876986026763916,\n",
              "  'val/min_aug_cost': 3.843059778213501}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.validate(lit_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate generalization on larger problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation DataLoader 0: 100%|██████████| 157/157 [02:03<00:00,  1.27it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         val/cost          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    12.835606575012207     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     val/min_aug_cost      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    11.294989585876465     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       val/min_cost        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    11.733050346374512     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        val/cost         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   12.835606575012207    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    val/min_aug_cost     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.294989585876465    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      val/min_cost       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.733050346374512    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'val/cost': 12.835606575012207,\n",
              "  'val/min_cost': 11.733050346374512,\n",
              "  'val/min_aug_cost': 11.294989585876465}]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Validating with more locations\n",
        "\n",
        "env = lit_model.env\n",
        "env.num_loc = 100\n",
        "lit_model.val_dataset = env.dataset(lit_model.val_size)\n",
        "trainer.validate(lit_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
