{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TSP Environment - test import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method InteractiveShell.excepthook of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f28f449d310>>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# rich tracebacks\n",
        "import rich\n",
        "import rich.traceback\n",
        "\n",
        "rich.traceback.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys; sys.path.append('../../')\n",
        "\n",
        "import math\n",
        "from typing import List, Tuple, Optional, NamedTuple, Dict, Union, Any\n",
        "from einops import rearrange, repeat\n",
        "from hydra.utils import instantiate\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "from torch.nn import DataParallel\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import lightning as L\n",
        "\n",
        "from torchrl.envs import EnvBase\n",
        "from torchrl.envs.utils import step_mdp\n",
        "from tensordict import TensorDict\n",
        "\n",
        "from graph_encoder import GraphAttentionEncoder\n",
        "from attention import CrossAttention\n",
        "from utils import CachedLookup, sample_many\n",
        "# from reinforce_baselines import *\n",
        "# from sanity.reinforce_baselines import *\n",
        "from sanity._reinforce_baselines_env import *\n",
        "\n",
        "# from ncobench.envs import TSPEnv\n",
        "# from sanity.problem_tsp import TSP\n",
        "from sanity.env import TSPEnv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AttentionModelFixed(NamedTuple):\n",
        "    \"\"\"\n",
        "    Context for AttentionModel decoder that is fixed during decoding so can be precomputed/cached\n",
        "    This class allows for efficient indexing of multiple Tensors at once\n",
        "    \"\"\"\n",
        "    node_embeddings: torch.Tensor\n",
        "    context_node_projected: torch.Tensor\n",
        "    glimpse_key: torch.Tensor\n",
        "    glimpse_val: torch.Tensor\n",
        "    logit_key: torch.Tensor\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        assert torch.is_tensor(key) or isinstance(key, slice)\n",
        "        return AttentionModelFixed(\n",
        "            node_embeddings=self.node_embeddings[key],\n",
        "            context_node_projected=self.context_node_projected[key],\n",
        "            glimpse_key=self.glimpse_key[:, key],  # dim 0 are the heads\n",
        "            glimpse_val=self.glimpse_val[:, key],  # dim 0 are the heads\n",
        "            logit_key=self.logit_key[key]\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AttentionModelBase\n",
        "\n",
        "Here we declare the `AttentionModelBase`, which is the `nn.Module`:\n",
        "- Given initial states, it returns the solutions and rewards for them\n",
        "- We then wrap the main model with REINFORCE baselines and epoch callbacks to train it (full `AttentionModel`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def set_decode_type(model, decode_type):\n",
        "    if isinstance(model, DataParallel):\n",
        "        model = model.module\n",
        "    model.set_decode_type(decode_type)\n",
        "\n",
        "\n",
        "class AttentionModelFixed(NamedTuple):\n",
        "    \"\"\"\n",
        "    Context for AttentionModel decoder that is fixed during decoding so can be precomputed/cached\n",
        "    This class allows for efficient indexing of multiple Tensors at once\n",
        "    \"\"\"\n",
        "    node_embeddings: torch.Tensor\n",
        "    context_node_projected: torch.Tensor\n",
        "    glimpse_key: torch.Tensor\n",
        "    glimpse_val: torch.Tensor\n",
        "    logit_key: torch.Tensor\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        assert torch.is_tensor(key) or isinstance(key, slice)\n",
        "        return AttentionModelFixed(\n",
        "            node_embeddings=self.node_embeddings[key],\n",
        "            context_node_projected=self.context_node_projected[key],\n",
        "            glimpse_key=self.glimpse_key[:, key],  # dim 0 are the heads\n",
        "            glimpse_val=self.glimpse_val[:, key],  # dim 0 are the heads\n",
        "            logit_key=self.logit_key[key]\n",
        "        )\n",
        "\n",
        "\n",
        "class AttentionModel2(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 embedding_dim,\n",
        "                 hidden_dim,\n",
        "                 problem,\n",
        "                 n_encode_layers=2,\n",
        "                 tanh_clipping=10.,\n",
        "                 mask_inner=True,\n",
        "                 mask_logits=True,\n",
        "                 normalization='batch',\n",
        "                 n_heads=8,\n",
        "                 checkpoint_encoder=False,\n",
        "                 shrink_size=None,\n",
        "                 use_flash_attn=False,\n",
        "                 _new_implementation=True,\n",
        "                 ):\n",
        "        super(AttentionModel2, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_encode_layers = n_encode_layers\n",
        "        self.decode_type = None\n",
        "        self.temp = 1.0\n",
        "\n",
        "        self.tanh_clipping = tanh_clipping\n",
        "\n",
        "        self.mask_inner = mask_inner\n",
        "        self.mask_logits = mask_logits\n",
        "\n",
        "        self.problem = problem\n",
        "        self.n_heads = n_heads\n",
        "        self.checkpoint_encoder = checkpoint_encoder\n",
        "        self.shrink_size = shrink_size\n",
        "\n",
        "        step_context_dim = 2 * embedding_dim  # Embedding of first and last node\n",
        "        node_dim = 2  # x, y\n",
        "        \n",
        "        # Learned input symbols for first action\n",
        "        self.W_placeholder = nn.Parameter(torch.Tensor(2 * embedding_dim))\n",
        "        self.W_placeholder.data.uniform_(-1, 1)  # Placeholder should be in range of activations\n",
        "\n",
        "        self.init_embed = nn.Linear(node_dim, embedding_dim)\n",
        "\n",
        "        # self.embedder = GraphAttentionEncoder(\n",
        "        self.embedder = GraphAttentionEncoder(\n",
        "            n_heads=n_heads,\n",
        "            embed_dim=embedding_dim,\n",
        "            n_layers=self.n_encode_layers,\n",
        "            normalization=normalization,\n",
        "            use_flash_attn=use_flash_attn,\n",
        "        )\n",
        "\n",
        "        # NOTE: FlashCrossAttention does not support inner masking!\n",
        "        self.cross_attention = CrossAttention()\n",
        "\n",
        "        # For each node we compute (glimpse key, glimpse value, logit key) so 3 * embedding_dim\n",
        "        self.project_node_embeddings = nn.Linear(embedding_dim, 3 * embedding_dim, bias=False)\n",
        "        self.project_fixed_context = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
        "        self.project_step_context = nn.Linear(step_context_dim, embedding_dim, bias=False)\n",
        "        assert embedding_dim % n_heads == 0\n",
        "        # Note n_heads * val_dim == embedding_dim so input to project_out is embedding_dim\n",
        "        self.project_out = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
        "        self._new_implementation = _new_implementation\n",
        "\n",
        "    def set_decode_type(self, decode_type, temp=None):\n",
        "        self.decode_type = decode_type\n",
        "        if temp is not None:  # Do not change temperature if not provided\n",
        "            self.temp = temp\n",
        "\n",
        "    def forward(self, state, return_pi=False):\n",
        "        \"\"\"\n",
        "        :param input: (batch_size, graph_size, node_dim) input node features or dictionary with multiple tensors\n",
        "        :param return_pi: whether to return the output sequences, this is optional as it is not compatible with\n",
        "        using DataParallel as the results may be of different lengths on different GPUs\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        input = state['observation']\n",
        "\n",
        "        if self.checkpoint_encoder and self.training:  # Only checkpoint if we need gradients\n",
        "            embeddings, _ = checkpoint(self.embedder, self._init_embed(input))\n",
        "        else:\n",
        "            embeddings, _ = self.embedder(self._init_embed(input))\n",
        "\n",
        "        _log_p, pi = self._inner(state, embeddings)\n",
        "\n",
        "        # cost, mask = self.problem.get_costs(input, pi)\n",
        "        cost = self.problem.get_costs(state)\n",
        "        mask = self.problem.get_mask(state)\n",
        "        \n",
        "        # Log likelyhood is calculated within the model since returning it per action does not work well with\n",
        "        # DataParallel since sequences can be of different lengths\n",
        "        ll = self._calc_log_likelihood(_log_p, pi, mask)\n",
        "        if return_pi:\n",
        "            return cost, ll, pi\n",
        "\n",
        "        return cost, ll\n",
        "    \n",
        "    def precompute_fixed(self, input):\n",
        "        embeddings, _ = self.embedder(self._init_embed(input))\n",
        "        # Use a CachedLookup such that if we repeatedly index this object with the same index we only need to do\n",
        "        # the lookup once... this is the case if all elements in the batch have maximum batch size\n",
        "        return CachedLookup(self._precompute(embeddings))\n",
        "\n",
        "    def _calc_log_likelihood(self, _log_p, a, mask):\n",
        "\n",
        "        # Get log_p corresponding to selected actions\n",
        "        log_p = _log_p.gather(2, a.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        # Optional: mask out actions irrelevant to objective so they do not get reinforced\n",
        "        if mask is not None:\n",
        "            log_p[mask] = 0\n",
        "\n",
        "        assert (log_p > -1000).data.all(), \"Logprobs should not be -inf, check sampling procedure!\"\n",
        "\n",
        "        # Calculate log_likelihood\n",
        "        return log_p.sum(1)\n",
        "\n",
        "    def _init_embed(self, input):\n",
        "\n",
        "        return self.init_embed(input)\n",
        "\n",
        "    def _inner(self, state, embeddings):\n",
        "\n",
        "        outputs = []\n",
        "        sequences = []\n",
        "\n",
        "        # state = self.problem.make_state(input)\n",
        "\n",
        "        # Compute keys, values for the glimpse and keys for the logits once as they can be reused in every step\n",
        "        fixed = self._precompute(embeddings)\n",
        "\n",
        "        batch_size = state['ids'].size(0)\n",
        "\n",
        "        # Perform decoding steps\n",
        "        i = 0\n",
        "        # while not (self.shrink_size is None and state.all_finished()):\n",
        "        while not state[\"done\"].any():\n",
        "\n",
        "            log_p, mask = self._get_log_p(fixed, state)\n",
        "\n",
        "            # Select the indices of the next nodes in the sequences, result (batch_size) long\n",
        "            selected = self._select_node(log_p.exp()[:, 0, :], mask[:, 0, :])  # Squeeze out steps dimension\n",
        "\n",
        "            state.set(\"action\", selected[:, None])\n",
        "            state = self.problem.step(state)['next']\n",
        "\n",
        "            # state = state.update(selected)\n",
        "\n",
        "\n",
        "            # Collect output of step\n",
        "            outputs.append(log_p[:, 0, :])\n",
        "            sequences.append(selected)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        # Collected lists, return Tensor\n",
        "        return torch.stack(outputs, 1), torch.stack(sequences, 1)\n",
        "\n",
        "\n",
        "    def _select_node(self, probs, mask):\n",
        "\n",
        "        assert (probs == probs).all(), \"Probs should not contain any nans\"\n",
        "\n",
        "        if self.decode_type == \"greedy\":\n",
        "            _, selected = probs.max(1)\n",
        "            assert not mask.gather(1, selected.unsqueeze(\n",
        "                -1)).data.any(), \"Decode greedy: infeasible action has maximum probability\"\n",
        "\n",
        "        elif self.decode_type == \"sampling\":\n",
        "            selected = probs.multinomial(1).squeeze(1)\n",
        "\n",
        "            # Check if sampling went OK, can go wrong due to bug on GPU\n",
        "            # See https://discuss.pytorch.org/t/bad-behavior-of-multinomial-function/10232\n",
        "            while mask.gather(1, selected.unsqueeze(-1)).data.any():\n",
        "                print('Sampled bad values, resampling!')\n",
        "                selected = probs.multinomial(1).squeeze(1)\n",
        "\n",
        "        else:\n",
        "            assert False, \"Unknown decode type\"\n",
        "        return selected\n",
        "\n",
        "    def _precompute(self, embeddings, num_steps=1):\n",
        "\n",
        "        # The fixed context projection of the graph embedding is calculated only once for efficiency\n",
        "        graph_embed = embeddings.mean(1)\n",
        "        # fixed context = (batch_size, 1, embed_dim) to make broadcastable with parallel timesteps\n",
        "        fixed_context = self.project_fixed_context(graph_embed)[:, None, :]\n",
        "\n",
        "        # The projection of the node embeddings for the attention is calculated once up front\n",
        "        glimpse_key_fixed, glimpse_val_fixed, logit_key_fixed = \\\n",
        "            self.project_node_embeddings(embeddings[:, None, :, :]).chunk(3, dim=-1)\n",
        "        \n",
        "        # No need to rearrange key for logit as there is a single head\n",
        "        fixed_attention_node_data = (\n",
        "            self._make_heads(glimpse_key_fixed, num_steps),\n",
        "            self._make_heads(glimpse_val_fixed, num_steps),\n",
        "            logit_key_fixed.contiguous()\n",
        "        )\n",
        "        return AttentionModelFixed(embeddings, fixed_context, *fixed_attention_node_data)\n",
        "\n",
        "    def _get_log_p_topk(self, fixed, state, k=None, normalize=True):\n",
        "        log_p, _ = self._get_log_p(fixed, state, normalize=normalize)\n",
        "\n",
        "        # Return topk\n",
        "        if k is not None and k < log_p.size(-1):\n",
        "            return log_p.topk(k, -1)\n",
        "\n",
        "        # Return all, note different from torch.topk this does not give error if less than k elements along dim\n",
        "        return (\n",
        "            log_p,\n",
        "            torch.arange(log_p.size(-1), device=log_p.device, dtype=torch.int64).repeat(log_p.size(0), 1)[:, None, :]\n",
        "        )\n",
        "\n",
        "    def _get_log_p(self, fixed, state, normalize=True):\n",
        "\n",
        "        # Compute query = context node embedding\n",
        "        query = fixed.context_node_projected + \\\n",
        "                self.project_step_context(self._get_parallel_step_context(fixed.node_embeddings, state))\n",
        "\n",
        "        # Compute keys and values for the nodes\n",
        "        glimpse_K, glimpse_V, logit_K = self._get_attention_node_data(fixed, state)\n",
        "\n",
        "        # Compute the mask\n",
        "        # mask = state.get_mask()\n",
        "        mask = self.problem.get_mask(state)\n",
        "\n",
        "        # Compute logits (unnormalized log_p)\n",
        "        log_p, glimpse = self._one_to_many_logits(query, glimpse_K, glimpse_V, logit_K, mask)\n",
        "\n",
        "        if normalize:\n",
        "            log_p = torch.log_softmax(log_p / self.temp, dim=-1)\n",
        "\n",
        "        assert not torch.isnan(log_p).any()\n",
        "\n",
        "        return log_p, mask\n",
        "\n",
        "    def _get_parallel_step_context(self, embeddings, state, from_depot=False):\n",
        "        \"\"\"\n",
        "        Returns the context per step, optionally for multiple steps at once (for efficient evaluation of the model)\n",
        "        \n",
        "        :param embeddings: (batch_size, graph_size, embed_dim)\n",
        "        :param prev_a: (batch_size, num_steps)\n",
        "        :param first_a: Only used when num_steps = 1, action of first step or None if first step\n",
        "        :return: (batch_size, num_steps, context_dim)\n",
        "        \"\"\"\n",
        "\n",
        "        current_node = self.problem.get_current_node(state)\n",
        "        batch_size, num_steps = current_node.size()\n",
        "\n",
        "        if num_steps == 1:  # We need to special case if we have only 1 step, may be the first or not\n",
        "            if state['i'][0].item() == 0: # TODO check\n",
        "                # First and only step, ignore prev_a (this is a placeholder)\n",
        "                return self.W_placeholder[None, None, :].expand(batch_size, 1, self.W_placeholder.size(-1))\n",
        "            else:\n",
        "                return embeddings.gather(\n",
        "                    1,\n",
        "                    torch.cat((state['first_a'], current_node), 1)[:, :, None].expand(batch_size, 2, embeddings.size(-1))\n",
        "                ).view(batch_size, 1, -1)\n",
        "        # More than one step, assume always starting with first\n",
        "        embeddings_per_step = embeddings.gather(\n",
        "            1,\n",
        "            current_node[:, 1:, None].expand(batch_size, num_steps - 1, embeddings.size(-1))\n",
        "        )\n",
        "        return torch.cat((\n",
        "            # First step placeholder, cat in dim 1 (time steps)\n",
        "            self.W_placeholder[None, None, :].expand(batch_size, 1, self.W_placeholder.size(-1)),\n",
        "            # Second step, concatenate embedding of first with embedding of current/previous (in dim 2, context dim)\n",
        "            torch.cat((\n",
        "                embeddings_per_step[:, 0:1, :].expand(batch_size, num_steps - 1, embeddings.size(-1)),\n",
        "                embeddings_per_step\n",
        "            ), 2)\n",
        "        ), 1)\n",
        "\n",
        "    def _one_to_many_logits(self, query, key, value, logit_K, mask):\n",
        "\n",
        "        batch_size, num_steps, embed_dim = query.size()\n",
        "        key_size = val_size = embed_dim // self.n_heads\n",
        "\n",
        "        kv = torch.stack([key, value])\n",
        "        q = rearrange(query, 'b 1 (h s) -> b 1 h s', h=self.n_heads)\n",
        "        kv = rearrange(kv, 'two h b 1 g s -> b g two h s', two=2, h=self.n_heads)     \n",
        "\n",
        "        # 1 means to keep, so we invert the mask\n",
        "        key_padding_mask = ~mask.squeeze()\n",
        "        heads = self.cross_attention(q, kv, key_padding_mask=key_padding_mask)\n",
        "        heads = rearrange(heads, 'b 1 h g -> h b 1 1 g')\n",
        "\n",
        "        # Project to get glimpse/updated context node embedding (batch_size, num_steps, embedding_dim)\n",
        "        glimpse = self.project_out(\n",
        "            heads.permute(1, 2, 3, 0, 4).contiguous().view(-1, num_steps, 1, self.n_heads * val_size))\n",
        "        \n",
        "        final_Q = glimpse\n",
        "        # Batch matrix multiplication to compute logits (batch_size, num_steps, graph_size)\n",
        "        # logits = 'compatibility'\n",
        "        logits = torch.matmul(final_Q, logit_K.transpose(-2, -1)).squeeze(-2) / math.sqrt(final_Q.size(-1))\n",
        "\n",
        "        # From the logits compute the probabilities by clipping, masking and softmax\n",
        "        if self.tanh_clipping > 0:\n",
        "            logits = torch.tanh(logits) * self.tanh_clipping\n",
        "        if self.mask_logits:\n",
        "            logits[mask] = -math.inf\n",
        "\n",
        "        return logits, glimpse.squeeze(-2)\n",
        "\n",
        "    def _get_attention_node_data(self, fixed, state):\n",
        "\n",
        "        # TSP or VRP without split delivery\n",
        "        return fixed.glimpse_key, fixed.glimpse_val, fixed.logit_key\n",
        "\n",
        "    def _make_heads(self, v, num_steps=None):\n",
        "        assert num_steps is None or v.size(1) == 1 or v.size(1) == num_steps\n",
        "\n",
        "        return (\n",
        "            v.contiguous().view(v.size(0), v.size(1), v.size(2), self.n_heads, -1)\n",
        "            .expand(v.size(0), v.size(1) if num_steps is None else num_steps, v.size(2), self.n_heads, -1)\n",
        "            .permute(3, 0, 1, 2, 4)  # (n_heads, batch_size, num_steps, graph_size, head_dim)\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test `AttentionModelBase`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AttentionModel(nn.Module):\n",
        "    def __init__(self, policy):\n",
        "        super().__init__()\n",
        "        self.policy = policy\n",
        "\n",
        "        # TODO: hydra instantiation\n",
        "        # self.policy = instantiate(cfg.policy)\n",
        "        # self.baseline = instantiate(cfg.baseline) TODO\n",
        "\n",
        "    def forward(self, td, phase: str=\"train\", decode_type: str=None):\n",
        "        \"\"\"Evaluate model, get costs and log probabilities and compare with baseline\"\"\"\n",
        "\n",
        "        # Evaluate model, get costs and log probabilities\n",
        "        cost, ll = self.policy(td)\n",
        "        bl_val, bl_loss = self.baseline.eval(td, cost)\n",
        "\n",
        "        # print(bl_val, bl_loss)\n",
        "        # Calculate loss\n",
        "        advantage = cost - bl_val\n",
        "        reinforce_loss = (advantage * ll).mean()\n",
        "        loss = reinforce_loss + bl_loss\n",
        "\n",
        "        return {'loss': loss, 'reinforce_loss': reinforce_loss, 'bl_loss': bl_loss, 'bl_val': bl_val, 'cost':cost} #, **out_policy}\n",
        "    \n",
        "    def set_decode_type(self, decode_type):\n",
        "        self.policy.set_decode_type(decode_type)\n",
        "\n",
        "    def setup(self, pl_module):\n",
        "        # Make baseline taking model itself and train_dataloader from model as input\n",
        "        # TODO make this as taken from config\n",
        "        self.baseline = instantiate({\"_target_\": \"__main__.WarmupBaseline\",\n",
        "                                    \"baseline\": {\"_target_\": \"__main__.RolloutBaseline\",                                             }\n",
        "                                    })   \n",
        "        self.baseline.setup(self.policy, pl_module.val_dataloader())                          \n",
        "        # self.baseline = NoBaseline()\n",
        "\n",
        "    def on_train_epoch_end(self, pl_module):\n",
        "        self.baseline.epoch_callback(self.policy, pl_module.val_dataloader(), pl_module.current_epoch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NCOLightningModule(L.LightningModule):\n",
        "    def __init__(self, model, lr=1e-4, batch_size=128, train_size=1000, val_size=10000):\n",
        "        super().__init__()\n",
        "\n",
        "        # TODO: hydra instantiation\n",
        "        # self.env = env\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "        self.batch_size = batch_size\n",
        "        self.train_size = train_size\n",
        "        self.val_size = val_size\n",
        "        self.setup()\n",
        "\n",
        "    def setup(self, stage=\"fit\"):\n",
        "        self.train_dataset = self._get_dataset(self.train_size)\n",
        "        self.val_dataset = self._get_dataset(self.val_size)\n",
        "        set_decode_type(self.model, \"sampling\")\n",
        "        if hasattr(self.model, \"setup\"):\n",
        "            self.model.setup(self)\n",
        "\n",
        "    def shared_step(self, batch: Any, batch_idx: int, phase: str):\n",
        "        output = self.model(batch, phase)\n",
        "        self.log(f\"{phase}/cost\", output[\"cost\"].mean(), prog_bar=True)\n",
        "        return {\"loss\": output['loss']}\n",
        "\n",
        "    def training_step(self, batch: Any, batch_idx: int):    \n",
        "        self.model.policy.set_decode_type(\"sampling\")\n",
        "        return self.shared_step(batch, batch_idx, phase='train')\n",
        "\n",
        "    def validation_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase='val')\n",
        "\n",
        "    def test_step(self, batch: Any, batch_idx: int):\n",
        "        return self.shared_step(batch, batch_idx, phase='test')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optim = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "        # TODO: scheduler\n",
        "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, total_steps)\n",
        "        return [optim] #, [scheduler]\n",
        "    \n",
        "    def train_dataloader(self):\n",
        "        return self._dataloader(self.train_dataset)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return self._dataloader(self.val_dataset)\n",
        "    \n",
        "    def on_train_epoch_end(self):\n",
        "        if hasattr(self.model, \"on_train_epoch_end\"):\n",
        "            self.model.on_train_epoch_end(self)\n",
        "        # sample new dataset\n",
        "        self.train_dataset = self._get_dataset(self.train_size) \n",
        "\n",
        "    def _get_dataset(self, size):\n",
        "    \n",
        "        class TorchDictDataset(Dataset):\n",
        "            def __init__(self, data):\n",
        "                self.data = data\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.data)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                return self.data[idx] # note: use torch.stack to get batch\n",
        "            \n",
        "\n",
        "        env = TSPEnv(n_loc=20)\n",
        "        env = env.transform()\n",
        "\n",
        "        data = env.gen_params(batch_size=size) # NOTE: need to put batch_size in a list!!\n",
        "        init_td = env.reset(data)\n",
        "        return TorchDictDataset(init_td)\n",
        "\n",
        "           \n",
        "    def _dataloader(self, dataset):\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False, # no need to shuffle, we're resampling every epoch\n",
        "            num_workers=0,\n",
        "            collate_fn=torch.stack, # we need this to stack the batches in the dataset\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_float32_matmul_precision('medium')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clear cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating baseline model on evaluation dataset\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span>model = AttentionModel(model)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>10 model = NCOLightningModule(model, batch_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">512</span>, train_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1280000</span>, val_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10000</span>)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 # Wandb Logger - we can use others as well as simply `None`</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 # logger = pl.loggers.WandbLogger(project=\"torchrl\", name=\"pendulum\")</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">12</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.batch_size = batch_size                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train_size = train_size                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.val_size = val_size                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>12 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.setup()                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, stage=<span style=\"color: #808000; text-decoration-color: #808000\">\"fit\"</span>):                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train_dataset = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_dataset(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.train_size)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.val_dataset = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_dataset(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.val_size)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 │   │   </span>set_decode_type(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model, <span style=\"color: #808000; text-decoration-color: #808000\">\"sampling\"</span>)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model, <span style=\"color: #808000; text-decoration-color: #808000\">\"setup\"</span>):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>19 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model.setup(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">shared_step</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, batch: Any, batch_idx: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>, phase: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 │   │   </span>output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(batch, phase)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">34</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">31 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.baseline = instantiate({<span style=\"color: #808000; text-decoration-color: #808000\">\"_target_\"</span>: <span style=\"color: #808000; text-decoration-color: #808000\">\"__main__.WarmupBaseline\"</span>,                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 │   │   │   │   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"baseline\"</span>: {<span style=\"color: #808000; text-decoration-color: #808000\">\"_target_\"</span>: <span style=\"color: #808000; text-decoration-color: #808000\">\"__main__.RolloutBaseline\"</span>,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 │   │   │   │   │   │   │   │   │   </span>})                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>34 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.baseline.setup(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.policy, pl_module.val_dataloader())                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 │   │   # self.baseline = NoBaseline()</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on_train_epoch_end</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, pl_module):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/botu/Dev/ncobench/notebooks/am/sanity/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_reinforce_baselines_env.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">61</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 58 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.n_epochs = n_epochs                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 59 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, model, dl):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 61 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.baseline.setup(model, dl)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 63 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">eval</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, td, cost):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/botu/Dev/ncobench/notebooks/am/sanity/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_reinforce_baselines_env.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">89</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 86 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bl_alpha = bl_alpha                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 87 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 88 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">setup</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, model, dl):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 89 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._update_model(model, dl)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 90 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 91 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_update_model</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, model, dl):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 │   │   </span>device = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(model.parameters()).device                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/botu/Dev/ncobench/notebooks/am/sanity/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_reinforce_baselines_env.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">95</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_update_model</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 92 │   │   </span>device = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(model.parameters()).device                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 93 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model = copy.deepcopy(model).to(device)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Evaluating baseline model on evaluation dataset\"</span>)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 95 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bl_vals = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.rollout(model, dl).cpu().numpy()                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mean = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bl_vals.mean()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 97 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">eval</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, td, cost):                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/botu/Dev/ncobench/notebooks/am/sanity/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_reinforce_baselines_env.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">134</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">rollout</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   │   │   </span>model.eval()                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   │   </span>device = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(model.parameters()).device <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># same as transfer_batch_to_device </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>134 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>cost = [model(batch.to(device))[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> dl]                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.cat(cost, dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/botu/Dev/ncobench/notebooks/am/sanity/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_reinforce_baselines_env.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">134</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   │   │   </span>model.eval()                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   │   </span>device = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(model.parameters()).device <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># same as transfer_batch_to_device </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>134 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>cost = [model(batch.to(device))[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> dl]                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> torch.cat(cost, dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/botu/Dev/ncobench/env/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">122</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 │   │   # Log likelyhood is calculated within the model since returning it per action do</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 │   │   # DataParallel since sequences can be of different lengths</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>122 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>ll = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._calc_log_likelihood(_log_p, pi, mask)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_pi:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cost, ll, pi                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_calc_log_likelihood</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">141</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">138 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   # Optional: mask out actions irrelevant to objective so they do not get reinforc</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> mask <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>141 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>log_p[mask] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">142 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> (log_p &gt; -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1000</span>).data.all(), <span style=\"color: #808000; text-decoration-color: #808000\">\"Logprobs should not be -inf, check sampling </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>too many indices for tensor of dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m10\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0mmodel = AttentionModel(model)                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m10 model = NCOLightningModule(model, batch_size=\u001b[94m512\u001b[0m, train_size=\u001b[94m1280000\u001b[0m, val_size=\u001b[94m10000\u001b[0m)       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m# Wandb Logger - we can use others as well as simply `None`\u001b[0m                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m# logger = pl.loggers.WandbLogger(project=\"torchrl\", name=\"pendulum\")\u001b[0m                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m12\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.batch_size = batch_size                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.train_size = train_size                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.val_size = val_size                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m12 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.setup()                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup\u001b[0m(\u001b[96mself\u001b[0m, stage=\u001b[33m\"\u001b[0m\u001b[33mfit\u001b[0m\u001b[33m\"\u001b[0m):                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.train_dataset = \u001b[96mself\u001b[0m._get_dataset(\u001b[96mself\u001b[0m.train_size)                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92msetup\u001b[0m:\u001b[94m19\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.val_dataset = \u001b[96mself\u001b[0m._get_dataset(\u001b[96mself\u001b[0m.val_size)                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0mset_decode_type(\u001b[96mself\u001b[0m.model, \u001b[33m\"\u001b[0m\u001b[33msampling\u001b[0m\u001b[33m\"\u001b[0m)                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mself\u001b[0m.model, \u001b[33m\"\u001b[0m\u001b[33msetup\u001b[0m\u001b[33m\"\u001b[0m):                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m19 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.model.setup(\u001b[96mself\u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mshared_step\u001b[0m(\u001b[96mself\u001b[0m, batch: Any, batch_idx: \u001b[96mint\u001b[0m, phase: \u001b[96mstr\u001b[0m):                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   │   \u001b[0moutput = \u001b[96mself\u001b[0m.model(batch, phase)                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92msetup\u001b[0m:\u001b[94m34\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m31 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.baseline = instantiate({\u001b[33m\"\u001b[0m\u001b[33m_target_\u001b[0m\u001b[33m\"\u001b[0m: \u001b[33m\"\u001b[0m\u001b[33m__main__.WarmupBaseline\u001b[0m\u001b[33m\"\u001b[0m,                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mbaseline\u001b[0m\u001b[33m\"\u001b[0m: {\u001b[33m\"\u001b[0m\u001b[33m_target_\u001b[0m\u001b[33m\"\u001b[0m: \u001b[33m\"\u001b[0m\u001b[33m__main__.RolloutBaseline\u001b[0m\u001b[33m\"\u001b[0m,    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   \u001b[0m})                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m34 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.baseline.setup(\u001b[96mself\u001b[0m.policy, pl_module.val_dataloader())                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# self.baseline = NoBaseline()\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mon_train_epoch_end\u001b[0m(\u001b[96mself\u001b[0m, pl_module):                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/home/botu/Dev/ncobench/notebooks/am/sanity/\u001b[0m\u001b[1;33m_reinforce_baselines_env.py\u001b[0m:\u001b[94m61\u001b[0m in \u001b[92msetup\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 58 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.n_epochs = n_epochs                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 59 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup\u001b[0m(\u001b[96mself\u001b[0m, model, dl):                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 61 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.baseline.setup(model, dl)                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92meval\u001b[0m(\u001b[96mself\u001b[0m, td, cost):                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/home/botu/Dev/ncobench/notebooks/am/sanity/\u001b[0m\u001b[1;33m_reinforce_baselines_env.py\u001b[0m:\u001b[94m89\u001b[0m in \u001b[92msetup\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 86 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.bl_alpha = bl_alpha                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 87 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 88 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup\u001b[0m(\u001b[96mself\u001b[0m, model, dl):                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 89 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._update_model(model, dl)                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 90 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 91 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_update_model\u001b[0m(\u001b[96mself\u001b[0m, model, dl):                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2m│   │   \u001b[0mdevice = \u001b[96mnext\u001b[0m(model.parameters()).device                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/home/botu/Dev/ncobench/notebooks/am/sanity/\u001b[0m\u001b[1;33m_reinforce_baselines_env.py\u001b[0m:\u001b[94m95\u001b[0m in \u001b[92m_update_model\u001b[0m      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 92 \u001b[0m\u001b[2m│   │   \u001b[0mdevice = \u001b[96mnext\u001b[0m(model.parameters()).device                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 93 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.model = copy.deepcopy(model).to(device)                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mEvaluating baseline model on evaluation dataset\u001b[0m\u001b[33m\"\u001b[0m)                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 95 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.bl_vals = \u001b[96mself\u001b[0m.rollout(model, dl).cpu().numpy()                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.mean = \u001b[96mself\u001b[0m.bl_vals.mean()                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92meval\u001b[0m(\u001b[96mself\u001b[0m, td, cost):                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/home/botu/Dev/ncobench/notebooks/am/sanity/\u001b[0m\u001b[1;33m_reinforce_baselines_env.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92mrollout\u001b[0m           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel.eval()                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   │   \u001b[0mdevice = \u001b[96mnext\u001b[0m(model.parameters()).device \u001b[2m# same as transfer_batch_to_device \u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   │   \u001b[0mcost = [model(batch.to(device))[\u001b[94m0\u001b[0m] \u001b[94mfor\u001b[0m batch \u001b[95min\u001b[0m dl]                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch.cat(cost, dim=\u001b[94m0\u001b[0m)                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/home/botu/Dev/ncobench/notebooks/am/sanity/\u001b[0m\u001b[1;33m_reinforce_baselines_env.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92m<listcomp>\u001b[0m        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel.eval()                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   │   \u001b[0mdevice = \u001b[96mnext\u001b[0m(model.parameters()).device \u001b[2m# same as transfer_batch_to_device \u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   │   \u001b[0mcost = [model(batch.to(device))[\u001b[94m0\u001b[0m] \u001b[94mfor\u001b[0m batch \u001b[95min\u001b[0m dl]                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m torch.cat(cost, dim=\u001b[94m0\u001b[0m)                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/home/botu/Dev/ncobench/env/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m:\u001b[94m122\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Log likelyhood is calculated within the model since returning it per action do\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# DataParallel since sequences can be of different lengths\u001b[0m                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m122 \u001b[2m│   │   \u001b[0mll = \u001b[96mself\u001b[0m._calc_log_likelihood(_log_p, pi, mask)                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m return_pi:                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m cost, ll, pi                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m_calc_log_likelihood\u001b[0m:\u001b[94m141\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m138 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Optional: mask out actions irrelevant to objective so they do not get reinforc\u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mask \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m141 \u001b[2m│   │   │   \u001b[0mlog_p[mask] = \u001b[94m0\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m (log_p > -\u001b[94m1000\u001b[0m).data.all(), \u001b[33m\"\u001b[0m\u001b[33mLogprobs should not be -inf, check sampling \u001b[0m   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mIndexError: \u001b[0mtoo many indices for tensor of dimension \u001b[1;36m2\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = AttentionModel2(\n",
        "    128,\n",
        "    128,\n",
        "    TSPEnv(20),\n",
        "    n_encode_layers=3,\n",
        ")\n",
        "\n",
        "model = AttentionModel(model)\n",
        "\n",
        "model = NCOLightningModule(model, batch_size=512, train_size=1280000, val_size=10000)\n",
        "\n",
        "# Wandb Logger - we can use others as well as simply `None`\n",
        "# logger = pl.loggers.WandbLogger(project=\"torchrl\", name=\"pendulum\")\n",
        "# logger = L.loggers.CSVLogger(\"logs\", name=\"tsp\")\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "# Trainer\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=epochs,\n",
        "    # precision=\"32\",\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    # logger=logger,\n",
        "    log_every_n_steps=1,   \n",
        "    gradient_clip_val=1.0, # clip gradients to avoid exploding gradients\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "trainer.fit(model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
