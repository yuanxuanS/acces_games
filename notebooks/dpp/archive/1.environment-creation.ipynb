{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DPP Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "# # Rich Traceback is a library that makes tracebacks more readable\n",
        "# from rich.traceback import install\n",
        "# install(show_locals=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import sys\n",
        "sys.path.append(2*\"../\")\n",
        "\n",
        "from collections import defaultdict\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.tensordict import TensorDict, TensorDictBase\n",
        "from torch import nn\n",
        "\n",
        "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec, BinaryDiscreteTensorSpec, UnboundedDiscreteTensorSpec\n",
        "from torchrl.envs import (\n",
        "    CatTensors,\n",
        "    EnvBase,\n",
        "    Transform,\n",
        "    TransformedEnv,\n",
        "    UnsqueezeTransform,\n",
        ")\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs, step_mdp\n",
        "\n",
        "\n",
        "from ncobench.envs.utils import make_composite_from_td, batch_to_scalar, _set_seed"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Making the custom environment\n",
        "\n",
        "Environment `_step`: this defines the state update of the TSP problem gived a TensorDict (`td` in the code) of the current state and the action to take:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _step(self, td: TensorDict) -> TensorDict:\n",
        "    current_node = td[\"action\"]\n",
        "    first_node = current_node if batch_to_scalar(td[\"i\"]) == 0 else td[\"first_node\"]\n",
        "\n",
        "    idxs = current_node[...,None] if current_node.ndim == 1 and td[\"action_mask\"].ndim == 2 else current_node\n",
        "\n",
        "    available = td[\"action_mask\"].scatter(\n",
        "        -1, idxs.expand_as(td[\"action_mask\"]), 0\n",
        "    )\n",
        "    \n",
        "    # Set done if i is greater than max_decaps\n",
        "    done = td[\"i\"] >= self.max_decaps\n",
        "    \n",
        "    # Calculate reward (minus length of path, since we want to maximize the reward -> minimize the path length)\n",
        "    # NOTE: reward is calculated outside for now via the get_reward function\n",
        "    # to calculate here need to pass action sequence or save it as state\n",
        "    reward = torch.ones_like(done) * float(\"-inf\")\n",
        "\n",
        "    # The output must be written in a ``\"next\"`` entry\n",
        "    return TensorDict(\n",
        "        {\n",
        "            \"next\": {\n",
        "                \"observation\": td[\"observation\"],\n",
        "                \"probe\": td[\"probe\"],\n",
        "                \"first_node\": first_node,\n",
        "                \"current_node\": current_node,\n",
        "                \"i\": td[\"i\"] + 1,\n",
        "                \"action_mask\": available,\n",
        "                \"reward\": reward,\n",
        "                \"done\": done,\n",
        "            }\n",
        "        },\n",
        "        td.shape,\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment Reset\n",
        "This defines the `_reset` of the TSP. It returns a TensorDict of the initial state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _reset(\n",
        "    self, td: Optional[TensorDict] = None, init_obs=None, batch_size=None\n",
        ") -> TensorDict:\n",
        "    # If no tensordict (or observations tensor) is passed, we generate a single set of hyperparameters\n",
        "    # Otherwise, we assume that the input tensordict contains all the relevant parameters to get started.\n",
        "    if batch_size is None:\n",
        "        batch_size = self.batch_size if init_obs is None else init_obs.shape[:-2]\n",
        "    batch_size = [batch_size] if isinstance(batch_size, int) else batch_size\n",
        "    device = init_obs.device if init_obs is not None else self.device\n",
        "    self.device = device\n",
        "\n",
        "    # We allow loading the initial observation from a dataset for faster loading\n",
        "    if init_obs is None:\n",
        "        init_obs = self.generate_data(batch_size=batch_size)\n",
        "\n",
        "    # Other variables\n",
        "    current_node = torch.zeros((*batch_size, 1), dtype=torch.int64, device=device)\n",
        "    i = torch.zeros((*batch_size, 1), dtype=torch.int64, device=device)\n",
        "\n",
        "    return TensorDict(\n",
        "        {\n",
        "            \"observation\": init_obs[\"observation\"],\n",
        "            \"probe\": init_obs[\"probe\"],\n",
        "            \"first_node\": current_node,\n",
        "            \"current_node\": current_node,\n",
        "            \"i\": i,\n",
        "            \"action_mask\": init_obs[\"action_mask\"],\n",
        "        },\n",
        "        batch_size=batch_size,\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment metadata \n",
        "\n",
        "This defines the input and output domains of the environment - similar to Gym's `spaces`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def _make_spec(self):\n",
        "    \"\"\"Make the observation and action specs from the parameters\"\"\"\n",
        "    self.observation_spec = CompositeSpec(\n",
        "        observation=BoundedTensorSpec(\n",
        "            minimum=self.min_loc,\n",
        "            maximum=self.max_loc,\n",
        "            shape=(self.size**2, 2),\n",
        "            dtype=torch.float32,\n",
        "        ),\n",
        "        probe=UnboundedDiscreteTensorSpec(\n",
        "            shape=(1),\n",
        "            dtype=torch.int64,\n",
        "        ),\n",
        "        first_node=UnboundedDiscreteTensorSpec(\n",
        "            shape=(1),\n",
        "            dtype=torch.int64,\n",
        "        ),\n",
        "        current_node=UnboundedDiscreteTensorSpec(\n",
        "            shape=(1),\n",
        "            dtype=torch.int64,\n",
        "        ),\n",
        "        i=UnboundedDiscreteTensorSpec(\n",
        "            shape=(1),\n",
        "            dtype=torch.int64,\n",
        "        ),\n",
        "        action_mask=UnboundedDiscreteTensorSpec(\n",
        "            # shape=(1, self.size**2),\n",
        "            shape=(self.size**2),\n",
        "            dtype=torch.bool\n",
        "        ),\n",
        "        shape=(),\n",
        "    )\n",
        "    self.input_spec = self.observation_spec.clone()\n",
        "    self.action_spec = BoundedTensorSpec(\n",
        "        shape=(1,),\n",
        "        dtype=torch.int64,\n",
        "        minimum=0,\n",
        "        maximum=self.size**2,\n",
        "    )\n",
        "    self.reward_spec = UnboundedContinuousTensorSpec(shape=(1,))\n",
        "    self.done_spec = UnboundedDiscreteTensorSpec(shape=(1,), dtype=torch.bool)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_data(self, batch_size):\n",
        "    # Create a list of observations on a grid\n",
        "    # n: number of rows and columns\n",
        "    # num_keepout: number of keepout regions\n",
        "    # return: a list of observations\n",
        "\n",
        "    m = n = self.size\n",
        "    # if int, convert to list and make it a batch for easier generation\n",
        "    batch_size = [batch_size] if isinstance(batch_size, int) else batch_size\n",
        "    batched = len(batch_size) > 0\n",
        "    bs = [1] if not batched else batch_size\n",
        "\n",
        "    # Create a list of observations on a grid\n",
        "    locs = torch.meshgrid(torch.arange(m, device=self.device), torch.arange(n, device=self.device))\n",
        "    locs = torch.stack(locs, dim=-1).reshape(-1, 2)\n",
        "    # normalize the locations by the number of rows and columns\n",
        "    locs = locs / torch.tensor([m, n], dtype=torch.float, device=self.device)\n",
        "    locs = locs[None].expand(*bs, -1, -1)\n",
        "\n",
        "    # Create available mask\n",
        "    available = torch.ones((*bs, m * n), dtype=torch.bool)\n",
        "\n",
        "    # Sample probe location from m*n\n",
        "    probe = torch.randint(m * n, size=(*bs, 1))\n",
        "    available.scatter_(1, probe, False)\n",
        "\n",
        "    # Sample keepout locations from m*n except probe\n",
        "    num_keepout = torch.randint(self.num_keepout_min, self.num_keepout_max, size=(*bs, 1), device=self.device)\n",
        "    keepouts = [torch.randperm(m * n)[:k] for k in num_keepout]\n",
        "    for i, (a, k) in enumerate(zip(available, keepouts)):\n",
        "        available[i] = a.scatter(0, k, False)\n",
        "\n",
        "    # available = available.unsqueeze(-2)\n",
        "\n",
        "    return TensorDict(\n",
        "        {\n",
        "            \"observation\": locs if batched else locs.squeeze(0),\n",
        "            \"probe\": probe if batched else probe.squeeze(0),\n",
        "            \"action_mask\": available if batched else available.squeeze(0),\n",
        "        },\n",
        "        batch_size=batch_size,\n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reward function\n",
        "\n",
        "Sometimes, we want to make it simpler to get the reward outside. Normally, each step should give a reward; but in our case, reward is $-\\infty$ unless finished The reason is that normally, we would have to collect all the previous locations and actions _inside_ the environment. But since the model already does that at the end, we can simply call the `get_reward` function to get the reward more efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decap_placement(self, pi, probe):\n",
        "    n = m = self.size # columns and rows\n",
        "    num_decap = torch.numel(pi)\n",
        "    z1 = self.raw_pdn\n",
        "    \n",
        "    decap = self.decap.reshape(-1)\n",
        "    z2 = torch.zeros((self.num_freq, num_decap, num_decap), dtype=torch.float32)\n",
        "\n",
        "    qIndx = torch.arange(num_decap)\n",
        "\n",
        "    z2[:, qIndx, qIndx] = torch.abs(decap)[:, None].repeat_interleave(z2[:, qIndx, qIndx].shape[-1], dim=-1)\n",
        "    pIndx = pi.long()\n",
        "\n",
        "    aIndx = torch.arange(len(z1[0]))\n",
        "    aIndx = torch.tensor(list(set(aIndx.tolist()) - set(pIndx.tolist())))\n",
        "\n",
        "    z1aa = z1[:, aIndx, :][:, :, aIndx]\n",
        "    z1ap = z1[:, aIndx, :][:, :, pIndx]\n",
        "    z1pa = z1[:, pIndx, :][:, :, aIndx]\n",
        "    z1pp = z1[:, pIndx, :][:, :, pIndx]\n",
        "    z2qq = z2[:, qIndx, :][:, :, qIndx]\n",
        "\n",
        "    zout = z1aa - torch.matmul(torch.matmul(z1ap, torch.inverse(z1pp + z2qq)), z1pa)\n",
        "\n",
        "    idx = torch.arange(n * m)\n",
        "    mask = torch.zeros(n * m).bool()\n",
        "    mask[pi] = True\n",
        "    mask = mask & (idx < probe)\n",
        "    probe -= mask.sum().item()\n",
        "\n",
        "    zout = zout[:, probe, probe]\n",
        "    return zout\n",
        "\n",
        "def decap_model(self, z_initial, z_final):\n",
        "    impedance_gap = torch.zeros(self.num_freq)\n",
        "\n",
        "    impedance_gap = z_initial - z_final\n",
        "    reward = torch.sum(impedance_gap * 1000000000 / self.freq)\n",
        "\n",
        "    reward = reward / 10\n",
        "    return reward\n",
        "\n",
        "def initial_impedance(self, probe):\n",
        "    zout = self.raw_pdn[:, probe, probe]\n",
        "    return zout\n",
        "\n",
        "def decap_simulator(self, probe, solution, keepout=None):\n",
        "    probe = probe.item()\n",
        "\n",
        "    assert len(solution) == len(torch.unique(solution)), \"An Element of Decap Sequence must be Unique\"\n",
        "\n",
        "    if keepout is not None:\n",
        "        keepout = torch.tensor(keepout)\n",
        "        intersect = torch.tensor(list(set(solution.tolist()) & set(keepout.tolist())))\n",
        "        assert len(intersect) == 0, \"Decap must be not placed at the keepout region\"\n",
        "\n",
        "    z_initial = self.initial_impedance(probe)\n",
        "    z_initial = torch.abs(z_initial)\n",
        "    z_final = self.decap_placement(solution, probe)\n",
        "    z_final = torch.abs(z_final)\n",
        "    reward = self.decap_model(z_initial, z_final)\n",
        "\n",
        "    return reward\n",
        "\n",
        "def get_reward(self, td, actions):\n",
        "\n",
        "    # We do the operation in a batch\n",
        "    if len(td.batch_size) == 0:\n",
        "        td = td.unsqueeze(0)\n",
        "        actions = actions.unsqueeze(0)\n",
        "\n",
        "    probes = td['probe']\n",
        "    reward = torch.stack([self.decap_simulator(p, a) for p, a in zip(probes, actions)])\n",
        "    \n",
        "    return reward"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Environment creation\n",
        "\n",
        "Here we use `EnvBase` to create the environment similarly to gym:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DPPEnv(EnvBase):\n",
        "    batch_locked = False\n",
        "    name = \"dpp\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        size: int = 10, # size of the grid (size x size)\n",
        "        min_loc: float = 0,\n",
        "        max_loc: float = 1,\n",
        "        num_freq=201,\n",
        "        num_keepout_min: int = 1,\n",
        "        num_keepout_max: int = 50,\n",
        "        max_decaps: int = 20,\n",
        "        chip_fpath=\"data/10x10_pkg_chip.npy\", \n",
        "        decap_fpath=\"data/01nF_decap.npy\", \n",
        "        freq_fpath=\"data/freq_201.npy\",\n",
        "        td_params: TensorDict = None,\n",
        "        seed: int = None,\n",
        "        device: str = \"cpu\",\n",
        "    ):\n",
        "        self.size = size\n",
        "        self.min_loc = min_loc\n",
        "        self.max_loc = max_loc\n",
        "        self.num_freq = num_freq\n",
        "        self.num_keepout_min = num_keepout_min\n",
        "        self.num_keepout_max = num_keepout_max\n",
        "        self.max_decaps = max_decaps\n",
        "\n",
        "        assert num_keepout_min <= num_keepout_max, \"num_keepout_min must be <= num_keepout_max\"\n",
        "        assert num_keepout_max <= size * size, \"num_keepout_max must be <= size * size (total number of locations)\"\n",
        "\n",
        "        with open(freq_fpath, \"rb\") as f:\n",
        "            self.freq = torch.from_numpy(np.load(f))\n",
        "        \n",
        "        with open(chip_fpath, \"rb\") as f:\n",
        "            self.raw_pdn = torch.from_numpy(np.load(f))\n",
        "\n",
        "        with open(decap_fpath, \"rb\") as f:\n",
        "            self.decap = torch.from_numpy(np.load(f)).to(torch.complex64)\n",
        "\n",
        "        super().__init__(device=device, batch_size=[])\n",
        "        # self._make_spec(td_params)\n",
        "        self._make_spec()\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "    # Helpers: _make_step and gen_params\n",
        "    # gen_params = gen_params # we don't use it for this case. See notebook 0\n",
        "    _make_spec = _make_spec\n",
        "\n",
        "    # Mandatory methods: _step, _reset and _set_seed\n",
        "    _reset = _reset\n",
        "    _step = _step\n",
        "    _set_seed = _set_seed\n",
        "\n",
        "    # Get reward\n",
        "    get_reward = get_reward\n",
        "\n",
        "    # Model\n",
        "    initial_impedance = initial_impedance\n",
        "    decap_placement = decap_placement\n",
        "    decap_model = decap_model\n",
        "    decap_simulator = decap_simulator\n",
        "    generate_data = generate_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "check_env_specs succeeded!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/botu/Dev/ncobench/env/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "env = DPPEnv(size=10)\n",
        "check_env_specs(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2])\n",
            "torch.Size([2])\n",
            "torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 2\n",
        "td = env.reset(batch_size=batch_size)\n",
        "for i in range(3):\n",
        "    td.set(\"action\", torch.tensor([i]).repeat(batch_size))\n",
        "    print(td['action'].shape)\n",
        "    td = env.step(td)['next']\n",
        "    # print(\"visited2\", td['visited'])\n",
        "    td.set(\"action\", torch.tensor([i]).repeat(batch_size))\n",
        "    td = env.step(td)['next']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1240536731811049673\n",
            "torch.Size([3, 21, 1])\n"
          ]
        }
      ],
      "source": [
        "seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "print(seed)\n",
        "env = DPPEnv(size=10, seed=seed)\n",
        "\n",
        "# Make a rollout\n",
        "rollout = env.rollout(\n",
        "    100,\n",
        "    auto_reset=False,  # we're executing the reset out of the ``rollout`` call\n",
        "    tensordict=env.reset(batch_size=[3]),\n",
        "    break_when_any_done=True\n",
        ")\n",
        "\n",
        "# Get the reward afterwards\n",
        "# observations = rollout['observation'][(rollout_['done'] == 1).squeeze()]\n",
        "# actions = rollout['action'][(rollout_['done'][:, -1] == 1).squeeze()].squeeze()\n",
        "# rewards = env.get_reward(observations, actions)\n",
        "# rollout_finished['reward'][:, -1] = rewards\n",
        "print(rollout['done'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_grid(self, decaps, probe, action_mask, ax=None, legend=True):\n",
        "    \"\"\"\n",
        "    Plot a grid of 1x1 squares representing the environment.\n",
        "    The keepout regions are the action_mask - decaps - probe\n",
        "    \"\"\"\n",
        "    settings = {\n",
        "        0: {\"color\": \"white\", \"label\": \"available\"},\n",
        "        1: {\"color\": \"grey\", \"label\": \"keepout\"},\n",
        "        2: {\"color\": \"tab:red\", \"label\": \"probe\"},\n",
        "        3: {\"color\": \"tab:blue\", \"label\": \"decap\"},\n",
        "    }\n",
        "\n",
        "    nonzero_indices = torch.nonzero(~action_mask, as_tuple=True)[0]\n",
        "    keepout = torch.cat([nonzero_indices, probe, decaps.squeeze(-1)])\n",
        "    unique_elements, counts = torch.unique(keepout, return_counts=True)\n",
        "    keepout = unique_elements[counts == 1]\n",
        "\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
        "\n",
        "    grid = np.meshgrid(np.arange(0, self.size), np.arange(0, self.size))\n",
        "    grid = np.stack(grid, axis=-1)\n",
        "\n",
        "    # Add new dimension to grid filled up with 0s\n",
        "    grid = np.concatenate([grid, np.zeros((self.size, self.size, 1))], axis=-1)\n",
        "\n",
        "    # Add keepout = 1\n",
        "    grid[keepout // self.size, keepout % self.size, 2] = 1\n",
        "    # Add probe = 2\n",
        "    grid[probe // self.size, probe % self.size, 2] = 2\n",
        "    # Add decaps = 3\n",
        "    grid[decaps // self.size, decaps % self.size, 2] = 3\n",
        "\n",
        "\n",
        "    xdim, ydim = grid.shape[0], grid.shape[1]\n",
        "    ax.imshow(np.zeros((xdim, ydim)), cmap=\"gray\")\n",
        "\n",
        "    ax.set_xlim(0, xdim)\n",
        "    ax.set_ylim(0, ydim)\n",
        "\n",
        "    for i in range(xdim):\n",
        "        for j in range(ydim):\n",
        "            color = settings[grid[i, j, 2]]['color']\n",
        "            x, y = grid[i, j, 0], grid[i, j, 1]\n",
        "            ax.add_patch(plt.Rectangle((x, y), 1, 1, color=color, linestyle=\"-\"))\n",
        "\n",
        "    # Add grid with 1x1 squares\n",
        "    ax.grid(\n",
        "        which=\"major\", axis=\"both\", linestyle=\"-\", color=\"k\", linewidth=1, alpha=0.5\n",
        "    )\n",
        "    # set 10 ticks\n",
        "    ax.set_xticks(np.arange(0, xdim, 1))\n",
        "    ax.set_yticks(np.arange(0, ydim, 1))\n",
        "\n",
        "    # Invert y axis\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    # Add legend\n",
        "    if legend:\n",
        "        num_unique = 4\n",
        "        handles = [\n",
        "            plt.Rectangle((0, 0), 1, 1, color=settings[i]['color']) for i in range(num_unique)\n",
        "        ]\n",
        "        ax.legend(\n",
        "            handles,\n",
        "            [settings[i]['label'] for i in range(num_unique)],\n",
        "            ncol=num_unique,\n",
        "            loc=\"upper center\",\n",
        "            bbox_to_anchor=(0.5, 1.1),\n",
        "        )\n",
        "\n",
        "\n",
        "td = rollout[-1]\n",
        "\n",
        "plot_grid(env, td[\"action\"].squeeze(), td[\"probe\"].squeeze(), td[\"action_mask\"][-1])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
