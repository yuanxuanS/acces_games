{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DPP environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "\n",
        "\n",
        "def decap_placement(\n",
        "    n,\n",
        "    m,\n",
        "    raw_pdn,\n",
        "    pi,\n",
        "    probing_port,\n",
        "    freq_pts,\n",
        "    fpath=\"data/01nF_decap.npy\",\n",
        "):\n",
        "    num_decap = np.size(pi)\n",
        "    probe = probing_port\n",
        "    z1 = raw_pdn\n",
        "\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        decap = np.load(f)\n",
        "    decap = decap.reshape(-1)\n",
        "    z2 = np.zeros((freq_pts, num_decap, num_decap))\n",
        "\n",
        "    ##### OLD ########\n",
        "    # qIndx = []\n",
        "    # for i in range(num_decap):\n",
        "    #     z2[:, i, i] = np.abs(decap)\n",
        "    #     qIndx.append(i)\n",
        "    # pIndx = pi.astype(int)\n",
        "    ##### OLD ########\n",
        "\n",
        "    qIndx = np.arange(num_decap)\n",
        "    z2[:, qIndx, qIndx] = np.abs(decap)[:, None].repeat(z2[:, qIndx, qIndx].shape[-1], axis=-1)\n",
        "    pIndx = pi.astype(int)\n",
        "\n",
        "    # pIndx : index of ports in z1 for connecting\n",
        "    # qIndx : index of ports in z2 for connecting\n",
        "\n",
        "    aIndx = np.arange(len(z1[0]))\n",
        "\n",
        "    aIndx = np.delete(aIndx, pIndx)\n",
        "\n",
        "    z1aa = z1[:, aIndx, :][:, :, aIndx]\n",
        "    z1ap = z1[:, aIndx, :][:, :, pIndx]\n",
        "    z1pa = z1[:, pIndx, :][:, :, aIndx]\n",
        "    z1pp = z1[:, pIndx, :][:, :, pIndx]\n",
        "    z2qq = z2[:, qIndx, :][:, :, qIndx]\n",
        "\n",
        "    zout = z1aa - np.matmul(np.matmul(z1ap, inv(z1pp + z2qq)), z1pa)\n",
        "\n",
        "    ###### OLD ########\n",
        "    # for i in range(n * m):\n",
        "    #     if i in pi:\n",
        "\n",
        "    #         if i < probing_port:\n",
        "    #             probe = probe - 1\n",
        "    ###### OLD ########\n",
        "\n",
        "    # New\n",
        "    idx = np.arange(n * m)\n",
        "    mask = np.zeros(n * m).astype(bool)\n",
        "    mask[pi] = True\n",
        "    mask = mask & (idx < probing_port)\n",
        "    probe -= mask.sum().item()\n",
        "\n",
        "    zout = zout[:, probe, probe]\n",
        "    return zout\n",
        "\n",
        "\n",
        "def decap_model(\n",
        "    z_initial, z_final, N_freq, fpath=\"data/freq_201.npy\"\n",
        "):\n",
        "\n",
        "    impedance_gap = np.zeros(N_freq)\n",
        "\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        freq = np.load(f)\n",
        "\n",
        "    ###### OLD ########\n",
        "    # reward = 0\n",
        "    # for i in range(N_freq):\n",
        "    #     impedance_gap[i] = z_initial[i] - z_final[i]\n",
        "    #     reward = reward + (impedance_gap[i] * 1000000000 / freq[i])\n",
        "    ###### OLD ########\n",
        "\n",
        "    impedance_gap = z_initial - z_final\n",
        "    reward = np.sum(impedance_gap * 1000000000 / freq)\n",
        "\n",
        "    reward = reward / 10\n",
        "    return reward\n",
        "\n",
        "\n",
        "def initial_impedance(n, m, raw_pdn, probe):\n",
        "\n",
        "    zout = raw_pdn[:, probe, probe]\n",
        "\n",
        "    return zout\n",
        "\n",
        "\n",
        "def decap_sim(\n",
        "    probe,\n",
        "    solution,\n",
        "    keepout=None,\n",
        "    N=10,\n",
        "    N_freq=201,\n",
        "    fpath=\"data/10x10_pkg_chip.npy\",\n",
        "):\n",
        "\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        raw_pdn = np.load(f)\n",
        "    solution = np.array(solution)\n",
        "\n",
        "    assert len(solution) == len(\n",
        "        np.unique(solution)\n",
        "    ), \"An Element of Decap Sequence must be Unique\"\n",
        "\n",
        "    if keepout is not None:\n",
        "        keepout = np.array(keepout)\n",
        "        intersect = np.intersect1d(solution, keepout)\n",
        "        assert len(intersect) == 0, \"Decap must be not placed at the keepout region\"\n",
        "\n",
        "    z_initial = initial_impedance(N, N, raw_pdn, probe)\n",
        "    z_initial = np.abs(z_initial)\n",
        "    z_final = decap_placement(N, N, raw_pdn, solution, probe, N_freq)\n",
        "    z_final = np.abs(z_final)\n",
        "    reward = decap_model(z_initial, z_final, N_freq)\n",
        "\n",
        "    return reward"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "reward = decap_sim(probe = 23, solution = [1,5,7,21], keepout = [2,3,10])\n",
        "\n",
        "\n",
        "Test reward: `6.684142842810994`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.684142842811002\n"
          ]
        }
      ],
      "source": [
        "reward = decap_sim(probe = 23, solution = [1,5,7,21], keepout = [2,3,10])\n",
        "print(reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.  0. ]\n",
            " [0.1 0. ]\n",
            " [0.2 0. ]\n",
            " [0.3 0. ]\n",
            " [0.4 0. ]\n",
            " [0.5 0. ]\n",
            " [0.6 0. ]\n",
            " [0.7 0. ]\n",
            " [0.8 0. ]\n",
            " [0.9 0. ]\n",
            " [0.  0.1]\n",
            " [0.1 0.1]\n",
            " [0.2 0.1]\n",
            " [0.3 0.1]\n",
            " [0.4 0.1]\n",
            " [0.5 0.1]\n",
            " [0.6 0.1]\n",
            " [0.7 0.1]\n",
            " [0.8 0.1]\n",
            " [0.9 0.1]\n",
            " [0.  0.2]\n",
            " [0.1 0.2]\n",
            " [0.2 0.2]\n",
            " [0.3 0.2]\n",
            " [0.4 0.2]\n",
            " [0.5 0.2]\n",
            " [0.6 0.2]\n",
            " [0.7 0.2]\n",
            " [0.8 0.2]\n",
            " [0.9 0.2]\n",
            " [0.  0.3]\n",
            " [0.1 0.3]\n",
            " [0.2 0.3]\n",
            " [0.3 0.3]\n",
            " [0.4 0.3]\n",
            " [0.5 0.3]\n",
            " [0.6 0.3]\n",
            " [0.7 0.3]\n",
            " [0.8 0.3]\n",
            " [0.9 0.3]\n",
            " [0.  0.4]\n",
            " [0.1 0.4]\n",
            " [0.2 0.4]\n",
            " [0.3 0.4]\n",
            " [0.4 0.4]\n",
            " [0.5 0.4]\n",
            " [0.6 0.4]\n",
            " [0.7 0.4]\n",
            " [0.8 0.4]\n",
            " [0.9 0.4]\n",
            " [0.  0.5]\n",
            " [0.1 0.5]\n",
            " [0.2 0.5]\n",
            " [0.3 0.5]\n",
            " [0.4 0.5]\n",
            " [0.5 0.5]\n",
            " [0.6 0.5]\n",
            " [0.7 0.5]\n",
            " [0.8 0.5]\n",
            " [0.9 0.5]\n",
            " [0.  0.6]\n",
            " [0.1 0.6]\n",
            " [0.2 0.6]\n",
            " [0.3 0.6]\n",
            " [0.4 0.6]\n",
            " [0.5 0.6]\n",
            " [0.6 0.6]\n",
            " [0.7 0.6]\n",
            " [0.8 0.6]\n",
            " [0.9 0.6]\n",
            " [0.  0.7]\n",
            " [0.1 0.7]\n",
            " [0.2 0.7]\n",
            " [0.3 0.7]\n",
            " [0.4 0.7]\n",
            " [0.5 0.7]\n",
            " [0.6 0.7]\n",
            " [0.7 0.7]\n",
            " [0.8 0.7]\n",
            " [0.9 0.7]\n",
            " [0.  0.8]\n",
            " [0.1 0.8]\n",
            " [0.2 0.8]\n",
            " [0.3 0.8]\n",
            " [0.4 0.8]\n",
            " [0.5 0.8]\n",
            " [0.6 0.8]\n",
            " [0.7 0.8]\n",
            " [0.8 0.8]\n",
            " [0.9 0.8]\n",
            " [0.  0.9]\n",
            " [0.1 0.9]\n",
            " [0.2 0.9]\n",
            " [0.3 0.9]\n",
            " [0.4 0.9]\n",
            " [0.5 0.9]\n",
            " [0.6 0.9]\n",
            " [0.7 0.9]\n",
            " [0.8 0.9]\n",
            " [0.9 0.9]] [False  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True False False  True  True False False  True False\n",
            " False  True  True False False  True  True False  True False  True False\n",
            " False  True  True  True  True  True False  True  True False  True  True\n",
            " False False  True  True  True False False  True  True False  True  True\n",
            "  True  True  True  True False  True  True  True  True  True  True  True\n",
            " False  True  True  True  True  True False  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True False  True False False  True\n",
            " False False  True False] 78\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1272563/925642795.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  available = np.ones((m * n), dtype=np.bool)\n"
          ]
        }
      ],
      "source": [
        "def generate_init_conditions(m=10, n=10, num_keepout_min=1, num_keepout_max=50):\n",
        "    # Create a list of observations on a grid\n",
        "    # n: number of rows and columns\n",
        "    # num_keepout: number of keepout regions\n",
        "    # return: a list of observations\n",
        "\n",
        "    # Create a list of observations on a grid\n",
        "    locs = np.meshgrid(np.arange(m), np.arange(n))\n",
        "    locs = np.stack(locs, axis=-1).reshape(-1, 2)\n",
        "    # normalize the locations by the number of rows and columns\n",
        "    locs = locs / np.array([m, n])\n",
        "\n",
        "    # Create available mask\n",
        "    available = np.ones((m * n), dtype=np.bool)\n",
        "\n",
        "    # Sample probe location from m*n\n",
        "    probe = np.random.choice(np.arange(m * n))\n",
        "    available[probe] = False\n",
        "\n",
        "    # Sample keepout locations from m*n except probe\n",
        "    num_keepout = np.random.randint(num_keepout_min, num_keepout_max)\n",
        "    keepout = np.random.choice(np.arange(m * n), num_keepout, replace=False)\n",
        "    available[keepout] = False\n",
        "\n",
        "    return locs, available, probe\n",
        "\n",
        "\n",
        "locs, available, probe = generate_init_conditions()\n",
        "print(locs, available, probe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import inv\n",
        "\n",
        "\n",
        "def decap_placement(\n",
        "    n,\n",
        "    m,\n",
        "    raw_pdn,\n",
        "    pi,\n",
        "    probing_port,\n",
        "    freq_pts,\n",
        "    fpath=\"data/01nF_decap.npy\",\n",
        "):\n",
        "    num_decap = np.size(pi)\n",
        "    probe = probing_port\n",
        "    z1 = raw_pdn\n",
        "\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        decap = np.load(f)\n",
        "    decap = decap.reshape(-1)\n",
        "    z2 = np.zeros((freq_pts, num_decap, num_decap))\n",
        "\n",
        "\n",
        "    qIndx = np.arange(num_decap)\n",
        "    z2[:, qIndx, qIndx] = np.abs(decap)[:, None].repeat(z2[:, qIndx, qIndx].shape[-1], axis=-1)\n",
        "    pIndx = pi.astype(int)\n",
        "\n",
        "    # pIndx : index of ports in z1 for connecting\n",
        "    # qIndx : index of ports in z2 for connecting\n",
        "\n",
        "    aIndx = np.arange(len(z1[0]))\n",
        "\n",
        "    aIndx = np.delete(aIndx, pIndx)\n",
        "\n",
        "    z1aa = z1[:, aIndx, :][:, :, aIndx]\n",
        "    z1ap = z1[:, aIndx, :][:, :, pIndx]\n",
        "    z1pa = z1[:, pIndx, :][:, :, aIndx]\n",
        "    z1pp = z1[:, pIndx, :][:, :, pIndx]\n",
        "    z2qq = z2[:, qIndx, :][:, :, qIndx]\n",
        "\n",
        "    zout = z1aa - np.matmul(np.matmul(z1ap, inv(z1pp + z2qq)), z1pa)\n",
        "\n",
        "    # New\n",
        "    idx = np.arange(n * m)\n",
        "    mask = np.zeros(n * m).astype(bool)\n",
        "    mask[pi] = True\n",
        "    mask = mask & (idx < probing_port)\n",
        "    probe -= mask.sum().item()\n",
        "\n",
        "    zout = zout[:, probe, probe]\n",
        "    return zout\n",
        "\n",
        "\n",
        "def decap_model(\n",
        "    z_initial, z_final, N_freq, fpath=\"data/freq_201.npy\"\n",
        "):\n",
        "\n",
        "    impedance_gap = np.zeros(N_freq)\n",
        "\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        freq = np.load(f)\n",
        "        \n",
        "    impedance_gap = z_initial - z_final\n",
        "    reward = np.sum(impedance_gap * 1000000000 / freq)\n",
        "\n",
        "    reward = reward / 10\n",
        "    return reward\n",
        "\n",
        "\n",
        "def initial_impedance(n, m, raw_pdn, probe):\n",
        "\n",
        "    zout = raw_pdn[:, probe, probe]\n",
        "\n",
        "    return zout\n",
        "\n",
        "\n",
        "def decap_sim(\n",
        "    probe,\n",
        "    solution,\n",
        "    keepout=None,\n",
        "    N=10,\n",
        "    N_freq=201,\n",
        "    fpath=\"data/10x10_pkg_chip.npy\",\n",
        "):\n",
        "\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        raw_pdn = np.load(f)\n",
        "    solution = np.array(solution)\n",
        "\n",
        "    assert len(solution) == len(\n",
        "        np.unique(solution)\n",
        "    ), \"An Element of Decap Sequence must be Unique\"\n",
        "\n",
        "    if keepout is not None:\n",
        "        keepout = np.array(keepout)\n",
        "        intersect = np.intersect1d(solution, keepout)\n",
        "        assert len(intersect) == 0, \"Decap must be not placed at the keepout region\"\n",
        "\n",
        "    z_initial = initial_impedance(N, N, raw_pdn, probe)\n",
        "    z_initial = np.abs(z_initial)\n",
        "    z_final = decap_placement(N, N, raw_pdn, solution, probe, N_freq)\n",
        "    z_final = np.abs(z_final)\n",
        "    reward = decap_model(z_initial, z_final, N_freq)\n",
        "\n",
        "    return reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.684142842811002\n"
          ]
        }
      ],
      "source": [
        "reward = decap_sim(probe = 23, solution = [1,5,7,21], keepout = [2,3,10])\n",
        "print(reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def decap_placement(n, m, raw_pdn, pi, probing_port, freq_pts, fpath=\"data/01nF_decap.npy\"):\n",
        "    num_decap = torch.numel(pi)\n",
        "    probe = probing_port\n",
        "    z1 = raw_pdn\n",
        "\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        decap = torch.from_numpy(np.load(f)).to(torch.complex64)\n",
        "    decap = decap.reshape(-1)\n",
        "    z2 = torch.zeros((freq_pts, num_decap, num_decap), dtype=torch.float32)\n",
        "\n",
        "    qIndx = torch.arange(num_decap)\n",
        "\n",
        "    z2[:, qIndx, qIndx] = torch.abs(decap)[:, None].repeat_interleave(z2[:, qIndx, qIndx].shape[-1], dim=-1)\n",
        "    pIndx = pi.long()\n",
        "\n",
        "    aIndx = torch.arange(len(z1[0]))\n",
        "    aIndx = torch.tensor(list(set(aIndx.tolist()) - set(pIndx.tolist())))\n",
        "\n",
        "    z1aa = z1[:, aIndx, :][:, :, aIndx]\n",
        "    z1ap = z1[:, aIndx, :][:, :, pIndx]\n",
        "    z1pa = z1[:, pIndx, :][:, :, aIndx]\n",
        "    z1pp = z1[:, pIndx, :][:, :, pIndx]\n",
        "    z2qq = z2[:, qIndx, :][:, :, qIndx]\n",
        "\n",
        "    zout = z1aa - torch.matmul(torch.matmul(z1ap, torch.inverse(z1pp + z2qq)), z1pa)\n",
        "\n",
        "    idx = torch.arange(n * m)\n",
        "    mask = torch.zeros(n * m).bool()\n",
        "    mask[pi] = True\n",
        "    mask = mask & (idx < probing_port)\n",
        "    probe -= mask.sum().item()\n",
        "\n",
        "    zout = zout[:, probe, probe]\n",
        "    return zout\n",
        "\n",
        "\n",
        "def decap_model(z_initial, z_final, N_freq, fpath=\"data/freq_201.npy\"):\n",
        "    impedance_gap = torch.zeros(N_freq)\n",
        "\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        freq = torch.from_numpy(np.load(f))\n",
        "        \n",
        "    impedance_gap = z_initial - z_final\n",
        "    reward = torch.sum(impedance_gap * 1000000000 / freq)\n",
        "\n",
        "    reward = reward / 10\n",
        "    return reward\n",
        "\n",
        "\n",
        "def initial_impedance(n, m, raw_pdn, probe):\n",
        "    zout = raw_pdn[:, probe, probe]\n",
        "    return zout\n",
        "\n",
        "\n",
        "def decap_sim(probe, solution, keepout=None, N=10, N_freq=201, fpath=\"data/10x10_pkg_chip.npy\"):\n",
        "    with open(fpath, \"rb\") as f:\n",
        "        raw_pdn = torch.from_numpy(np.load(f))\n",
        "    solution = torch.tensor(solution)\n",
        "\n",
        "    assert len(solution) == len(torch.unique(solution)), \"An Element of Decap Sequence must be Unique\"\n",
        "\n",
        "    if keepout is not None:\n",
        "        keepout = torch.tensor(keepout)\n",
        "        intersect = torch.tensor(list(set(solution.tolist()) & set(keepout.tolist())))\n",
        "        assert len(intersect) == 0, \"Decap must be not placed at the keepout region\"\n",
        "\n",
        "    z_initial = initial_impedance(N, N, raw_pdn, probe)\n",
        "    z_initial = torch.abs(z_initial)\n",
        "    z_final = decap_placement(N, N, raw_pdn, solution, probe, N_freq)\n",
        "    z_final = torch.abs(z_final)\n",
        "    reward = decap_model(z_initial, z_final, N_freq)\n",
        "\n",
        "    return reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.6841, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "reward = decap_sim(probe = 23, solution = [1,5,7,21], keepout = [2,3,10])\n",
        "print(reward)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passing tensors instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.6841, dtype=torch.float64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1272563/800108083.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  keepout = torch.tensor(keepout)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class DecapSimulator:\n",
        "\n",
        "    def __init__(self, num=10, num_freq=201, chip_fpath=\"data/10x10_pkg_chip.npy\", decap_fpath=\"data/01nF_decap.npy\", freq_fpath=\"data/freq_201.npy\"):\n",
        "\n",
        "        self.num = num\n",
        "        self.num_freq = num_freq\n",
        "\n",
        "        with open(freq_fpath, \"rb\") as f:\n",
        "            self.freq = torch.from_numpy(np.load(f))\n",
        "        \n",
        "        with open(chip_fpath, \"rb\") as f:\n",
        "            self.raw_pdn = torch.from_numpy(np.load(f))\n",
        "\n",
        "        with open(decap_fpath, \"rb\") as f:\n",
        "            self.decap = torch.from_numpy(np.load(f)).to(torch.complex64)\n",
        "    \n",
        "    def decap_placement(self, pi, probing_port):\n",
        "        n = m = self.num # columns and rows\n",
        "        num_decap = torch.numel(pi)\n",
        "        probe = probing_port\n",
        "        z1 = self.raw_pdn\n",
        "        \n",
        "        decap = self.decap.reshape(-1)\n",
        "        z2 = torch.zeros((self.num_freq, num_decap, num_decap), dtype=torch.float32)\n",
        "\n",
        "        qIndx = torch.arange(num_decap)\n",
        "\n",
        "        z2[:, qIndx, qIndx] = torch.abs(decap)[:, None].repeat_interleave(z2[:, qIndx, qIndx].shape[-1], dim=-1)\n",
        "        pIndx = pi.long()\n",
        "\n",
        "        ####### OLD CODE #######\n",
        "        aIndx = torch.arange(len(z1[0]))\n",
        "        aIndx = torch.tensor(list(set(aIndx.tolist()) - set(pIndx.tolist())))\n",
        "        ####### OLD CODE #######\n",
        "\n",
        "        # batch_size = 1\n",
        "        # aIndx_batch = torch.arange(len(z1[0])).unsqueeze(0).repeat(batch_size, 1)\n",
        "        # pIndx_batch = pIndx.unsqueeze(0).repeat(batch_size, 1)\n",
        "        # mask_batch = torch.ones_like(aIndx_batch).scatter(1, pIndx_batch, 0)\n",
        "        # aIndx_batch = torch.index_select(aIndx_batch, 1, mask_batch.nonzero()[:, 1])\n",
        "        # aIndx = aIndx_batch[0]\n",
        "\n",
        "        # # batched selection\n",
        "        # aIndx = aIndx.unsqueeze(0).repeat(batch_size, 1)\n",
        "        # pIndx = pIndx.unsqueeze(0).repeat(batch_size, 1)\n",
        "\n",
        "        # z1aa = torch.gather(z1, 1, aIndx.unsqueeze(2).repeat(1, 1, len(aIndx)))\n",
        "        # num_indices = aIndx.shape[-1]\n",
        "        # z1aa = torch.gather(z1, 1, aIndx.unsqueeze(-1).repeat(1, 1, num_indices))\n",
        "        # print(z1aa.shape)\n",
        "        # z1aa = torch.gather(z1aa, 2, aIndx.unsqueeze(1).repeat(1, num_indices, 1))\n",
        "        # print(z1aa.shape)\n",
        "\n",
        "        # aIndx = aIndx[0]\n",
        "        # pIndx = pIndx[0]\n",
        "\n",
        "\n",
        "        z1aa = z1[:, aIndx, :][:, :, aIndx]\n",
        "        z1ap = z1[:, aIndx, :][:, :, pIndx]\n",
        "        z1pa = z1[:, pIndx, :][:, :, aIndx]\n",
        "        z1pp = z1[:, pIndx, :][:, :, pIndx]\n",
        "        z2qq = z2[:, qIndx, :][:, :, qIndx]\n",
        "\n",
        "        zout = z1aa - torch.matmul(torch.matmul(z1ap, torch.inverse(z1pp + z2qq)), z1pa)\n",
        "\n",
        "        idx = torch.arange(n * m)\n",
        "        mask = torch.zeros(n * m).bool()\n",
        "        mask[pi] = True\n",
        "        mask = mask & (idx < probing_port)\n",
        "        probe -= mask.sum().item()\n",
        "\n",
        "        zout = zout[:, probe, probe]\n",
        "        return zout\n",
        "\n",
        "    def decap_model(self, z_initial, z_final):\n",
        "        impedance_gap = torch.zeros(self.num_freq)\n",
        "\n",
        "        impedance_gap = z_initial - z_final\n",
        "        reward = torch.sum(impedance_gap * 1000000000 / self.freq)\n",
        "\n",
        "        reward = reward / 10\n",
        "        return reward\n",
        "\n",
        "    def initial_impedance(self, probe):\n",
        "        zout = self.raw_pdn[:, probe, probe]\n",
        "        return zout\n",
        "\n",
        "    def decap_sim(self, probe, solution, keepout=None):\n",
        "        probe = probe.item()\n",
        "\n",
        "        assert len(solution) == len(torch.unique(solution)), \"An Element of Decap Sequence must be Unique\"\n",
        "\n",
        "        if keepout is not None:\n",
        "            keepout = torch.tensor(keepout)\n",
        "            intersect = torch.tensor(list(set(solution.tolist()) & set(keepout.tolist())))\n",
        "            assert len(intersect) == 0, \"Decap must be not placed at the keepout region\"\n",
        "\n",
        "        z_initial = self.initial_impedance(probe)\n",
        "        z_initial = torch.abs(z_initial)\n",
        "        z_final = self.decap_placement(solution, probe)\n",
        "        z_final = torch.abs(z_final)\n",
        "        reward = self.decap_model(z_initial, z_final)\n",
        "\n",
        "        return reward\n",
        "\n",
        "\n",
        "env = DecapSimulator()\n",
        "\n",
        "probe = torch.Tensor([23]).long()\n",
        "solution = torch.Tensor([1,5,7,21]).long()\n",
        "keepout = torch.Tensor([2,3,10]).long()\n",
        "\n",
        "reward = env.decap_sim(probe, solution, keepout)\n",
        "print(reward)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor(6.6841, dtype=torch.float64)\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n",
            "tensor([ 1,  5,  7, 21])\n",
            "23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1272563/987756417.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  keepout = torch.tensor(keepout)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class DecapSimulator:\n",
        "\n",
        "    def __init__(self, num=10, num_freq=201, chip_fpath=\"data/10x10_pkg_chip.npy\", decap_fpath=\"data/01nF_decap.npy\", freq_fpath=\"data/freq_201.npy\"):\n",
        "\n",
        "        self.size = num\n",
        "        self.num_freq = num_freq\n",
        "\n",
        "        with open(freq_fpath, \"rb\") as f:\n",
        "            self.freq = torch.from_numpy(np.load(f))\n",
        "        \n",
        "        with open(chip_fpath, \"rb\") as f:\n",
        "            self.raw_pdn = torch.from_numpy(np.load(f))\n",
        "\n",
        "        with open(decap_fpath, \"rb\") as f:\n",
        "            self.decap = torch.from_numpy(np.load(f)).to(torch.complex64)\n",
        "    \n",
        "    def decap_placement(self, pi, probe):\n",
        "        n = m = self.size # columns and rows\n",
        "        num_decap = torch.numel(pi)\n",
        "        z1 = self.raw_pdn\n",
        "        \n",
        "        decap = self.decap.reshape(-1)\n",
        "        z2 = torch.zeros((self.num_freq, num_decap, num_decap), dtype=torch.float32)\n",
        "\n",
        "        qIndx = torch.arange(num_decap)\n",
        "\n",
        "        z2[:, qIndx, qIndx] = torch.abs(decap)[:, None].repeat_interleave(z2[:, qIndx, qIndx].shape[-1], dim=-1)\n",
        "        pIndx = pi.long()\n",
        "\n",
        "        aIndx = torch.arange(len(z1[0]))\n",
        "        aIndx = torch.tensor(list(set(aIndx.tolist()) - set(pIndx.tolist())))\n",
        "\n",
        "        z1aa = z1[:, aIndx, :][:, :, aIndx]\n",
        "        z1ap = z1[:, aIndx, :][:, :, pIndx]\n",
        "        z1pa = z1[:, pIndx, :][:, :, aIndx]\n",
        "        z1pp = z1[:, pIndx, :][:, :, pIndx]\n",
        "        z2qq = z2[:, qIndx, :][:, :, qIndx]\n",
        "\n",
        "        zout = z1aa - torch.matmul(torch.matmul(z1ap, torch.inverse(z1pp + z2qq)), z1pa)\n",
        "\n",
        "        idx = torch.arange(n * m)\n",
        "        mask = torch.zeros(n * m).bool()\n",
        "        mask[pi] = True\n",
        "        mask = mask & (idx < probe)\n",
        "        probe -= mask.sum().item()\n",
        "\n",
        "        zout = zout[:, probe, probe]\n",
        "        return zout\n",
        "\n",
        "    def decap_model(self, z_initial, z_final):\n",
        "        impedance_gap = torch.zeros(self.num_freq)\n",
        "\n",
        "        impedance_gap = z_initial - z_final\n",
        "        reward = torch.sum(impedance_gap * 1000000000 / self.freq)\n",
        "\n",
        "        reward = reward / 10\n",
        "        return reward\n",
        "\n",
        "    def initial_impedance(self, probe):\n",
        "        zout = self.raw_pdn[:, probe, probe]\n",
        "        return zout\n",
        "\n",
        "    def decap_sim(self, probe, solution, keepout=None):\n",
        "        probe = probe.item()\n",
        "\n",
        "        print(solution)\n",
        "        print(probe)\n",
        "\n",
        "        assert len(solution) == len(torch.unique(solution)), \"An Element of Decap Sequence must be Unique\"\n",
        "\n",
        "        if keepout is not None:\n",
        "            keepout = torch.tensor(keepout)\n",
        "            intersect = torch.tensor(list(set(solution.tolist()) & set(keepout.tolist())))\n",
        "            assert len(intersect) == 0, \"Decap must be not placed at the keepout region\"\n",
        "\n",
        "        z_initial = self.initial_impedance(probe)\n",
        "        z_initial = torch.abs(z_initial)\n",
        "        z_final = self.decap_placement(solution, probe)\n",
        "        z_final = torch.abs(z_final)\n",
        "        reward = self.decap_model(z_initial, z_final)\n",
        "\n",
        "        return reward\n",
        "\n",
        "env = DecapSimulator()\n",
        "\n",
        "probe = torch.Tensor([23]).long()\n",
        "solution = torch.Tensor([1,5,7,21]).long()\n",
        "keepout = torch.Tensor([2,3,10]).long()\n",
        "\n",
        "reward = env.decap_sim(probe, solution, keepout)\n",
        "print(reward)\n",
        "\n",
        "\n",
        "# Batched\n",
        "probe = probe.repeat(32, 1)\n",
        "solution = solution.repeat(32, 1)\n",
        "keepout = keepout.repeat(32, 1)\n",
        "\n",
        "rewards = [r for r in map(env.decap_sim, probe, solution, keepout)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64), tensor(6.6841, dtype=torch.float64)]\n"
          ]
        }
      ],
      "source": [
        "print(rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1]) torch.Size([5, 100])\n",
            "torch.Size([5, 100, 2]) torch.Size([5, 100]) torch.Size([5, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def generate_init_conditions(batch_size, m=10, n=10, num_keepout_min=1, num_keepout_max=50):\n",
        "    # Create a list of observations on a grid\n",
        "    # n: number of rows and columns\n",
        "    # num_keepout: number of keepout regions\n",
        "    # return: a list of observations\n",
        "\n",
        "    # Create a list of observations on a grid\n",
        "    batch_size = [batch_size] if isinstance(batch_size, int) else batch_size\n",
        "\n",
        "    locs = torch.meshgrid(torch.arange(m), torch.arange(n))\n",
        "    locs = torch.stack(locs, dim=-1).reshape(-1, 2)\n",
        "    # normalize the locations by the number of rows and columns\n",
        "    locs = locs / torch.tensor([m, n], dtype=torch.float)\n",
        "\n",
        "    # Create available mask\n",
        "    available = torch.ones((*batch_size, m * n), dtype=torch.bool)\n",
        "\n",
        "    # Sample probe location from m*n\n",
        "    probe = torch.randint(m * n, size=(*batch_size, 1))\n",
        "    available.scatter_(1, probe, False)\n",
        "\n",
        "    # Sample keepout locations from m*n except probe\n",
        "    num_keepout = torch.randint(num_keepout_min, num_keepout_max, size=(*batch_size, 1))\n",
        "\n",
        "    print(num_keepout.shape, available.shape)\n",
        "    keepouts = [torch.randperm(m * n)[:k] for k in num_keepout]\n",
        "    for i, (a, k) in enumerate(zip(available, keepouts)):\n",
        "        available[i] = a.scatter(0, k, False)\n",
        "    # num_keepout = torch.randint(num_keepout_min, num_keepout_max, size=(batch_size, 1))\n",
        "    # keepout_mask = torch.zeros((batch_size, m * n), dtype=torch.bool)\n",
        "\n",
        "    # for b in range(batch_size):\n",
        "    #     keepouts = torch.randperm(m * n)[:num_keepout[b]]\n",
        "    #     keepout_mask[b, keepouts] = True\n",
        "\n",
        "    # available.masked_fill_(keepout_mask, False)\n",
        "\n",
        "    return locs.unsqueeze(0).repeat(*batch_size, 1, 1), available, probe\n",
        "\n",
        "\n",
        "batch_size = 5\n",
        "locs, available, probe = generate_init_conditions(batch_size)\n",
        "print(locs.shape, available.shape, probe.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([81, 86, 63, 91, 63])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# \n",
        "torch.count_nonzero(available, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1272563/2210145885.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  keepout = torch.tensor(keepout)\n"
          ]
        }
      ],
      "source": [
        "rewards = [r for r in map(env.decap_sim, probe, solution, keepout)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batched environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unhashable type: 'list'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[51], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m keepout \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([[\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m10\u001b[39m]])\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mrepeat(\u001b[39m32\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39m# Get reward for the batched input\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m reward \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mdecap_sim(probe, solution, keepout)\n\u001b[1;32m     89\u001b[0m \u001b[39mprint\u001b[39m(reward)\n",
            "Cell \u001b[0;32mIn[51], line 75\u001b[0m, in \u001b[0;36mDecapSimulator.decap_sim\u001b[0;34m(self, probe, solution, keepout)\u001b[0m\n\u001b[1;32m     73\u001b[0m z_initial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitial_impedance(probe)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mswapaxes(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m z_initial \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs(z_initial)\n\u001b[0;32m---> 75\u001b[0m z_final \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecap_placement(solution, probe)\n\u001b[1;32m     76\u001b[0m z_final \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs(z_final)\n\u001b[1;32m     77\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecap_model(z_initial, z_final)\n",
            "Cell \u001b[0;32mIn[51], line 35\u001b[0m, in \u001b[0;36mDecapSimulator.decap_placement\u001b[0;34m(self, pi, probe)\u001b[0m\n\u001b[1;32m     32\u001b[0m pIndx \u001b[39m=\u001b[39m pi\u001b[39m.\u001b[39mlong()\n\u001b[1;32m     34\u001b[0m aIndx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(z1[\u001b[39m0\u001b[39m]))[\u001b[39mNone\u001b[39;00m]\u001b[39m.\u001b[39mexpand(\u001b[39m*\u001b[39mbatch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m aIndx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39;49m(aIndx\u001b[39m.\u001b[39;49mtolist()) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(pIndx\u001b[39m.\u001b[39mtolist())))\n\u001b[1;32m     37\u001b[0m z1aa \u001b[39m=\u001b[39m z1[:, aIndx, :][:, :, aIndx]\n\u001b[1;32m     38\u001b[0m z1ap \u001b[39m=\u001b[39m z1[:, aIndx, :][:, :, pIndx]\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class DecapSimulator:\n",
        "    def __init__(self, num=10, num_freq=201, chip_fpath=\"data/10x10_pkg_chip.npy\", decap_fpath=\"data/01nF_decap.npy\", freq_fpath=\"data/freq_201.npy\"):\n",
        "        self.num = num\n",
        "        self.num_freq = num_freq\n",
        "\n",
        "        with open(freq_fpath, \"rb\") as f:\n",
        "            self.freq = torch.from_numpy(np.load(f))\n",
        "        \n",
        "        with open(chip_fpath, \"rb\") as f:\n",
        "            self.raw_pdn = torch.from_numpy(np.load(f))\n",
        "\n",
        "        with open(decap_fpath, \"rb\") as f:\n",
        "            self.decap = torch.from_numpy(np.load(f)).to(torch.complex64)\n",
        "    \n",
        "    def decap_placement(self, pi, probe):\n",
        "        \n",
        "        batch_size = pi.shape[:-1]\n",
        "\n",
        "        n = m = self.num # columns and rows\n",
        "        num_decap = pi.shape[-1] # we consider the num_decap the same in the batch\n",
        "        z1 = self.raw_pdn\n",
        "        \n",
        "        decap = self.decap.reshape(-1)\n",
        "        z2 = torch.zeros((self.num_freq, num_decap, num_decap), dtype=torch.float32)\n",
        "\n",
        "        qIndx = torch.arange(num_decap)\n",
        "\n",
        "        z2[:, qIndx, qIndx] = torch.abs(decap)[:, None].repeat_interleave(z2[:, qIndx, qIndx].shape[-1], dim=-1)\n",
        "        pIndx = pi.long()\n",
        "        \n",
        "        aIndx = torch.arange(len(z1[0]))[None].expand(*batch_size, -1)\n",
        "        aIndx = torch.tensor(list(set(aIndx.tolist()) - set(pIndx.tolist())))\n",
        "\n",
        "        z1aa = z1[:, aIndx, :][:, :, aIndx]\n",
        "        z1ap = z1[:, aIndx, :][:, :, pIndx]\n",
        "        z1pa = z1[:, pIndx, :][:, :, aIndx]\n",
        "        z1pp = z1[:, pIndx, :][:, :, pIndx]\n",
        "        z2qq = z2[:, :, qIndx, :][:, :, :, qIndx]\n",
        "\n",
        "        zout = z1aa - torch.matmul(torch.matmul(z1ap, torch.inverse(z1pp + z2qq)), z1pa)\n",
        "\n",
        "        idx = torch.arange(n * m)\n",
        "        mask = torch.zeros(batch_size, n * m).bool()\n",
        "        mask[:, pi] = True\n",
        "        mask = mask & (idx < probe)\n",
        "        probe -= mask.sum(dim=1)\n",
        "\n",
        "        zout = zout[torch.arange(batch_size), :, probe, probe]\n",
        "        return zout\n",
        "\n",
        "    def decap_model(self, z_initial, z_final):\n",
        "        impedance_gap = torch.zeros_like(z_initial)\n",
        "\n",
        "        impedance_gap = z_initial - z_final\n",
        "        reward = torch.sum(impedance_gap * 1000000000 / self.freq, dim=1)\n",
        "\n",
        "        reward = reward / 10\n",
        "        return reward\n",
        "\n",
        "    def initial_impedance(self, probe):\n",
        "        zout = self.raw_pdn[:, probe, probe]\n",
        "        return zout\n",
        "\n",
        "    def decap_sim(self, probe, solution, keepout=None):\n",
        "        \n",
        "        # if keepout is not None:\n",
        "        #     intersect = torch.tensor(list(set(solution.tolist()) & set(keepout.tolist())))\n",
        "        #     assert len(intersect) == 0, \"Decap must be not placed at the keepout region\"\n",
        "\n",
        "        z_initial = self.initial_impedance(probe).squeeze().swapaxes(0,1)\n",
        "        z_initial = torch.abs(z_initial)\n",
        "        z_final = self.decap_placement(solution, probe)\n",
        "        z_final = torch.abs(z_final)\n",
        "        reward = self.decap_model(z_initial, z_final)\n",
        "\n",
        "        return reward\n",
        "    \n",
        "env = DecapSimulator()\n",
        "\n",
        "probe = torch.Tensor([[23]]).long().repeat(32,1)\n",
        "solution = torch.Tensor([[1, 5, 7, 21]]).long().repeat(32,1)\n",
        "keepout = torch.Tensor([[2, 3, 10]]).long().repeat(32,1)\n",
        "\n",
        "# Get reward for the batched input\n",
        "reward = env.decap_sim(probe, solution, keepout)\n",
        "print(reward)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "probe = torch.Tensor([23]).long()\n",
        "solution = torch.Tensor([1,5,7,21]).long()\n",
        "keepout = torch.Tensor([2,3,10]).long()\n",
        "\n",
        "\n",
        "# Make them into a mask of 100 elements\n",
        "mask = torch.zeros(100).bool()\n",
        "probe = torch.scatter(mask, 0, probe, 1)\n",
        "solution = torch.scatter(mask, 0, solution, 1)\n",
        "keepout = torch.scatter(mask, 0, keepout, 1)\n",
        "\n",
        "print(probe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[23]])\n"
          ]
        }
      ],
      "source": [
        "# Get index of True element\n",
        "probe = torch.nonzero(probe)\n",
        "print(probe)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbc5b198709957cb10390a2819ca930d3578f48e335d60395e01c5208a66cb86"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
