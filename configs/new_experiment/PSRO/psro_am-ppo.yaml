# @package _global_

defaults:
  
  - override /env: svrp.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml
  - override /logger: wandb.yaml  # csv.yaml  #
  
# psro params
iters: 30
epsilon: 0.01
prog_epoch1: 15
prog_epoch2: 10
adver_epoch: 5

env:
  num_loc: 50

logger:
  wandb:
    project: "rl4co-psro"
    tags: ["adv-am", "${env.name}"]
    group: ${env.name}${env.num_loc}
    name: am-${env.name}${env.num_loc}
    offline: True


model_psro:
  batch_size:  512 #10 #
  val_batch_size: 10_000  #1024  #10 #
  test_batch_size: 1024 #10   #
  train_data_size: 640_000  #100  #
  val_data_size: 10_000  #
  test_data_size: 100  #100 #
  data_dir: "data${paths.stoch_idx}/"
  # policy_kwargs:
  #   test_decode_type: "multistart_sampling"


model:
  optimizer_kwargs:
    lr: 1e-4
    weight_decay: 0
  lr_scheduler:
    "MultiStepLR"
  lr_scheduler_kwargs:
    milestones: [7, 12] #
    gamma: 0.1
  data_dir: "data${paths.stoch_idx}/"
  # policy_kwargs:
  #   test_decode_type: "multistart_sampling"

load_prog_from_path: /home/u2021141179/rl4co_cp/logs/train/runs/svrp50/am-svrp50/2024-05-04_22-56-20/rl4co/n4no1ty5/checkpoints/epoch=99-step=125000.ckpt

# svrp20
#/home/u2021141179/rl4co_cp/logs/train/runs/svrp20/am-svrp20/2024-02-27_12-22-21/rl4co/ajzphdl4/checkpoints/epoch=99-step=250000.ckpt
# csp20
#/home/u2021141179/rl4co_cp/logs/train/runs/csp20/am-csp20/2024-04-25_14-06-46/rl4co/u9r7s1o3/checkpoints/epoch=99-step=125000.ckpt
# csp50
#/home/u2021141179/rl4co_cp/logs/train/runs/csp50/am-csp50/2024-05-04_07-06-59/rl4co/9rwb952x/checkpoints/epoch=99-step=125000.ckpt
# svrp50
# /home/u2021141179/rl4co_cp/logs/train/runs/svrp50/am-svrp50/2024-05-04_22-56-20/rl4co/n4no1ty5/checkpoints/epoch=99-step=125000.ckpt
# null

train_with_pretrain: null
  # "/home/panpan/rl4co/logs/train_rarl/runs/svrp20/am-svrp20/2024-01-11_22-28-55/csv/version_0/checkpoints/epoch=106-step=627500.ckpt"

model_adversary:
  opponent: null
  optimizer_kwargs:
    lr: 1e-3
    weight_decay: 0
  lr_scheduler:
    "MultiStepLR"
  lr_scheduler_kwargs:
    milestones: [2, 4]
    gamma: 0.1
  data_dir: "data${paths.stoch_idx}/"
  # policy_kwargs:
  #   test_decode_type: "multistart_sampling"

# trainer:
#   # max_epochs:  50 #

seed: 1234

evaluate_method: "greedy"   #["greedy", "sampling", "greedy_multistart", "augment_dihedral_8", "augment", "greedy_multistart_augment_dihedral_8", "greedy_multistart_augment"]